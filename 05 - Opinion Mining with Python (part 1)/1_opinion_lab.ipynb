{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_opinion_lab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "ZwNfCgBU9IOR",
        "Qr17VRMp9IOw"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unibodatascience/BBS-TextMining/blob/master/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/1_opinion_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ff1tWjz9IMU"
      },
      "source": [
        "# Opinion Mining & Sentiment Analysis: Lab Activities\n",
        "\n",
        "**Text Mining unit**\n",
        "\n",
        "_Prof. Gianluca Moro, DISI, University of Bologna_\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum UniversitÃ  di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVEJNfK9IMV"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import external libraries (thus verifying they are correctly installed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mahnniQH9IMV"
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqGAJAwE9IMY"
      },
      "source": [
        "If using IPython/Jupyter, run the following to render plots inline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4F4jCZtw9IMY"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XQSMiSN9IMa"
      },
      "source": [
        "Set some options in pandas for printing DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p72mmuD39IMb"
      },
      "source": [
        "pd.options.display.max_colwidth = 100\n",
        "pd.options.display.precision = 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naIH999P9IMd"
      },
      "source": [
        "Define a utility function to download data files if they are not already present in working directory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8v0EsMy9IMd"
      },
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPuiZa99IMf"
      },
      "source": [
        "## Activity 1: Twitter Opinion Mining\n",
        "\n",
        "**Goal:** evaluate from Twitter how much customers are satisfied of airline companies\n",
        "\n",
        "1. Collect tweets citing airline companies\n",
        "2. Define lists of opinion keywords\n",
        "3. Evaluate sentiment of each tweet\n",
        "4. Summarize sentiment for each airline company\n",
        "5. Extract customer satisfaction for companies from the ACSI website\n",
        "6. Compare scores estimated from Twitter with those extracted from ACSI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAkDuqRx9IMf"
      },
      "source": [
        "This is a list of the Twitter accounts of airline companies taken into consideration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZwtwx3F9IMg"
      },
      "source": [
        "airlines = [\n",
        "    \"delta\",\n",
        "    \"americanair\",\n",
        "    \"jetblue\",\n",
        "    \"southwestair\",\n",
        "    \"united\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeYYAQJN9IMj"
      },
      "source": [
        "### Collect tweets citing airline companies\n",
        "\n",
        "Recent tweets matching a given query can be searched using the Twitter Search API; many libraries exist for Python and other languages providing easy access to the API\n",
        "\n",
        "We see here how to obtain tweets using the `TwitterSearch` package, installable with `pip install TwitterSearch`; a Twitter account with an associated mobile number is needed in order to use the API\n",
        "\n",
        "If you can't or don't want to use your Twitter account and/or install the package, you can use a set of pre-collected tweets we provide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OoGLa6FsR9P",
        "outputId": "be1decd9-be20-43fa-e90a-269f410383fb"
      },
      "source": [
        "!pip install TwitterSearch==1.0.2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting TwitterSearch==1.0.2\n",
            "  Downloading https://files.pythonhosted.org/packages/52/77/3731f0d25c97ef1d1e5d034563f9e8ec2445946c1633b3813c22c7f363ee/TwitterSearch-1.0.2.tar.gz\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from TwitterSearch==1.0.2) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from TwitterSearch==1.0.2) (1.3.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (2020.12.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.3.0->TwitterSearch==1.0.2) (3.1.0)\n",
            "Building wheels for collected packages: TwitterSearch\n",
            "  Building wheel for TwitterSearch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for TwitterSearch: filename=TwitterSearch-1.0.2-cp37-none-any.whl size=18462 sha256=00ad3d66863766f69009628ba298468f53d0e285256222d5710be29d6d85ede4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/98/87/016442cb92cf56a0e262e7d68ad00b3701928e247d04955fdb\n",
            "Successfully built TwitterSearch\n",
            "Installing collected packages: TwitterSearch\n",
            "Successfully installed TwitterSearch-1.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HORmDG1V9IMj"
      },
      "source": [
        "#### Creating a Twitter application\n",
        "\n",
        "In order to use Twitter APIs you need API keys: follow these steps to obtain one\n",
        "\n",
        "1. Go to https://developer.twitter.com/en/apps and login with your Twitter account\n",
        "2. Click the \"Create New App\" button, fill the form with short descriptive values (you may use e.g. \"http://example.com\" as the URL) and confirm\n",
        "3. Click on the app you just created and open the \"Key and Access Tokens\" tab\n",
        "4. For better security, ensure to set the Access Level to Read-only\n",
        "5. Click on the \"Create my access token\" button below\n",
        "\n",
        "You will need strings labeled with _Consumer Key_, _Consumer Secret_, _Access Token_ and _Access Token Secret_ shown in the page to use the API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tCYLFbaTyZ2"
      },
      "source": [
        "#### Loading keys\n",
        "\n",
        "Load the necessary Twitter security keys from file. \n",
        "\n",
        "*Software Security note*: avoid to leave secret keys hardcoded or write them in shell commands. Prefer keeping them in protected files or using secrets management tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4T4LzxiT1UX"
      },
      "source": [
        "import json\n",
        "\n",
        "with open('twitter_keys.json') as f:\n",
        "  keys = json.load(f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBhW_i09IMk"
      },
      "source": [
        "#### Authenticating\n",
        "\n",
        "Import the necessary classes and create a `TwitterSearch` object providing the API codes obtained above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5muh0UR9IMk"
      },
      "source": [
        "from TwitterSearch import TwitterSearch, TwitterSearchOrder\n",
        "\n",
        "ts = TwitterSearch(\n",
        "    consumer_key = keys[\"consumer_key\"],\n",
        "    consumer_secret = keys[\"consumer_secret\"], \n",
        "    access_token = keys[\"access_token\"], \n",
        "    access_token_secret = keys[\"access_token_secret\"] \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKcbMR79IMm"
      },
      "source": [
        "#### Obtaining tweets\n",
        "\n",
        "Create a `TwitterSearchOrder` indicating the tweets to search: we start for example by searching tweets about Delta Air Lines, whose Twitter account is \"@delta\"; by default the search will return up to 100 tweets, the upper limit set by Twitter for each request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfMohlNI9IMn"
      },
      "source": [
        "tso = TwitterSearchOrder()\n",
        "tso.set_keywords([\"@delta\"])\n",
        "tso.set_language(\"en\")\n",
        "tso.set_include_entities(False)\n",
        "tso.set_count(5) # To limit the search to five tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_MWWTcN9IMo"
      },
      "source": [
        "We can now issue the request to the Twitter API\n",
        "\n",
        "**Warning:** the Twitter API has usage rate limitations, `search_tweets` and other API methods will temporarily stop working if executed many times in few minutes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2GkB71N9IMp",
        "outputId": "b1b9e8a7-d680-46a1-a8dd-67d3a965016f"
      },
      "source": [
        "tsresp = ts.search_tweets(tso)\n",
        "tsresp # Print the search result retrieved as JSON object"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'content': {'search_metadata': {'completed_in': 0.05,\n",
              "   'count': 5,\n",
              "   'max_id': 1402521011090821121,\n",
              "   'max_id_str': '1402521011090821121',\n",
              "   'next_results': '?max_id=1402517785750740991&q=%40delta&lang=en&count=5',\n",
              "   'query': '%40delta',\n",
              "   'refresh_url': '?since_id=1402521011090821121&q=%40delta&lang=en',\n",
              "   'since_id': 0,\n",
              "   'since_id_str': '0'},\n",
              "  'statuses': [{'contributors': None,\n",
              "    'coordinates': None,\n",
              "    'created_at': 'Wed Jun 09 07:00:41 +0000 2021',\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'geo': None,\n",
              "    'id': 1402521011090821121,\n",
              "    'id_str': '1402521011090821121',\n",
              "    'in_reply_to_screen_name': 'Delta',\n",
              "    'in_reply_to_status_id': 1402460824703148032,\n",
              "    'in_reply_to_status_id_str': '1402460824703148032',\n",
              "    'in_reply_to_user_id': 5920532,\n",
              "    'in_reply_to_user_id_str': '5920532',\n",
              "    'is_quote_status': False,\n",
              "    'lang': 'en',\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'place': None,\n",
              "    'retweet_count': 0,\n",
              "    'retweeted': False,\n",
              "    'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
              "    'text': '@Delta Please call me at your earliest convenience and leave a message with a call back number. There were much bigâ€¦ https://t.co/Tgkm4kAC5F',\n",
              "    'truncated': True,\n",
              "    'user': {'contributors_enabled': False,\n",
              "     'created_at': 'Fri Aug 27 18:48:11 +0000 2010',\n",
              "     'default_profile': False,\n",
              "     'default_profile_image': False,\n",
              "     'description': 'Father, Husband, Photographer, Music Enthusiast, Artist, Writer, Cat Lover.',\n",
              "     'entities': {'description': {'urls': []},\n",
              "      'url': {'urls': [{'display_url': 'hurricaneoflions.com',\n",
              "         'expanded_url': 'http://www.hurricaneoflions.com',\n",
              "         'indices': [0, 22],\n",
              "         'url': 'http://t.co/vl8qfDm55p'}]}},\n",
              "     'favourites_count': 90,\n",
              "     'follow_request_sent': False,\n",
              "     'followers_count': 58,\n",
              "     'following': False,\n",
              "     'friends_count': 462,\n",
              "     'geo_enabled': True,\n",
              "     'has_extended_profile': False,\n",
              "     'id': 183723484,\n",
              "     'id_str': '183723484',\n",
              "     'is_translation_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'lang': None,\n",
              "     'listed_count': 1,\n",
              "     'location': 'Long Island, New York',\n",
              "     'name': 'Hurricane of Lions',\n",
              "     'notifications': False,\n",
              "     'profile_background_color': 'FFF04D',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme19/bg.gif',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme19/bg.gif',\n",
              "     'profile_background_tile': True,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/2169857665/lionSquare_normal.gif',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/2169857665/lionSquare_normal.gif',\n",
              "     'profile_link_color': '0099CC',\n",
              "     'profile_sidebar_border_color': 'FFF8AD',\n",
              "     'profile_sidebar_fill_color': 'F6FFD1',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'protected': False,\n",
              "     'screen_name': 'HOLphoto',\n",
              "     'statuses_count': 364,\n",
              "     'time_zone': None,\n",
              "     'translator_type': 'none',\n",
              "     'url': 'http://t.co/vl8qfDm55p',\n",
              "     'utc_offset': None,\n",
              "     'verified': False,\n",
              "     'withheld_in_countries': []}},\n",
              "   {'contributors': None,\n",
              "    'coordinates': None,\n",
              "    'created_at': 'Wed Jun 09 06:56:04 +0000 2021',\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'geo': None,\n",
              "    'id': 1402519848207360002,\n",
              "    'id_str': '1402519848207360002',\n",
              "    'in_reply_to_screen_name': None,\n",
              "    'in_reply_to_status_id': None,\n",
              "    'in_reply_to_status_id_str': None,\n",
              "    'in_reply_to_user_id': None,\n",
              "    'in_reply_to_user_id_str': None,\n",
              "    'is_quote_status': False,\n",
              "    'lang': 'en',\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'place': None,\n",
              "    'possibly_sensitive': False,\n",
              "    'retweet_count': 1,\n",
              "    'retweeted': False,\n",
              "    'retweeted_status': {'contributors': None,\n",
              "     'coordinates': None,\n",
              "     'created_at': 'Wed Jun 09 03:12:46 +0000 2021',\n",
              "     'favorite_count': 4,\n",
              "     'favorited': False,\n",
              "     'geo': None,\n",
              "     'id': 1402463654600138752,\n",
              "     'id_str': '1402463654600138752',\n",
              "     'in_reply_to_screen_name': None,\n",
              "     'in_reply_to_status_id': None,\n",
              "     'in_reply_to_status_id_str': None,\n",
              "     'in_reply_to_user_id': None,\n",
              "     'in_reply_to_user_id_str': None,\n",
              "     'is_quote_status': False,\n",
              "     'lang': 'en',\n",
              "     'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "     'place': None,\n",
              "     'possibly_sensitive': False,\n",
              "     'retweet_count': 1,\n",
              "     'retweeted': False,\n",
              "     'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
              "     'text': 'Been on hold with @Delta for over 2 and a half hours... all I know is pain https://t.co/LCsSgcbtn8',\n",
              "     'truncated': False,\n",
              "     'user': {'contributors_enabled': False,\n",
              "      'created_at': 'Tue Jan 27 23:10:44 +0000 2009',\n",
              "      'default_profile': False,\n",
              "      'default_profile_image': False,\n",
              "      'description': 'Mover, Shaker and Producer. Me and my friends deliver the future. Stream on Twitch, create content for @nrdyco $rocknrolla email - wolf6productions@gmail.com',\n",
              "      'entities': {'description': {'urls': []},\n",
              "       'url': {'urls': [{'display_url': 'linktr.ee/wolf6_actual',\n",
              "          'expanded_url': 'https://linktr.ee/wolf6_actual',\n",
              "          'indices': [0, 23],\n",
              "          'url': 'https://t.co/QHH3ZXV053'}]}},\n",
              "      'favourites_count': 56801,\n",
              "      'follow_request_sent': False,\n",
              "      'followers_count': 899,\n",
              "      'following': False,\n",
              "      'friends_count': 1046,\n",
              "      'geo_enabled': True,\n",
              "      'has_extended_profile': True,\n",
              "      'id': 19623462,\n",
              "      'id_str': '19623462',\n",
              "      'is_translation_enabled': False,\n",
              "      'is_translator': False,\n",
              "      'lang': None,\n",
              "      'listed_count': 23,\n",
              "      'location': 'Austin, TX',\n",
              "      'name': 'Dustin',\n",
              "      'notifications': False,\n",
              "      'profile_background_color': '131516',\n",
              "      'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "      'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "      'profile_background_tile': True,\n",
              "      'profile_banner_url': 'https://pbs.twimg.com/profile_banners/19623462/1469511842',\n",
              "      'profile_image_url': 'http://pbs.twimg.com/profile_images/1398799233432506370/Nf-r9Wj4_normal.jpg',\n",
              "      'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1398799233432506370/Nf-r9Wj4_normal.jpg',\n",
              "      'profile_link_color': 'FF691F',\n",
              "      'profile_sidebar_border_color': 'EEEEEE',\n",
              "      'profile_sidebar_fill_color': 'EFEFEF',\n",
              "      'profile_text_color': '333333',\n",
              "      'profile_use_background_image': True,\n",
              "      'protected': False,\n",
              "      'screen_name': 'Wolf6_Actual',\n",
              "      'statuses_count': 45822,\n",
              "      'time_zone': None,\n",
              "      'translator_type': 'none',\n",
              "      'url': 'https://t.co/QHH3ZXV053',\n",
              "      'utc_offset': None,\n",
              "      'verified': False,\n",
              "      'withheld_in_countries': []}},\n",
              "    'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              "    'text': 'RT @Wolf6_Actual: Been on hold with @Delta for over 2 and a half hours... all I know is pain https://t.co/LCsSgcbtn8',\n",
              "    'truncated': False,\n",
              "    'user': {'contributors_enabled': False,\n",
              "     'created_at': 'Sat Jun 27 07:59:44 +0000 2020',\n",
              "     'default_profile': True,\n",
              "     'default_profile_image': False,\n",
              "     'description': 'Chii is Chii',\n",
              "     'entities': {'description': {'urls': []}},\n",
              "     'favourites_count': 1355,\n",
              "     'follow_request_sent': False,\n",
              "     'followers_count': 23,\n",
              "     'following': False,\n",
              "     'friends_count': 36,\n",
              "     'geo_enabled': False,\n",
              "     'has_extended_profile': True,\n",
              "     'id': 1276787253138751488,\n",
              "     'id_str': '1276787253138751488',\n",
              "     'is_translation_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'lang': None,\n",
              "     'listed_count': 0,\n",
              "     'location': '',\n",
              "     'name': 'ChiisaiInu',\n",
              "     'notifications': False,\n",
              "     'profile_background_color': 'F5F8FA',\n",
              "     'profile_background_image_url': None,\n",
              "     'profile_background_image_url_https': None,\n",
              "     'profile_background_tile': False,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1276787403340935168/laqx4C3r_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1276787403340935168/laqx4C3r_normal.jpg',\n",
              "     'profile_link_color': '1DA1F2',\n",
              "     'profile_sidebar_border_color': 'C0DEED',\n",
              "     'profile_sidebar_fill_color': 'DDEEF6',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'protected': False,\n",
              "     'screen_name': 'InuChiisai',\n",
              "     'statuses_count': 457,\n",
              "     'time_zone': None,\n",
              "     'translator_type': 'none',\n",
              "     'url': None,\n",
              "     'utc_offset': None,\n",
              "     'verified': False,\n",
              "     'withheld_in_countries': []}},\n",
              "   {'contributors': None,\n",
              "    'coordinates': None,\n",
              "    'created_at': 'Wed Jun 09 06:55:14 +0000 2021',\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'geo': None,\n",
              "    'id': 1402519642380271617,\n",
              "    'id_str': '1402519642380271617',\n",
              "    'in_reply_to_screen_name': 'vibrantvikki',\n",
              "    'in_reply_to_status_id': 1402512288599339012,\n",
              "    'in_reply_to_status_id_str': '1402512288599339012',\n",
              "    'in_reply_to_user_id': 487958243,\n",
              "    'in_reply_to_user_id_str': '487958243',\n",
              "    'is_quote_status': False,\n",
              "    'lang': 'en',\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'place': None,\n",
              "    'possibly_sensitive': False,\n",
              "    'retweet_count': 0,\n",
              "    'retweeted': False,\n",
              "    'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
              "    'text': '@Delta \\U0001f972ðŸ’€ yâ€™all won. Goodnight. https://t.co/D3AfiLTx1J',\n",
              "    'truncated': False,\n",
              "    'user': {'contributors_enabled': False,\n",
              "     'created_at': 'Thu Feb 09 22:47:28 +0000 2012',\n",
              "     'default_profile': False,\n",
              "     'default_profile_image': False,\n",
              "     'description': 'Insta: victoriasashley',\n",
              "     'entities': {'description': {'urls': []},\n",
              "      'url': {'urls': [{'display_url': 'instagram.com/victoriasashley',\n",
              "         'expanded_url': 'http://instagram.com/victoriasashley',\n",
              "         'indices': [0, 23],\n",
              "         'url': 'https://t.co/Mpzu37XrM8'}]}},\n",
              "     'favourites_count': 21504,\n",
              "     'follow_request_sent': False,\n",
              "     'followers_count': 1275,\n",
              "     'following': False,\n",
              "     'friends_count': 676,\n",
              "     'geo_enabled': True,\n",
              "     'has_extended_profile': True,\n",
              "     'id': 487958243,\n",
              "     'id_str': '487958243',\n",
              "     'is_translation_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'lang': None,\n",
              "     'listed_count': 9,\n",
              "     'location': 'Los Angeles, CA',\n",
              "     'name': 'Victoriaaaa.',\n",
              "     'notifications': False,\n",
              "     'profile_background_color': '1A1B1F',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme9/bg.gif',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme9/bg.gif',\n",
              "     'profile_background_tile': False,\n",
              "     'profile_banner_url': 'https://pbs.twimg.com/profile_banners/487958243/1590855780',\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1394912012103127042/XEyDcNCX_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1394912012103127042/XEyDcNCX_normal.jpg',\n",
              "     'profile_link_color': '2FC2EF',\n",
              "     'profile_sidebar_border_color': '181A1E',\n",
              "     'profile_sidebar_fill_color': '252429',\n",
              "     'profile_text_color': '666666',\n",
              "     'profile_use_background_image': True,\n",
              "     'protected': False,\n",
              "     'screen_name': 'vibrantvikki',\n",
              "     'statuses_count': 37903,\n",
              "     'time_zone': None,\n",
              "     'translator_type': 'none',\n",
              "     'url': 'https://t.co/Mpzu37XrM8',\n",
              "     'utc_offset': None,\n",
              "     'verified': False,\n",
              "     'withheld_in_countries': []}},\n",
              "   {'contributors': None,\n",
              "    'coordinates': None,\n",
              "    'created_at': 'Wed Jun 09 06:48:56 +0000 2021',\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'geo': None,\n",
              "    'id': 1402518054332866563,\n",
              "    'id_str': '1402518054332866563',\n",
              "    'in_reply_to_screen_name': 'Delta',\n",
              "    'in_reply_to_status_id': 1382659082327236611,\n",
              "    'in_reply_to_status_id_str': '1382659082327236611',\n",
              "    'in_reply_to_user_id': 5920532,\n",
              "    'in_reply_to_user_id_str': '5920532',\n",
              "    'is_quote_status': False,\n",
              "    'lang': 'en',\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'place': None,\n",
              "    'retweet_count': 0,\n",
              "    'retweeted': False,\n",
              "    'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
              "    'text': '@Delta @ndbekah Will digital attestation process be easily conducted thru the mobile app at check-in time?',\n",
              "    'truncated': False,\n",
              "    'user': {'contributors_enabled': False,\n",
              "     'created_at': 'Fri Apr 10 05:01:58 +0000 2009',\n",
              "     'default_profile': True,\n",
              "     'default_profile_image': False,\n",
              "     'description': '',\n",
              "     'entities': {'description': {'urls': []}},\n",
              "     'favourites_count': 4,\n",
              "     'follow_request_sent': False,\n",
              "     'followers_count': 13,\n",
              "     'following': False,\n",
              "     'friends_count': 62,\n",
              "     'geo_enabled': False,\n",
              "     'has_extended_profile': False,\n",
              "     'id': 30165937,\n",
              "     'id_str': '30165937',\n",
              "     'is_translation_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'lang': None,\n",
              "     'listed_count': 0,\n",
              "     'location': '',\n",
              "     'name': 'Ed',\n",
              "     'notifications': False,\n",
              "     'profile_background_color': 'C0DEED',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_tile': False,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/2080398747/mullet00_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/2080398747/mullet00_normal.jpg',\n",
              "     'profile_link_color': '1DA1F2',\n",
              "     'profile_sidebar_border_color': 'C0DEED',\n",
              "     'profile_sidebar_fill_color': 'DDEEF6',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'protected': False,\n",
              "     'screen_name': 'sackdz',\n",
              "     'statuses_count': 22,\n",
              "     'time_zone': None,\n",
              "     'translator_type': 'none',\n",
              "     'url': None,\n",
              "     'utc_offset': None,\n",
              "     'verified': False,\n",
              "     'withheld_in_countries': []}},\n",
              "   {'contributors': None,\n",
              "    'coordinates': None,\n",
              "    'created_at': 'Wed Jun 09 06:47:52 +0000 2021',\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'geo': None,\n",
              "    'id': 1402517785750740992,\n",
              "    'id_str': '1402517785750740992',\n",
              "    'in_reply_to_screen_name': None,\n",
              "    'in_reply_to_status_id': None,\n",
              "    'in_reply_to_status_id_str': None,\n",
              "    'in_reply_to_user_id': None,\n",
              "    'in_reply_to_user_id_str': None,\n",
              "    'is_quote_status': False,\n",
              "    'lang': 'en',\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'place': {'attributes': {},\n",
              "     'bounding_box': {'coordinates': [[[-71.893265, 42.210065],\n",
              "        [-71.731611, 42.210065],\n",
              "        [-71.731611, 42.341455],\n",
              "        [-71.893265, 42.341455]]],\n",
              "      'type': 'Polygon'},\n",
              "     'contained_within': [],\n",
              "     'country': 'United States',\n",
              "     'country_code': 'US',\n",
              "     'full_name': 'Worcester, MA',\n",
              "     'id': '28db2dbc4240f0b2',\n",
              "     'name': 'Worcester',\n",
              "     'place_type': 'city',\n",
              "     'url': 'https://api.twitter.com/1.1/geo/id/28db2dbc4240f0b2.json'},\n",
              "    'retweet_count': 0,\n",
              "    'retweeted': False,\n",
              "    'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              "    'text': '.@staceyabrams IF big companies like @delta, @cocacola, @att, @homedepot, etc. stand for #votingrights &amp; want to seâ€¦ https://t.co/9feXkhMuGL',\n",
              "    'truncated': True,\n",
              "    'user': {'contributors_enabled': False,\n",
              "     'created_at': 'Thu Feb 24 05:47:22 +0000 2011',\n",
              "     'default_profile': True,\n",
              "     'default_profile_image': False,\n",
              "     'description': \"Always ask a question, no matter how dumb you may think it to be. Your question could change history... or at least 1 person's view.\",\n",
              "     'entities': {'description': {'urls': []}},\n",
              "     'favourites_count': 638,\n",
              "     'follow_request_sent': False,\n",
              "     'followers_count': 29,\n",
              "     'following': False,\n",
              "     'friends_count': 539,\n",
              "     'geo_enabled': True,\n",
              "     'has_extended_profile': True,\n",
              "     'id': 256850304,\n",
              "     'id_str': '256850304',\n",
              "     'is_translation_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'lang': None,\n",
              "     'listed_count': 0,\n",
              "     'location': 'Worcester, MA',\n",
              "     'name': 'Chris S',\n",
              "     'notifications': False,\n",
              "     'profile_background_color': 'C0DEED',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_tile': False,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1307531300480450562/h0fubOpT_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1307531300480450562/h0fubOpT_normal.jpg',\n",
              "     'profile_link_color': '1DA1F2',\n",
              "     'profile_sidebar_border_color': 'C0DEED',\n",
              "     'profile_sidebar_fill_color': 'DDEEF6',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'protected': False,\n",
              "     'screen_name': 'chris121710',\n",
              "     'statuses_count': 2239,\n",
              "     'time_zone': None,\n",
              "     'translator_type': 'none',\n",
              "     'url': None,\n",
              "     'utc_offset': None,\n",
              "     'verified': False,\n",
              "     'withheld_in_countries': []}}]},\n",
              " 'meta': {'date': 'Wed, 09 Jun 2021 07:02:26 GMT', 'pragma': 'no-cache', 'server': 'tsa_b', 'status': '200 OK', 'expires': 'Tue, 31 Mar 1981 05:00:00 GMT', 'set-cookie': 'personalization_id=\"v1_aPLZzeBU7rdyISbgH1w2kQ==\"; Max-Age=63072000; Expires=Fri, 09 Jun 2023 07:02:26 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id=v1%3A162322214644087152; Max-Age=63072000; Expires=Fri, 09 Jun 2023 07:02:26 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'content-type': 'application/json;charset=utf-8', 'cache-control': 'no-cache, no-store, must-revalidate, pre-check=0, post-check=0', 'last-modified': 'Wed, 09 Jun 2021 07:02:26 GMT', 'x-transaction': 'e4f562519ceae43e', 'content-length': '3056', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-xss-protection': '0', 'x-rate-limit-limit': '180', 'x-rate-limit-reset': '1623223046', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '179', 'x-twitter-response-tags': 'BouncerCompliant', 'strict-transport-security': 'max-age=631138519', 'x-connection-hash': '080fee30fa3219064b07db7db36cb30a283129ffc7564e6faf38ed80d8f250f6'}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDdUPf659IMq"
      },
      "source": [
        "We obtain an object with detailed information about the request and the response by Twitter, to obtain the list of tweets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWwj7bEy9IMr",
        "outputId": "9b3f6c41-a1a2-40c0-d8b1-b0c69a0c1a59"
      },
      "source": [
        "delta_tweets = tsresp[\"content\"][\"statuses\"]\n",
        "delta_tweets[0] # First tweet data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contributors': None,\n",
              " 'coordinates': None,\n",
              " 'created_at': 'Wed Jun 09 07:00:41 +0000 2021',\n",
              " 'favorite_count': 0,\n",
              " 'favorited': False,\n",
              " 'geo': None,\n",
              " 'id': 1402521011090821121,\n",
              " 'id_str': '1402521011090821121',\n",
              " 'in_reply_to_screen_name': 'Delta',\n",
              " 'in_reply_to_status_id': 1402460824703148032,\n",
              " 'in_reply_to_status_id_str': '1402460824703148032',\n",
              " 'in_reply_to_user_id': 5920532,\n",
              " 'in_reply_to_user_id_str': '5920532',\n",
              " 'is_quote_status': False,\n",
              " 'lang': 'en',\n",
              " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              " 'place': None,\n",
              " 'retweet_count': 0,\n",
              " 'retweeted': False,\n",
              " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
              " 'text': '@Delta Please call me at your earliest convenience and leave a message with a call back number. There were much bigâ€¦ https://t.co/Tgkm4kAC5F',\n",
              " 'truncated': True,\n",
              " 'user': {'contributors_enabled': False,\n",
              "  'created_at': 'Fri Aug 27 18:48:11 +0000 2010',\n",
              "  'default_profile': False,\n",
              "  'default_profile_image': False,\n",
              "  'description': 'Father, Husband, Photographer, Music Enthusiast, Artist, Writer, Cat Lover.',\n",
              "  'entities': {'description': {'urls': []},\n",
              "   'url': {'urls': [{'display_url': 'hurricaneoflions.com',\n",
              "      'expanded_url': 'http://www.hurricaneoflions.com',\n",
              "      'indices': [0, 22],\n",
              "      'url': 'http://t.co/vl8qfDm55p'}]}},\n",
              "  'favourites_count': 90,\n",
              "  'follow_request_sent': False,\n",
              "  'followers_count': 58,\n",
              "  'following': False,\n",
              "  'friends_count': 462,\n",
              "  'geo_enabled': True,\n",
              "  'has_extended_profile': False,\n",
              "  'id': 183723484,\n",
              "  'id_str': '183723484',\n",
              "  'is_translation_enabled': False,\n",
              "  'is_translator': False,\n",
              "  'lang': None,\n",
              "  'listed_count': 1,\n",
              "  'location': 'Long Island, New York',\n",
              "  'name': 'Hurricane of Lions',\n",
              "  'notifications': False,\n",
              "  'profile_background_color': 'FFF04D',\n",
              "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme19/bg.gif',\n",
              "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme19/bg.gif',\n",
              "  'profile_background_tile': True,\n",
              "  'profile_image_url': 'http://pbs.twimg.com/profile_images/2169857665/lionSquare_normal.gif',\n",
              "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/2169857665/lionSquare_normal.gif',\n",
              "  'profile_link_color': '0099CC',\n",
              "  'profile_sidebar_border_color': 'FFF8AD',\n",
              "  'profile_sidebar_fill_color': 'F6FFD1',\n",
              "  'profile_text_color': '333333',\n",
              "  'profile_use_background_image': True,\n",
              "  'protected': False,\n",
              "  'screen_name': 'HOLphoto',\n",
              "  'statuses_count': 364,\n",
              "  'time_zone': None,\n",
              "  'translator_type': 'none',\n",
              "  'url': 'http://t.co/vl8qfDm55p',\n",
              "  'utc_offset': None,\n",
              "  'verified': False,\n",
              "  'withheld_in_countries': []}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjUN5pSD9IMs"
      },
      "source": [
        "For each tweet we have an object with many details: among the key ones we have its unique ID, the name of the author and its actual text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncZvBikP9IMt",
        "outputId": "a57484bf-dd37-4314-ca05-3b6104b69ac2"
      },
      "source": [
        "delta_tweets[0][\"id\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1402521011090821121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7MjVSGsJ9IMv",
        "outputId": "c0d46448-c634-4ff7-926c-ae48e2b54a3a"
      },
      "source": [
        "delta_tweets[0][\"user\"][\"name\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hurricane of Lions'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "HMTV3-cQ9IMx",
        "outputId": "78e63307-ae41-4653-9a65-f17ddeb9c2a4"
      },
      "source": [
        "delta_tweets[0][\"text\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'@Delta Please call me at your earliest convenience and leave a message with a call back number. There were much bigâ€¦ https://t.co/Tgkm4kAC5F'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTfoH9L89IMz"
      },
      "source": [
        "Define a function to repeat the operations given above on any search string and return a list of the contents of each tweet (without metadata)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dIJlfOIX9IMz"
      },
      "source": [
        "def get_recent_tweets(query):\n",
        "    print(\"getting tweets for '{}' ... \".format(query), end=\"\")\n",
        "    tso = TwitterSearchOrder()\n",
        "    tso.set_keywords([query]) # the keywords of our tweets search\n",
        "    tso.set_language(\"en\") # fetch only english tweets\n",
        "    tso.set_include_entities(False) # Entities provide metadata and additional contextual information about content posted on Twitter (e.g. hashtags, urls, user_mentions, symbols). https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/entities\n",
        "    tso.set_count(5) # the number of tweets we want to get. If ommitted it is set to 100 that is also the maximum value\n",
        "    tsresp = ts.search_tweets(tso)\n",
        "    texts = [status[\"text\"] for status in tsresp[\"content\"][\"statuses\"]]\n",
        "    print(\"{} retrieved\".format(len(texts)))\n",
        "    return texts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDC-Z8Md9IM1"
      },
      "source": [
        "Use then this function to create a dictionary mapping airline names to list of relevant tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeWeR8-h9IM1",
        "outputId": "6a37ae76-1a36-4858-a1d4-90ea48dfe58a"
      },
      "source": [
        "current_tweets = {\n",
        "    airline: get_recent_tweets(\"@\" + airline)\n",
        "    for airline in airlines\n",
        "}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "getting tweets for '@delta' ... 5 retrieved\n",
            "getting tweets for '@americanair' ... 5 retrieved\n",
            "getting tweets for '@jetblue' ... 5 retrieved\n",
            "getting tweets for '@southwestair' ... 5 retrieved\n",
            "getting tweets for '@united' ... 5 retrieved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WUU2w7RlJFE",
        "outputId": "0b380ca7-fa8c-4dd4-f239-b66809b76854"
      },
      "source": [
        "current_tweets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'americanair': ['@AmericanAir Please tell me why I was taken off an out going flight, threatened with jail and having child servicesâ€¦ https://t.co/KD2XQX0FUX',\n",
              "  '1/2 @AmericanAir  how is it that my teenage daughter arrives PDX to find out her bag never left the origin airportâ€¦ https://t.co/VVkhGqBOEw',\n",
              "  'A fine #CEO who I greatly respect after stood up for my right to vote in Texas! Charles Koch 1/10th of 1% defacto lâ€¦ https://t.co/1LghvbFmvt',\n",
              "  '@seacoast86 @AmericanAir Exactly.',\n",
              "  '@AmericanAir please do better!'],\n",
              " 'delta': ['@Delta Please call me at your earliest convenience and leave a message with a call back number. There were much bigâ€¦ https://t.co/Tgkm4kAC5F',\n",
              "  'RT @Wolf6_Actual: Been on hold with @Delta for over 2 and a half hours... all I know is pain https://t.co/LCsSgcbtn8',\n",
              "  '@Delta \\U0001f972ðŸ’€ yâ€™all won. Goodnight. https://t.co/D3AfiLTx1J',\n",
              "  '@Delta @ndbekah Will digital attestation process be easily conducted thru the mobile app at check-in time?',\n",
              "  '.@staceyabrams IF big companies like @delta, @cocacola, @att, @homedepot, etc. stand for #votingrights &amp; want to seâ€¦ https://t.co/9feXkhMuGL'],\n",
              " 'jetblue': [\"Hellooooo, when you're using your computer what icon is for @ChipotleTweets and @JetBlue team up to create a hot new brand, @tonyhsieh\",\n",
              "  \"RT @TheTailoryNYC: @IanDeason  Our bag has been held up in ATL for 3 days now, since Sunday. We've heard no word from your team after calliâ€¦\",\n",
              "  '@JetBlue Your airline lost my bags 2 days ago. Thereâ€™s been no response from your end to the connecting airline desâ€¦ https://t.co/pbr56AEOFJ',\n",
              "  'Does anyone know if ur allowed to bring hot pockets in ur carry on @JetBlue',\n",
              "  'RT @qatarairways: Our strategic partnerships with @AlaskaAir, @AmericanAir and @JetBlue enable us to connect to more points in the United Sâ€¦'],\n",
              " 'southwestair': ['@AnthonyJMarohn @cswildfeuer @SouthwestAir There were certain requirements and that ended in December 2020.',\n",
              "  '@SouthwestAir I got an email that I canceled my flight, which was incorrect. I then had to wait on hold for over 30â€¦ https://t.co/q5hMprbFDd',\n",
              "  'Thank you @SouthwestAir for opening travel for the West Coast.  Prices are great! https://t.co/ZOVO6derQC',\n",
              "  'RT @SouthwestAir: Happy 50th Birthday to us! Between now and June 18, over 50 million Rapid RewardsÂ® bonus points are up for grabs. Enter dâ€¦',\n",
              "  'What is your dream airplane to go on? Mine is @SouthwestAir ðŸ˜ https://t.co/igsWu4O4gW'],\n",
              " 'united': ['RT @boomaero: Destinations around the globe, accessible in half the time. Meet the future @united Overture fleet. https://t.co/zVG2aMCVKx #â€¦',\n",
              "  '@EatingAsia @united Ouch. Take care and hope you get home soon.',\n",
              "  '@united having trouble using my flight credit for a new flight.',\n",
              "  'Ok @united . Iâ€™m feeling the love as I approach 2,000,000 in 2021. https://t.co/ttkxneuxn5',\n",
              "  '@FlyFrontier @Delta @united @SpiritAirlines Whats with all the red eye onlys from san diego to orlando ? who wantsâ€¦ https://t.co/zdfJlShD1a']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW7g6aIYleKr",
        "outputId": "03e4bf89-4353-4351-950c-8decccf40306"
      },
      "source": [
        "current_tweets[\"delta\"][:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['@Delta Please call me at your earliest convenience and leave a message with a call back number. There were much bigâ€¦ https://t.co/Tgkm4kAC5F',\n",
              " 'RT @Wolf6_Actual: Been on hold with @Delta for over 2 and a half hours... all I know is pain https://t.co/LCsSgcbtn8',\n",
              " '@Delta \\U0001f972ðŸ’€ yâ€™all won. Goodnight. https://t.co/D3AfiLTx1J']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjfbPhaw9IM4"
      },
      "source": [
        "### Using pre-collected tweets\n",
        "\n",
        "For convenience, we provide a set of precollected tweets about the airline companies as an alternative to latest tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJXE4I_I9IM4"
      },
      "source": [
        "download(\"tweets.zip\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/tweets.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sEkMrRK9IM6"
      },
      "source": [
        "The ZIP archive contains a `company_name.txt` file for each airline company, each with a list of tweets (one per line): we load them into a dict mapping the name of each company to the list of relevant tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQzbR0hz9IM7"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "archive_tweets = {}\n",
        "with ZipFile(\"tweets.zip\") as zipf:\n",
        "    for airline in airlines:\n",
        "        with zipf.open(airline + \".txt\") as f:\n",
        "            archive_tweets[airline] = list(line.decode().strip() for line in f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScC5ge499IM8"
      },
      "source": [
        "You can read for example some tweets about Delta airlines:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rg0Nu9e9IM9",
        "outputId": "f301491e-43a5-4f12-a616-9661af4cb3b3"
      },
      "source": [
        "archive_tweets[\"delta\"][:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings vs Rangers in NY - http://t.co/JXBc5kDXnZ\"RT',\n",
              " '@AneetharPweety am @delta state buh on ma way to benin city now',\n",
              " 'RT @iamdiddy: If youâ€™re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lounge at @Delta terminal at JFK. http://t.co/â€¦']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-dWEteC9IM-"
      },
      "source": [
        "In the following we will work on these `archive_tweets`, replace that in the line below with `current_tweets` if you want to use downloaded tweets instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO407nji9IM-"
      },
      "source": [
        "tweets = archive_tweets # current_tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khZAVoZV9INA"
      },
      "source": [
        "To better deal with them later, we represents tweets into a pandas DataFrame with two columns\n",
        "- a `text` column with the text of the tweet\n",
        "- an `airline` column with the airline each tweet refers to"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_q-5J0N9INA"
      },
      "source": [
        "tweets = pd.DataFrame(\n",
        "    {\"airline\": airline, \"text\": text}\n",
        "    for airline, tweetlist in tweets.items()\n",
        "    for text in tweetlist\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "BVxwWYH79INC",
        "outputId": "da11b671-1594-4a63-ec25-63707e6461ed"
      },
      "source": [
        "tweets.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>delta</td>\n",
              "      <td>\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delta</td>\n",
              "      <td>@AneetharPweety am @delta state buh on ma way to benin city now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>delta</td>\n",
              "      <td>RT @iamdiddy: If youâ€™re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline                                                                                                 text\n",
              "0   delta  \"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings ...\n",
              "1   delta                                      @AneetharPweety am @delta state buh on ma way to benin city now\n",
              "2   delta  RT @iamdiddy: If youâ€™re flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lou..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKrg7s8f9INF"
      },
      "source": [
        "### Estimating sentiment using lists of opinion words\n",
        "\n",
        "Several methods and algorithms have been proposed in literature to estimate the sentiment of a document (or sentence), usually quite complex.\n",
        "\n",
        "To get started, we will use a trivial lexicon-based method which assigns a score by counting known positive and negative words in each tweet.\n",
        "\n",
        "Hu and Liu made available for download a list of about 6,800 words labeled as either positive or negative.\n",
        "\n",
        "- **Positive:** love, best, cool, great, good, amazing, ...\n",
        "- **Negative:** hate, worst, sucks, awful, nightmare, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrgWberF9INF"
      },
      "source": [
        "We write\n",
        "- a function used to process word lists, ignoring lines either empty or starting with \";\" (comments)\n",
        "- another function using the first one to get a set of words contained in a named file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBxH-BSW9ING"
      },
      "source": [
        "def scan_hu_liu(f):\n",
        "    for line in f:\n",
        "        line = line.decode(errors=\"ignore\").strip() # strip() function removes spaces at the beginning and at the end of the string\n",
        "        if line and not line.startswith(\";\"):\n",
        "            yield line\n",
        "\n",
        "def load_hu_liu(filename):\n",
        "    with open(filename, \"rb\") as f:\n",
        "        return set(scan_hu_liu(f)) # set(...) is the build function to create a new Python set {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqbslQd69INI"
      },
      "source": [
        "We then download the two sets (one for positive words and one for negative ones) and use the latter function to load them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAfuoln99INI",
        "outputId": "e05b1960-6cdc-4149-a6d4-8ae2f0929ac5"
      },
      "source": [
        "download(\"positive-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/positive-words.txt\")\n",
        "download(\"negative-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/negative-words.txt\")\n",
        "\n",
        "hu_liu_pos = load_hu_liu(\"positive-words.txt\")\n",
        "print('Positive words')\n",
        "print(hu_liu_pos)\n",
        "\n",
        "print()\n",
        "\n",
        "hu_liu_neg = load_hu_liu(\"negative-words.txt\")\n",
        "print('Negative words')\n",
        "print(hu_liu_neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive words\n",
            "{'exaltation', 'super', 'influential', 'well-balanced', 'lucid', 'pros', 'preferably', 'famous', 'lower-priced', 'blockbuster', 'wonderful', 'afford', 'advantages', 'believable', 'appreciative', 'upgraded', 'chic', 'beckons', 'approval', 'respectable', 'foolproof', 'smoothly', 'hearten', 'uplift', 'finely', 'marvelous', 'replaceable', 'rectification', 'appeal', 'rosy', 'readable', 'prominent', 'supremely', 'tough', 'non-violent', 'bonuses', 'cure', 'faultless', 'fast', 'accomplished', 'fashionable', 'inspiration', 'err-free', 'terrifically', 'attentive', 'enticing', 'rapt', 'unity', 'likable', 'engaging', 'sane', 'large-capacity', 'effectively', 'sweeten', 'fortunately', 'spirited', 'flattering', 'refunded', 'affectionate', 'trouble-free', 'sensibly', 'fairly', 'dashing', 'richly', 'exuberance', 'contribution', 'entice', 'liberty', 'gracefully', 'imaginative', 'courageously', 'topnotch', 'succeeded', 'exhilarate', 'enviously', 'overtaken', 'gladly', 'smitten', 'honesty', 'purposeful', 'friendliness', 'unassailable', 'plusses', 'dote', 'courteous', 'euphoric', 'respectfully', 'unquestionable', 'ebulliently', 'exultingly', 'enrapture', 'enchanting', 'awesomeness', 'appealing', 'hands-down', 'refund', 'fruitful', 'glorify', 'self-sufficiency', 'unfazed', 'dominates', 'helping', 'personalized', 'vouch', 'tremendously', 'fresh', 'trophy', 'versatile', 'clever', 'earnestly', 'enthuse', 'staunchly', 'beutifully', 'obsessions', 'preferes', 'reliable', 'eye-catching', 'scenic', 'delectable', 'assuring', 'motivated', 'razor-sharp', 'unselfish', 'restructuring', 'swankiest', 'cheapest', 'humourous', 'low-price', 'twinkly', 'cohesive', 'luminous', 'overjoyed', 'supurbly', 'law-abiding', 'merrily', 'ingeniously', 'luxurious', 'sumptuously', 'thoughtfully', 'comprehensive', 'flexible', 'versatility', 'lucky', 'gladness', 'innovation', 'mesmerizing', 'fantastically', 'warmhearted', 'enchant', 'elegantly', 'progressive', 'believeable', 'astonishing', 'smartly', 'steadiness', 'assuredly', 'guiltless', 'irresistible', 'successfully', 'issue-free', 'viewable', 'glowing', 'mesmerized', 'intimate', 'luster', 'fragrant', 'satisfies', 'refinement', 'remission', 'amazed', 'accolade', 'insightfully', 'zippy', 'lovely', 'charisma', 'proving', 'acclaimed', 'love', 'soft', 'fondness', 'usable', 'marvelously', 'spotless', 'reverence', 'quieter', 'quaint', 'deservedly', 'marveled', 'timely', 'stellar', 'correct', 'all-around', 'adventurous', 'feasibly', 'galore', 'exciting', 'wealthy', 'ingenious', 'hardy', 'restored', 'fascinate', 'distinction', 'sufficiently', 'exhilaration', 'upscale', 'proactive', 'time-honored', 'mighty', 'rich', 'zenith', 'variety', 'reconcile', 'inestimable', 'approve', 'easier', 'romantically', 'appreciatively', 'promises', 'futurestic', 'noteworthy', 'loveliness', 'reclaim', 'heartening', 'indulgence', 'wonderous', 'unbound', 'earnest', 'thoughtfulness', 'eulogize', 'brilliant', 'delicate', 'idol', 'lovable', 'saint', 'solace', 'beloved', 'freedoms', 'rightness', 'enthralled', 'civilize', 'excelent', 'equitable', 'fortitude', 'low-priced', 'commodious', 'dignified', 'chivalrous', 'kid-friendly', 'unreal', 'well-wishers', 'exceeding', 'ready', 'patriot', 'humour', 'surmount', 'speedily', 'distinctive', 'skillful', 'brainiest', 'gratified', 'retractable', 'infallibility', 'convincingly', 'titillate', 'effusion', 'easy-to-use', 'favored', 'incredibly', 'respect', 'securely', 'sufficient', 'attune', 'unaffected', 'painlessly', 'admirer', 'fond', 'inventive', 'appreciates', 'adroitly', 'trendy', 'convient', 'user-replaceable', 'romanticize', 'spontaneous', 'subsidize', 'defeat', 'woo', 'continuity', 'unbiased', 'ennoble', 'openness', 'silent', 'satisfying', 'fav', 'overture', 'well-bred', 'enjoyment', 'sprightly', 'desirable', 'ideal', 'harmonize', 'passionately', 'ingenuity', 'staunchness', 'rapid', 'fervent', 'tidy', 'fascinatingly', 'warmth', 'glorious', 'well-backlit', 'rightfully', 'improvements', 'steadfastness', 'revolutionized', 'accolades', 'ecstatic', 'catchy', 'feature-rich', 'profoundly', 'great', 'majestic', 'danke', 'promise', 'grace', 'fluent', 'faithful', 'terrific', 'undaunted', 'well-managed', 'truthfully', 'passionate', 'best-known', 'outperforms', 'exceptional', 'endorsing', 'dirt-cheap', 'admire', 'marvel', 'wowed', 'energy-saving', 'reliably', 'compactly', 'inviolable', 'flutter', 'invincible', 'togetherness', 'simplifying', 'fascinating', 'appropriate', 'first-class', 'amuse', 'accomplishment', 'satisified', 'enjoys', 'goodwill', 'endorses', 'ardently', 'tenacious', 'outstanding', 'pinnacle', 'praiseworthy', 'overtakes', 'amiability', 'endearing', 'fast-paced', 'multi-purpose', 'civility', 'colorful', 'prosperous', 'ilu', 'admirable', 'refreshed', 'dignify', 'stately', 'lucidly', 'correctly', 'encouraging', 'upliftingly', 'respite', 'faithfully', 'excitedly', 'sparkle', 'flatteringly', 'brave', 'consummate', 'impassioned', 'peacefully', 'vivid', 'deserving', 'prefer', 'panoramic', 'reverent', 'refreshing', 'supurb', 'well', 'evaluative', 'awards', 'opulent', 'rock-star', 'trusted', 'secure', 'straightforward', 'gratifyingly', 'glimmering', 'awarded', 'admiringly', 'adorer', 'seasoned', 'affable', 'better-known', 'sweetheart', 'winner', 'worth-while', 'sturdier', 'understandable', 'titillatingly', 'prospros', 'smoother', 'standout', 'trivially', 'mercy', 'formidable', 'enticed', 'softer', 'enlightenment', 'pain-free', 'adventuresome', 'defeated', 'decency', 'wellbeing', 'tender', 'gorgeously', 'sagely', 'illuminating', 'undisputed', 'marvellous', 'cleanly', 'accessible', 'altruistically', 'enjoying', 'headway', 'diligence', 'nicely', 'bright', 'satisfied', 'diligently', 'aver', 'lionhearted', 'sustainable', 'elate', 'bountiful', 'a+', 'rejoicing', 'richer', 'picturesque', 'reassure', 'regard', 'brilliantly', 'coherence', 'unquestionably', 'proper', 'cuteness', 'admirably', 'redeem', 'strikingly', 'monumental', 'uphold', 'heartwarming', 'complementary', 'inexpensive', 'light-hearted', 'tenaciously', 'gratifying', 'pluses', 'luck', 'graciously', 'adequate', 'smiling', 'interests', 'excitedness', 'beautify', 'eloquent', 'refresh', 'jollify', 'undisputable', 'productive', 'intelligent', 'recommendation', 'elan', 'foresight', 'prefers', 'neatly', 'comely', 'smoothes', 'unfettered', 'well-established', 'counter-attacks', 'extoll', 'sensations', 'counter-attack', 'reaffirmation', 'pampers', 'accomplish', 'obsession', 'tantalizingly', 'dreamland', 'affirm', 'striving', 'vouchsafe', 'reachable', 'smarter', 'wonderously', 'worth', 'immaculately', 'gaiety', 'luxury', 'glisten', 'astonish', 'plentiful', 'outstrip', 'laudable', 'reformed', 'wisdom', 'satisfactorily', 'originality', 'idolize', 'entertain', 'exultation', 'cleverly', 'gainful', 'meritorious', 'enviousness', 'tickle', 'inspire', 'defender', 'courageousness', 'gains', 'willingly', 'supremacy', 'fortuitous', 'genial', 'breathtaking', 'ecstasies', 'savings', 'succeeds', 'impressively', 'revel', 'intrigue', 'master', 'righten', 'eye-catch', 'bloom', 'thrifty', 'proud', 'sturdy', 'audible', 'subsidizes', 'eager', 'everlasting', 'rejoicingly', 'pep', 'sincerely', 'groundbreaking', 'aspiration', 'dauntless', 'endorsed', 'exhilaratingly', 'saver', 'sweetness', 'doubtless', 'prodigiously', 'merriness', 'enough', 'grin', 'bravery', 'exquisite', 'piety', 'significant', 'loyal', 'wows', 'venerate', 'alluring', 'capably', 'revival', 'smiles', 'miraculousness', 'considerate', 'heaven', 'compliant', 'hotcake', 'flawless', 'splendidly', 'exuberant', 'profusion', 'poeticize', 'awesomely', 'honor', 'poised', 'capable', 'perseverance', 'complemented', 'fun', 'hotcakes', 'glad', 'dexterous', 'honest', 'tenderly', 'audibly', 'glimmer', 'kudos', 'adorable', 'benevolence', 'reverently', 'defeating', 'jubilant', 'led', 'glory', 'unbeatable', 'savior', 'stylishly', 'masterpiece', 'verifiable', 'fair', 'masters', 'autonomous', 'evenly', 'clearer', 'extraordinarily', 'breakthroughs', 'virtuously', 'exceed', 'efficient', 'invulnerable', 'resourceful', 'adoring', 'wowing', 'survival', 'feasible', 'revere', 'achievable', 'long-lasting', 'cushy', 'bullish', 'monumentally', 'intriguingly', 'acumen', 'stronger', 'nice', 'immaculate', 'marvelousness', 'lead', 'cheery', 'agile', 'integral', 'impeccable', 'envy', 'enrapt', 'revolutionary', 'handily', 'fervidly', 'flashy', 'sexy', 'insightful', 'reasonably', 'premier', 'cheerful', 'grand', 'maturely', 'enviably', 'decent', 'effective', 'instructive', 'ecstatically', 'enthusiastically', 'ameliorate', 'fervor', 'convincing', 'rejoice', 'hot', 'splendor', 'compatible', 'freedom', 'entertains', 'dignity', 'indulgent', 'righteously', 'excites', 'radiance', 'elite', 'improving', 'affirmation', 'problem-free', 'spacious', 'inviolate', 'compassionate', 'luckiest', 'rapturous', 'thrills', 'well-connected', 'mightily', 'cure-all', 'courtly', 'fecilitous', 'exult', 'triumph', 'dawn', 'cornerstone', 'blameless', 'top-quality', 'better-than-expected', 'trustworthy', 'interesting', 'affordably', 'earnestness', 'gorgeous', 'amiabily', 'risk-free', 'pampered', 'vibrant', 'friendly', 'rapture', 'magic', 'excellently', 'fulfillment', 'jubilation', 'support', 'wondrous', 'godlike', 'witty', 'contentment', 'hooray', 'assure', 'pure', 'easy', 'adaptive', 'advocates', 'celebrate', 'righteousness', 'self-determination', 'roomy', 'worked', 'expansive', 'backbone', 'judicious', 'zest', 'credence', 'gentle', 'effectual', 'palatial', 'fortunate', 'soothingly', 'leading', 'slammin', 'cherished', 'tolerable', 'shimmering', 'diplomatic', 'renewed', 'happy', 'exceptionally', 'luxuriant', 'simpler', 'bravo', 'meticulous', 'swank', 'ovation', 'exceled', 'pamperedness', 'compassion', 'flexibility', 'sweet', 'easiness', 'dexterously', 'undamaged', 'examplar', 'eloquently', 'loving', 'high-spirited', 'outperformed', 'skilled', 'distinguished', 'exhilarating', 'gaily', 'revive', 'laudably', 'heros', 'nurturing', 'delighted', 'bonny', 'sensible', 'simplify', 'consistent', 'educated', 'merry', 'titillating', 'unencumbered', 'relief', 'mature', 'problem-solver', 'rightly', 'innocuous', 'enrich', 'shine', 'skillfully', 'glow', 'attraction', 'complements', 'integrated', 'amity', 'astonished', 'richness', 'wow', 'exquisitely', 'enthrall', 'propitious', 'credible', 'profound', 'pre-eminent', 'resplendent', 'angelic', 'gems', 'proficiently', 'improved', 'lovably', 'masterpieces', 'dazzled', 'empowerment', 'amply', 'compliment', 'luckier', 'agreeableness', 'spellbinding', 'ebullient', 'soundness', 'greatest', 'fine-looking', 'gumption', 'punctual', 'congratulate', 'entrancing', 'proven', 'enviable', 'gentlest', 'desirous', 'devout', 'upbeat', 'permissible', 'wholeheartedly', 'nobly', 'hug', 'confidence', 'delightfully', 'exalt', 'nifty', 'prosper', 'harmonious', 'spellbindingly', 'smart', 'eyecatch', 'enjoyable', 'tenacity', 'orderly', 'unconditional', 'fave', 'dependably', 'perfectly', 'humility', 'holy', 'avidly', 'freshest', 'empathy', 'illustrious', 'generously', 'amicably', 'hilarious', 'ingenuous', 'regal', 'respectful', 'sweeping', 'qualified', 'unrivaled', 'feisty', 'smilingly', 'manageable', 'precisely', 'convience', 'easiest', 'maturity', 'industrious', 'jubilantly', 'wonder', 'halcyon', 'peaceable', 'popular', 'facilitate', 'well-received', 'strong', 'enliven', 'outsmart', 'praise', 'worthwhile', 'slick', 'awestruck', 'posh', 'well-regarded', 'excitement', 'luckiness', 'zeal', 'thumb-up', 'sumptuousness', 'amicability', 'overtake', 'joyful', 'impartial', 'cozy', 'flawlessly', 'blossom', 'heavenly', 'rock-stars', 'spellbind', 'amenity', 'entrust', 'energetic', 'examplary', 'swiftness', 'humor', 'well-made', 'enthusiasm', 'pardon', 'logical', 'state-of-the-art', 'important', 'non-violence', 'solidarity', 'meticulously', 'capability', 'stellarly', 'defeats', 'elevate', 'sagacity', 'impeccably', 'talent', 'noiseless', 'brilliances', 'inpressed', 'endear', 'unrestricted', 'justly', 'favour', 'empathize', 'lavishly', 'fairness', 'harmony', 'prominence', 'superiority', 'thoughtful', 'supreme', 'cherish', 'well-educated', 'paramount', 'powerfully', 'advocate', 'jaw-dropping', 'god-send', 'statuesque', 'elated', 'champion', 'dummy-proof', 'irreproachable', 'optimism', 'intelligible', 'tantalize', 'futuristic', 'treasure', 'breeze', 'rectifying', 'rejuvenated', 'courageous', 'low-cost', 'recovery', 'gallant', 'prompt', 'coolest', 'work', 'gem', 'momentous', 'delicacy', 'magnificence', 'better', 'thank', 'record-setting', 'indebted', 'extraordinary', 'trumpet', 'faster', 'recommendations', 'protective', 'well-positioned', 'invincibility', 'rewarding', 'suave', 'invigorate', 'diligent', 'productively', 'shimmeringly', 'invigorating', 'uplifting', 'reward', 'flourishing', 'brand-new', 'comfy', 'supports', 'heroic', 'frugal', 'adored', 'dumbfounding', 'talented', 'self-respect', 'protection', 'stimulating', 'congenial', 'impressed', 'glitz', 'trust', 'renaissance', 'positively', 'intelligence', 'joyously', 'likes', 'outdo', 'well-intentioned', 'magnanimously', 'deginified', 'delicious', 'ergonomical', 'peach', 'virtue', 'genuine', 'advocated', 'festive', 'ideally', 'passion', 'surpass', 'spellbound', 'unabashedly', 'intuitive', 'protect', 'amusing', 'astutely', 'leads', 'acclamation', 'gush', 'snappy', 'winning', 'fancinating', 'diversified', 'revolutionizes', 'good', 'valiantly', 'resounding', 'benefits', 'recommend', 'conciliatory', 'revelation', 'tougher', 'geeky', 'infallible', 'promptly', 'steadfastly', 'excel', 'valiant', 'triumphal', 'upgradable', 'plush', 'fast-growing', 'outperforming', 'liked', 'conveniently', 'eminent', 'trustingly', 'gracious', 'resourcefulness', 'keenness', 'authentic', 'poise', 'hottest', 'constructive', 'divine', 'crisper', 'enlighten', 'benefit', 'gloriously', 'recomend', 'gleefully', 'spectacular', 'successes', 'restful', 'patience', 'trustworthiness', 'enthral', 'preferring', 'clearly', 'concise', 'buoyant', 'affection', 'gratefully', 'steadfast', 'reaffirm', 'savvy', 'fabulously', 'happily', 'outwit', 'unmatched', 'recommended', 'unequivocally', 'contrasty', 'compact', 'eases', 'endorsement', 'felicity', 'veritable', 'reforming', 'prudently', 'willingness', 'nicest', 'commendably', 'amiable', 'purify', 'impressive', 'reputation', 'wonders', 'worthy', 'complimentary', 'fascination', 'whoooa', 'oasis', 'refined', 'cost-effective', 'enjoyably', 'wisely', 'cooperatively', 'happiness', 'effusively', 'rejuvenating', 'merit', 'achievible', 'amazement', 'affectation', 'suffice', 'reforms', 'novelty', 'effusiveness', 'rational', 'generosity', 'improvement', 'hardier', 'firmer', 'propitiously', 'righteous', 'transparent', 'beneficially', 'sweetly', 'skill', 'efficiently', 'loved', 'saintliness', 'trusting', 'enhanced', 'comforting', 'sociable', 'steady', 'eagerness', 'first-in-class', 'faithfulness', 'outshone', 'exultant', 'breathtakingly', 'beneficiary', 'stupendously', 'portable', 'praising', 'relaxed', 'snazzy', 'flatter', 'dominate', 'encouragingly', 'suitable', 'ecstasy', 'playfully', 'fidelity', 'fancy', 'genius', 'restructure', 'mind-blowing', 'cost-saving', 'exellent', 'agreeable', 'powerful', 'enraptured', 'whoa', 'obtainable', 'courage', 'afordable', 'instantly', 'smartest', 'encourage', 'talents', 'loves', 'prolific', 'user-friendly', 'playful', 'clears', 'enjoy', 'quicker', 'solid', 'polite', 'easing', 'ultra-crisp', 'excited', 'chaste', 'upliftment', 'precise', 'readily', 'solicitous', 'homage', 'fans', 'loyalty', 'divinely', 'effusive', 'benifits', 'thrive', 'excellent', 'invaluable', 'outdone', 'well-known', 'pepped', 'meaningful', 'reasoned', 'aspirations', 'persevere', 'brightest', 'truthfulness', 'liberation', 'abundant', 'admiring', 'best-performing', 'cleanliness', 'exalted', 'promised', 'stirringly', 'agility', 'accommodative', 'applaud', 'ambitious', 'successful', 'useful', 'ecenomical', 'comfort', 'lustrous', 'commend', 'glitter', 'principled', 'excite', 'lucrative', 'astonishment', 'rockstar', 'fantastic', 'accurately', 'tingle', 'attractively', 'destiny', 'promoter', 'cherub', 'pleasingly', 'best-selling', 'morality', 'hospitable', 'warmer', 'awesome', 'daring', 'nimble', 'peacekeepers', 'gain', 'breakthrough', 'gratify', 'awe', 'favorited', 'wins', 'godsend', 'appreciate', 'brainy', 'tempting', 'convienient', 'feat', 'rectify', 'convenient', 'striking', 'fondly', 'idolized', 'bargain', 'calmness', 'upheld', 'dotingly', 'excellency', 'first-rate', 'nourishing', 'illuminate', 'miracle', 'pleasing', 'unabashed', 'resilient', 'stimulative', 'hallowed', 'outperform', 'peerless', 'raptureous', 'hopeful', 'desiring', 'appreciated', 'attractive', 'happier', 'gifted', 'avid', 'congratulation', 'steadiest', 'excellence', 'liking', 'lively', 'sumptuous', 'enterprising', 'supportive', 'smoothest', 'navigable', 'pamperedly', 'smile', 'tempt', 'edify', 'victory', 'perfection', 'heartfelt', 'imaculate', 'low-risk', 'heroically', 'peace', 'whooa', 'thrill', 'rewardingly', 'engrossing', 'cajole', 'knowledgeable', 'suavely', 'heal', 'prowess', 'mesmerizes', 'gainfully', 'fervid', 'succeed', 'strongest', 'excellant', 'rightful', 'ardent', 'gold', 'adjustable', 'remarkably', 'willing', 'thinner', 'swankier', 'cheer', 'stupendous', 'peaceful', 'glistening', 'sleek', 'succes', 'modesty', 'fiery', 'preferable', 'commendable', 'accurate', 'alluringly', 'harmoniously', 'goodly', 'achievements', 'receptive', 'dependable', 'authoritative', 'illuminati', 'exuberantly', 'notably', 'soundly', 'romantic', 'favorable', 'reasonable', 'raptureously', 'charming', 'stabilize', 'handsome', 'matchless', 'preeminent', 'ease', 'pleasure', 'relent', 'prestigious', 'simplest', 'effortlessly', 'resound', 'irresistibly', 'responsive', 'astonishingly', 'victorious', 'fine', 'enthusiastic', 'conciliate', 'pleasurably', 'comfortably', 'deft', 'sensation', 'electrify', 'staunch', 'openly', 'healthful', 'optimistic', 'famed', 'brotherly', 'realistic', 'glee', 'right', 'impartially', 'neatest', 'enjoyed', 'fresher', 'temptingly', 'jubilate', 'pleases', 'beckon', 'swift', 'robust', 'sufficed', 'elegant', 'windfall', 'euphorically', 'remarkable', 'well-rounded', 'keenly', 'adulation', 'favor', 'altruistic', 'ebullience', 'redeeming', 'agilely', 'patriotic', 'impress', 'reconciliation', 'warm', 'masterfully', 'tranquility', 'generous', 'reassurance', 'delightfulness', 'invaluablely', 'lush', 'easygoing', 'magnanimous', 'well-informed', 'aspire', 'heroine', 'congratulatory', 'recover', 'clear-cut', 'beautifully', 'impressiveness', 'wieldy', 'workable', 'eloquence', 'unlimited', 'outshine', 'effortless', 'miraculously', 'grandeur', 'astounded', 'illumine', 'abounds', 'trusty', 'spiritual', 'pleased', 'qualify', 'pretty', 'greatness', 'pleasant', 'safe', 'serenity', 'subsidizing', 'golden', 'guidance', 'supported', 'mesmerizingly', 'legendary', 'stability', 'lean', 'relish', 'helpful', 'splendid', 'danken', 'agreeably', 'hallmarks', 'finer', 'conscientious', 'memorable', 'abundance', 'well-mannered', 'exonerate', 'convenience', 'marvelled', 'intimacy', 'vigilant', 'cooperative', 'accessable', 'patient', 'poetic', 'survivor', 'self-satisfaction', 'sporty', 'radiant', 'rockstars', 'satisfy', 'selective', 'ardor', 'fearlessly', 'straighten', 'frolic', 'pleasurable', 'breathlessness', 'supporter', 'delightful', 'gained', 'charm', 'embolden', 'levity', 'remedy', 'simplified', 'enrichment', 'dead-cheap', 'complement', 'positives', 'amazes', 'celebratory', 'useable', 'jubiliant', 'miracles', 'comfortable', 'progress', 'affordable', 'enhance', 'sublime', 'quiet', 'uncomplicated', 'exceeds', 'cleaner', 'nourishment', 'bolster', 'cool', 'gratification', 'beneficial', 'affinity', 'enticingly', 'creative', 'welcome', 'cashbacks', 'captivate', 'brighten', 'outstandingly', 'lawful', 'laud', 'remunerate', 'ftw', 'mastery', 'unequivocal', 'prosperity', 'hero', 'modern', 'suffices', 'handy', 'realizable', 'finest', 'properly', 'affluence', 'gallantly', 'amusingly', 'humane', 'celebrated', 'saintly', 'fastest-growing', 'dead-on', 'proves', 'adore', 'humorous', 'beckoned', 'pleasantly', 'boost', 'stylized', 'magical', 'vivacious', 'accomodative', 'rapturously', 'kindly', 'accomplishments', 'chivalry', 'impartiality', 'cute', 'expeditiously', 'vigilance', 'marvels', 'miraculous', 'humble', 'bonus', 'fervently', 'competitive', 'idyllic', 'economical', 'god-given', 'booming', 'top-notch', 'precious', 'exaltedly', 'brilliance', 'gutsy', 'graciousness', 'auspicious', 'incredible', 'prudence', 'winners', 'covenant', 'helped', 'joyous', 'surreal', 'eagerly', 'evocative', 'seamless', 'dazzle', 'thankful', 'neat', 'regally', 'blissfully', 'sharpest', 'stimulates', 'improve', 'dumbfounded', 'thrilled', 'fashionably', 'fabulous', 'heroize', 'dextrous', 'reform', 'available', 'balanced', 'valor', 'lyrical', 'undisputably', 'sophisticated', 'ethical', 'overtook', 'intriguing', 'lawfully', 'classic', 'erudite', 'prefered', 'merriment', 'classy', 'exaltingly', 'benefactor', 'blissful', 'captivating', 'award', 'effectiveness', 'foremost', 'maneuverable', 'trump', 'sparkling', 'unparalleled', 'salutary', 'champ', 'gaining', 'gleeful', 'expertly', 'revives', 'tranquil', 'winnable', 'congratulations', 'amaze', 'liberate', 'irreplaceable', 'personages', 'affability', 'darling', 'hail', 'exemplar', 'tops', 'superbly', 'magnificently', 'goood', 'abound', 'endorse', 'revolutionize', 'sincerity', 'well-behaved', 'innovative', 'nourish', 'inestimably', 'renowned', 'commitment', 'truthful', 'like', 'toll-free', 'bliss', 'thumbs-up', 'honored', 'virtuous', 'superior', 'advantage', 'reputable', 'thrift', 'sharper', 'vibrantly', 'advantageously', 'decisiveness', 'privilege', 'consistently', 'proficient', 'freed', 'excelled', 'enhancement', 'inspiring', 'prodigious', 'calming', 'glowingly', 'shiny', 'visionary', 'jolly', 'refine', 'world-famous', 'dynamic', 'prudent', 'overtaking', 'priceless', 'peppy', 'salute', 'clear', 'daringly', 'unwavering', 'celebration', 'prize', 'affluent', 'appreciable', 'eyecatching', 'inspirational', 'youthful', 'promising', 'wonderfully', 'jaw-droping', 'enchantingly', 'streamlined', 'faith', 'eased', 'adulatory', 'exalting', 'supple', 'paradise', 'substantive', 'brighter', 'fertile', 'elatedly', 'delight', 'painless', 'exemplary', 'subsidized', 'revitalize', 'leverage', 'majesty', 'renown', 'hallmark', 'prodigy', 'speedy', 'confident', 'spectacularly', 'assurances', 'handier', 'responsibly', 'superb', 'nicer', 'positive', 'luxuriously', 'polished', 'thrilling', 'stylish', 'privileged', 'graceful', 'safely', 'works', 'fortune', 'enchanted', 'benevolent', 'pepping', 'wise', 'adulate', 'well-being', 'extol', 'affirmative', 'famously', 'excallent', 'masterful', 'empower', 'entertaining', 'well-run', 'fanfare', 'affably', 'fearless', 'brisk', 'intricate', 'peps', 'win', 'dominated', 'fortuitously', 'cheaper', 'coherent', 'crisp', 'assurance', 'soothe', 'toughest', 'handsomely', 'prestige', 'won', 'pamper', 'wholesome', 'rejuvenate', 'amenable', 'sensational', 'stunning', 'adroit', 'free', 'ample', 'gratitude', 'harmless', 'thriving', 'energize', 'beautiful', 'exceeded', 'amazing', 'stunningly', 'honoring', 'beauteous', 'stable', 'satisfactory', 'yay', 'worthiness', 'serene', 'glamorous', 'merciful', 'felicitate', 'best', 'lighter', 'advanced', 'mesmerize', 'profuse', 'geekier', 'traction', 'hard-working', 'carefree', 'cleanest', 'euphoria', 'humorously', 'detachable', 'simplifies', 'grateful', 'sincere', 'blessing', 'infallibly', 'triumphantly', 'articulate', 'encouragement', 'triumphant', 'angel', 'elation', 'charmingly', 'acclaim', 'goodness', 'immense', 'lifesaver', 'roomier', 'stimulate', 'lavish', 'clean', 'awed', 'perfect', 'modest', 'charitable', 'astoundingly', 'entranced', 'joyfully', 'solicitously', 'dedicated', 'unforgettable', 'calm', 'cohere', 'cleared', 'astounding', 'dazzling', 'advantageous', 'amicable', 'phenomenally', 'excels', 'amazingly', 'fancier', 'mercifully', 'admiration', 'enhances', 'gusto', 'excitingly', 'deference', 'prettily', 'enthusiast', 'restructured', 'politeness', 'felicitous', 'ambitiously', 'awsome', 'providence', 'boundless', 'patiently', 'honorable', 'idealize', 'soulful', 'adoringly', 'ingenuously', 'upgradeable', 'improves', 'kindliness', 'blithe', 'fastest', 'boom', 'valuable', 'energy-efficient', 'thrillingly', 'kindness', 'beautifullly', 'heartily', 'instrumental', 'jovial', 'rapport', 'sharp', 'stunned', 'swanky', 'adaptable', 'envious', 'warmly', 'favorite', 'cashback', 'phenomenal', 'bless', 'smooth', 'top', 'gladden', 'sensationally', 'sustainability', 'luxuriate', 'guarantee', 'beneficent', 'astound', 'decisive', 'efficacious', 'pride', 'achievement', 'beckoning', 'hale', 'individualized', 'durable', 'optimal', 'exceedingly', 'magnificent', 'resolute', 'eminence', 'elegance', 'self-sufficient', 'apotheosis', 'redemption', 'poignant', 'stainless', 'fame', 'clarity', 'lover', 'noble', 'supporting', 'success', 'succeeding', 'gooood', 'flourish', 'high-quality', 'eventful', 'joy', 'charismatic', 'impresses', 'healthy', 'sensitive', 'keen', 'beauty', 'tantalizing', 'gratifies'}\n",
            "\n",
            "Negative words\n",
            "{'morbidly', 'mysteriously', 'hairloss', 'disaffected', 'rape', 'sardonically', 'discountenance', 'asininely', 'cave', 'hypocricy', 'revile', 'sueing', 'improbably', 'worriedly', 'backaching', 'lame', 'incognizant', 'delusional', 'mangling', 'hapless', 'usurper', 'irascible', 'indecent', 'gibber', 'mangles', 'ruffle', 'iniquity', 'injure', 'profane', 'repetitive', 'blur', 'wild', 'chagrin', 'lame-duck', 'itch', 'misbegotten', 'devious', 'fabrication', 'malign', 'shadowy', 'diatribe', 'stressfully', 'indeterminate', 'fib', 'melodramatic', 'counter-productive', 'thwart', 'deform', 'ingratitude', 'plight', 'dejectedly', 'irretating', 'inability', 'shrilly', 'excoriate', 'lecher', 'unwelcome', 'toil', 'inadequate', 'frozen', 'slogging', 'strike', 'harsh', 'vagrant', 'detracting', 'agony', 'escapade', 'ironical', 'absentee', 'louder', 'smokescreen', 'incredulous', 'poorer', 'avariciously', 'allege', 'sin', 'crept', 'glaringly', 'rifts', 'scowl', 'grievance', 'sneaky', 'impossible', 'impatiently', 'bull****', 'imprudent', 'inteferes', 'bulkiness', 'defects', 'burdensomely', 'irritant', 'rusty', 'hazardous', 'hardened', 'direness', 'emptiness', 'forbid', 'crippled', 'vague', 'ill-formed', 'untruthful', 'inconsistence', 'discontentedly', 'second-class', 'inexcusable', 'boring', 'clunky', 'ill-mannered', 'impractical', 'trample', 'fanaticism', 'begging', 'humiliate', 'dissatisfied', 'aspersions', 'enslave', 'corruptted', 'tangles', 'aches', 'hastily', 'sloppy', 'engulf', 'curses', 'revengefully', 'rut', 'disprove', 'eccentric', 'cruelty', 'alienated', 'haunting', 'shock', 'fluster', 'dilapidated', 'discontinued', 'hostile', 'cripples', 'nervously', 'ordeal', 'concession', 'stingingly', 'oddly', 'declaim', 'inadverent', 'scratches', 'inveigle', 'unnerved', 'falling', 'uncaring', 'imprisonment', 'inimically', 'bastard', 'scornful', 'deceitful', 'bizarre', 'sidetrack', 'bumps', 'extravagantly', 'sardonic', 'defiler', 'retract', 'scandel', 'grudge', 'appal', 'plunder', 'swelled', 'troublesome', 'ashamed', 'disapointing', 'insane', 'unruly', 'repugnant', 'squander', 'egocentric', 'implacable', 'bearish', 'headaches', 'inextricable', 'pretentiously', 'harms', 'insinuating', 'filthy', 'wrongful', 'enviously', 'obsess', 'brat', 'nefarious', 'incompliant', 'dubiously', 'arrogant', 'erase', 'offensiveness', 'condescendingly', 'fearful', 'sneering', 'fickle', 'disapproval', 'conflict', 'bereft', 'impudent', 'disgruntled', 'droops', 'downbeat', 'grisly', 'murky', 'impurity', 'notorious', 'smoldering', 'overlook', 'deterrent', 'incompatible', 'incomplete', 'displeasure', 'dearth', 'jagged', 'debaser', 'dissappointed', 'impotent', 'subjugation', 'vanity', 'noises', 'inconveniently', 'terror-genic', 'debts', 'myth', 'wail', 'resurgent', 'glut', 'chaotic', 'perfidity', 'annihilation', 'pandering', 'delinquency', 'drunken', 'sedentary', 'top-heavy', 'hiss', 'picketed', 'flicering', 'lurid', 'matte', 'unlawfully', 'fevers', 'undersized', 'devastation', 'irksomely', 'impedance', 'inane', 'disorderly', 'incapable', 'ulterior', 'villainous', 'ambivalent', 'undefined', 'annoyances', 'semi-retarded', 'bullying', 'hating', 'ripped', 'awkward', 'tetchily', 'dies', 'baffled', 'culpable', 'disconsolation', 'chafe', 'recant', 'undermine', 'bloodthirsty', 'vicious', 'smelt', 'outrageously', 'meanness', 'hates', 'bum', 'pitiless', 'stressful', 'desiccated', 'sully', 'acerbically', 'condescend', 'perilous', 'spew', 'compulsion', 'stench', 'inhuman', 'juddering', 'licentiously', 'presumptuously', 'jaundiced', 'hype', 'clouding', 'disturbingly', 'pretend', 'disadvantageous', 'deficient', 'buggy', 'kill', 'aggressor', 'immoderately', 'hum', 'feckless', 'jaded', 'huckster', 'fudge', 'gainsayer', 'sagged', 'obsessive', 'hater', 'jarring', 'satirical', 'hangs', 'inconvenience', 'absence', 'extravagant', 'decay', 'hoax', 'decayed', 'propagandize', 'invidiousness', 'intimidating', 'overbalanced', 'stupidly', 'faithless', 'peevishly', 'childish', 'chore', 'flaunt', 'hysterical', 'befoul', 'timid', 'disorganized', 'wobble', 'kooky', 'lies', 'gabble', 'friggin', 'zap', 'stains', 'stifling', 'obscenely', 'uglier', 'overreach', 'fatigue', 'rebuke', 'incorrectly', 'dismal', 'inadvisable', 'provocation', 'macabre', 'castrated', 'strife', 'horrifys', 'earsplitting', 'intrude', 'craziness', 'guilt', 'pointlessly', 'ugly', 'vomited', 'waste', 'tangle', 'dwindling', 'killed', 'stingy', 'gloom', 'drag', 'disunity', 'impugn', 'controversial', 'distraction', 'dissonant', 'blasphemy', 'dishonesty', 'opponent', 'overthrows', 'retarded', 'spoon-fed', 'plot', 'unfit', 'burden', 'secretive', 'ironically', 'delayed', 'aggravate', 'distorted', 'allegation', 'extravagance', 'wastefulness', 'inhibit', 'lecherous', 'insociable', 'incorrigible', 'irregularity', 'so-cal', 'sour', 'panicky', 'pugnacity', 'two-faces', 'unwarranted', 'volatility', 'fumble', 'exclusion', 'refuting', 'fuss', 'stupify', 'intransigence', 'senseless', 'illusory', 'stale', 'un-viewable', 'destructive', 'chintzy', 'confusions', 'unfriendly', 'frightful', 'washed-out', 'thirst', 'lesser-known', 'nauseates', 'outrage', 'skinny', 'barbarity', 'interfere', 'excessively', 'overpriced', 'sourly', 'detraction', 'fright', 'forgetful', 'forgetfully', 'insular', 'latency', 'despondent', 'mistakenly', 'halfhearted', 'prate', 'snobbish', 'conspicuous', 'distress', 'sore', 'transgress', 'dissenter', 'loathsome', 'prevaricate', 'unfavorable', 'paradoxical', 'hysterics', 'lascivious', 'poison', 'misbecome', 'ripoff', 'soreness', 'despicable', 'squirm', 'derisive', 'stuttered', 'unorthodoxy', 'persecute', 'lunatic', 'wasteful', 'toughness', 'unresponsive', 'callous', 'extortion', 'butchery', 'haughty', 'oversimplified', 'flat-out', 'relentlessness', 'stupor', 'risks', 'whine', 'untrustworthy', 'expulse', 'obliterated', 'long-time', 'foolishness', 'naughty', 'fail', 'enemies', 'incite', 'bedlam', 'bug', 'afraid', 'malicious', 'invasive', 'inequities', 'irrecoverably', 'malice', 'noise', 'ragged', 'dissidence', 'unmoved', 'vibrated', 'dizzingly', 'worthlessness', 'chatterbox', 'hurting', 'dropout', 'cumbersome', 'outraged', 'menacingly', 'desiccate', 'hatefully', 'scathingly', 'scams', 'quash', 'retaliate', 'impaired', 'uncertain', 'uprising', 'wickedly', 'dizzing', 'death', 'frown', 'imbroglio', 'ill-used', 'revulsive', 'deter', 'bashful', 'blandish', 'harasses', 'sags', 'avarice', 'devil', 'denunciation', 'dilemma', 'disgrace', 'disruption', 'exagerated', 'languorously', 'lowly', 'miseries', 'scarcity', 'parasite', 'stubborn', 'tacky', 'thankless', 'belabor', 'taunting', 'siege', 'farfetched', 'hysterically', 'irresponsibly', 'madness', 'peevish', 'muddy', 'peeve', 'indecorum', 'poky', 'virus', 'boredom', 'harassed', 'pitifully', 'dishonor', 'vileness', 'tingled', 'cartoonish', 'awkwardness', 'contortions', 'disappointed', 'chide', 'glib', 'bane', 'emasculate', 'inadequacy', 'reluctant', 'negligence', 'crack', 'succumb', 'blotchy', 'jeering', 'prohibitive', 'agonizingly', 'unattractive', 'scratchy', 'selfishness', 'delaying', 'sunder', 'radicalization', 'slashing', 'biting', 'stalemate', 'vociferously', 'graft', 'offending', 'invidiously', 'pretense', 'shortcomings', 'paltry', 'contempt', 'degenerate', 'quarrelsome', 'depraved', 'pervasive', 'agonies', 'fraud', 'dissonantly', 'insolvent', 'resentful', 'discredit', 'misinterpret', 'bust', 'frazzled', 'nervousness', 'sever', 'balk', 'commonplace', 'ail', 'pervert', 'infection', 'detests', 'shortsighted', 'misbehave', 'facetiously', 'prickle', 'layoff', 'exasperating', 'spoilled', 'misrepresentation', 'grouch', 'disoobedient', 'forged', 'perplex', 'ruthlessness', 'debilitate', 'enmity', 'explode', 'dissappointing', 'grumpiest', 'imperfection', 'dented', 'shiver', 'unskilled', 'fat-cats', 'wrinkle', 'jealousy', 'misguidance', 'puzzling', 'unpopular', 'unsettling', 'inexperienced', 'inconsiderately', 'invective', 'smoulder', 'corrupts', 'craven', 'sceptical', 'choppy', 'disconcert', 'dejection', 'foul', 'straining', 'upbraid', 'corruption', 'ding', 'gaff', 'awful', 'paranoia', 'unthinkable', 'polluter', 'cuss', 'impoverished', 'deplorably', 'blurs', 'confuse', 'cowardly', 'gibe', 'hardship', 'frustrating', 'disappoint', 'aching', 'altercation', 'cold', 'blunder', 'instigate', 'intermittent', 'thicker', 'flareup', 'imbecile', 'snag', 'debauch', 'difficulties', 'hopeless', 'deluge', 'expired', 'glibly', 'stresses', 'ugh', 'awfulness', 'indigent', 'jam', 'throbs', 'prejudge', 'blab', 'disgracefully', 'confounding', 'insecure', 'insult', 'shroud', 'suffers', 'tamper', 'frustration', 'notoriously', 'dehumanize', 'deject', 'pokey', 'blame', 'apologists', 'unsuccessful', 'disdained', 'betrayals', 'undissolved', 'desolation', 'embroilment', 'unusual', 'jitter', 'breakup', 'worries', 'musty', 'abysmally', 'counterproductive', 'violator', 'rumors', 'leer', 'rabid', 'doomed', 'malaise', 'pompous', 'stranger', 'detracted', 'crude', 'chilly', 'outrageous', 'wrest', 'futile', 'menacing', 'smut', 'immorally', 'mocked', 'gimmick', 'ached', 'suffered', 'tarnish', 'bugging', 'villianously', 'scarily', 'forgetfulness', 'indoctrinate', 'vindictively', 'eschew', 'leery', 'offence', 'eruptions', 'drastic', 'suicidal', 'unsophisticated', 'hoard', 'alienation', 'poorest', 'sucked', 'neglect', 'frantic', 'sloth', 'trickery', 'polution', 'wrip', 'arduous', 'sufferer', 'unfortunate', 'misuse', 'infidels', 'stump', 'absent-minded', 'murderously', 'redundant', 'laggy', 'hurted', 'ominous', 'stiflingly', 'darkened', 'capsize', 'grate', 'bastards', 'rigidness', 'anarchist', 'amputate', 'erode', 'procrastination', 'rampage', 'ignorant', 'capriciousness', 'treason', 'defiance', 'paucity', 'sinking', 'hegemonistic', 'forbidding', 'marginally', 'diatribes', 'torturously', 'muddle', 'rough', 'sagging', 'disconsolately', 'dire', 'adversity', 'disillusioned', 'gruff', 'symptom', 'lorn', 'malodorous', 'falsely', 'traduce', 'disgusting', 'plague', 'heartbreaking', 'melodramatically', 'resignation', 'vindictive', 'anarchistic', 'fanatics', 'overpaid', 'threaten', 'betrayal', 'infected', 'shake', 'dilly-dally', 'nervous', 'regression', 'decry', 'gawky', 'warped', 'strict', 'unspeakable', 'carp', 'fatty', 'beseech', 'mudslinger', 'avaricious', 'inexpertly', 'despondently', 'demoralize', 'runaway', 'warp', 'brutalizing', 'concerns', 'frightening', 'clique', 'vex', 'struck', 'viciousness', 'aggression', 'disbeliever', 'exaggerate', 'expire', 'cheesy', 'racism', 'cataclysmically', 'adulterier', 'corrupt', 'lost', 'bumpy', 'derision', 'rremediable', 'travesties', 'wretch', 'grumpier', 'indecency', 'lunaticism', 'delusion', 'disagrees', 'jealousness', 'controversy', 'heckles', 'wane', 'shocking', 'occlude', 'flakey', 'interference', 'cramp', 'nave', 'inept', 'slothful', 'whiny', 'trap', 'deceit', 'dawdle', 'contamination', 'dimmer', 'inhumanity', 'maddening', 'messed', 'extremism', 'overwhelms', 'savage', 'gutter', 'scariest', 'slumpping', 'starve', 'unacceptably', 'spookier', 'treacherous', 'incompatibility', 'reprehensibly', 'slowly', 'impenitent', 'infested', 'spank', 'suppression', 'indeterminably', 'hassles', 'livid', 'intolerance', 'unaccustomed', 'hotheaded', 'disingenuous', 'inhumane', 'blind', 'demoralizingly', 'fooled', 'despicably', 'nemesis', 'disgustedly', 'inglorious', 'torment', 'atrocious', 'incorrect', 'maniac', 'busybody', 'f**k', 'touted', 'dispirited', 'inflated', 'dim', 'panicking', 'scary', 'appalled', 'wilt', 'outsider', 'malevolently', 'apprehensively', 'plotters', 'downgrade', 'silly', 'abomination', 'rumbling', 'incessantly', 'ridicule', 'indignant', 'devilment', 'prohibitively', 'creak', 'douchebags', 'improperly', 'incoherence', 'insignificance', 'skepticism', 'lapsed', 'uneconomical', 'vilify', 'dusty', 'hegemonism', 'fundamentalism', 'flagging', 'flickers', 'troublemaker', 'absurdly', 'discord', 'remorselessness', 'lewdly', 'splatter', 'confessions', 'wariness', 'hardships', 'ire', 'ghetto', 'taboo', 'immodest', 'infamous', 'cuplrit', 'violators', 'bewilder', 'burdensome', 'standstill', 'fiction', 'tenderness', 'tragically', 'overloaded', 'stagnate', 'bothers', 'disreputable', 'bitterness', 'interferes', 'cheating', 'revolt', 'damnably', 'dismally', 'junkyard', 'impinge', 'radically', 'dud', 'comical', 'dissatisfying', 'forswear', 'dirtbag', 'hard-liner', 'animosity', 'demonizing', 'traumatize', 'lukewarm', 'askance', 'contemptible', 'improbability', 'patronize', 'smudges', 'acrid', 'anti-israeli', 'outbreak', 'egregious', 'steep', 'besmirch', 'displeased', 'ill-advised', 'upsetting', 'vomiting', 'concede', 'draconic', 'polarisation', 'villian', 'upset', 'hinder', 'murder', 'ultra-hardline', 'vent', 'imposition', 'irrecoverable', 'disrespectfully', 'dying', 'lie', 'slaughtered', 'trapped', 'smudging', 'dizzy', 'deny', 'intolerablely', 'unhealthy', 'wary', 'wicked', 'spotty', 'dead', 'scummy', 'dent', 'fracture', 'ineffectual', 'unhappy', 'anti-occupation', 'dumbfound', 'inequitably', 'fraught', 'ridicules', 'slanders', 'distrustful', 'imaginary', 'incomparable', 'polemize', 'imprudence', 'demonize', 'wretched', 'tin-y', 'tension', 'bogus', 'entrap', 'steals', 'stern', 'insinuation', 'rogue', 'trivialize', 'mischievously', 'ineffectively', 'hell-bent', 'strangely', 'addicted', 'messing', 'rattled', 'stole', 'skeletons', 'indoctrination', 'misfit', 'pillage', 'boiling', 'shirk', 'wildly', 'contrariness', 'handicapped', 'frost', 'unable', 'crueler', 'dirty', 'apologist', 'dubious', 'darker', 'cheats', 'hang', 'poor', 'delude', 'racist', 'demeaning', 'flabbergast', 'steeply', 'fears', 'impersonal', 'dissuasive', 'quibble', 'underpaid', 'unkind', 'dishearten', 'blameworthy', 'spiritless', 'wrestle', 'halfheartedly', 'fatally', 'shame', 'beguile', 'destabilisation', 'monster', 'denial', 'set-up', 'scaly', 'unravel', 'joke', 'distorts', 'inconstant', 'zealous', 'bother', 'debauchery', 'disillusion', 'strained', 'monotony', 'scolding', 'unwilling', 'odor', 'impudently', 'inefficiently', 'smudge', 'ill-usage', 'warning', 'waning', 'overbalance', 'cliched', 'screw-up', 'mistified', 'apathetically', 'bereave', 'penalty', 'spookily', 'curt', 'moan', '2-faces', 'conspicuously', 'dispute', 'pollute', 'conspiracies', 'imprecision', 'buzzing', 'inflammation', 'strange', 'hesitant', 'apocalypse', 'illogic', 'moribund', 'discoutinous', 'crash', 'limp', 'criticize', 'goading', 'flabbergasted', 'soapy', 'blundering', 'rage', 'toxic', 'pretence', 'disown', 'tentatively', 'arrogantly', 'backbiting', 'staid', 'divisive', 'frazzle', 'infraction', 'underdog', 'discontinuous', 'snobby', 'unclean', 'alienate', 'drawback', 'mendacious', 'accidental', 'adulterated', 'paupers', 'self-humiliation', 'sloooooooooooooow', 'effigy', 'unpredictable', 'mercilessly', 'refusing', 'frustrate', 'hostility', 'recessionary', 'erroneous', 'two-faced', 'illness', 'asinininity', 'banalize', 'deceiving', 'imperfections', 'suffering', 'clamorous', 'delirious', 'defame', 'craftily', 'crumple', 'defensive', 'rivalry', 'covetous', 'bashing', 'mystify', 'problems', 'improper', 'refuse', 'tumultuous', 'enviousness', 'failure', 'uneasily', 'stodgy', 'bonkers', 'cruelest', 'terribly', 'faults', 'sinful', 'maliciously', 'stinks', 'divisiveness', 'sued', 'snagging', 'sorrowfully', 'rejecting', 'unsupportive', 'invalidate', 'lividly', 'audiciously', 'dumb', 'asperse', 'catastrophic', 'gloatingly', 'inescapably', 'stymied', 'annoyed', 'corrosive', 'devilishly', 'immature', 'inescapable', 'snappishly', 'flaw', 'fusty', 'harrow', 'killjoy', 'sketchy', 'spews', 'misstatement', 'overpower', 'swelling', 'unsafe', 'deceiver', 'unconvincing', 'dissolute', 'combust', 'prisoner', 'oblivious', 'inefficacy', 'dismaying', 'fearsome', 'faze', 'fatal', 'bleak', 'dishonorable', 'undercuts', 'insignificantly', 'deteriorating', 'austere', 'denied', 'detriment', 'horrific', 'teasingly', 'preposterously', 'tumble', 'despise', 'less-developed', 'scratched', 'penalize', 'deception', 'over-valuation', 'sunken', 'susceptible', 'nonsense', 'unreasonably', 'impermissible', 'audacious', 'loser', 'rantingly', 'stunted', 'deride', 'botch', 'conspiratorial', 'hoodium', 'mispronounce', 'blindside', 'smouldering', 'abolish', 'cataclysm', 'confused', 'grumble', 'heck', 'inconsolably', 'sullen', 'wreaked', 'barbaric', 'dump', 'intimidatingly', 'illegal', 'breaks', 'inimical', 'last-ditch', 'pessimistic', 'retreat', 'ruin', 'shambles', 'unlicensed', 'unreliable', 'unscrupulous', 'venomously', 'acrimonious', 'misaligns', 'outrages', 'slanderous', 'swagger', 'dazed', 'intractable', 'aground', 'obstacle', 'brashness', 'bloody', 'stumbles', 'dismissively', 'sarcastically', 'moron', 'tumbles', 'unspeakablely', 'cannibalize', 'fraudulent', 'occludes', 'ploy', 'spoonfed', 'wreck', 'devastate', 'inflationary', 'precipitous', 'crowded', 'falsehood', 'garbage', 'anxious', 'boastful', 'condescending', 'ill-tempered', 'reviled', 'broke', 'inconsistency', 'forfeit', 'scum', 'tumbled', 'forsaken', 'horrifying', 'rhapsodize', 'clogged', 'idiotic', 'lugubrious', 'defamatory', 'antagonist', 'disrespectfulness', 'erodes', 'molestation', 'fuzzy', 'harangue', 'greedy', 'dragoon', 'irking', 'misjudgment', 'strangest', 'rejection', 'lanky', 'aweful', 'irritation', 'anti-american', 'flawed', 'degradingly', 'failing', 'tauntingly', 'disgustingly', 'hard-line', 'deadweight', 'oppressors', 'undecided', 'throttle', 'imperfect', 'underestimate', 'victimize', 'astray', 'sluggish', 'licentiousness', 'contemptuous', 'drastically', 'inconsistent', 'contradiction', 'contradict', 'merciless', 'falter', 'lech', 'dispirit', 'scold', 'scam', 'overtaxed', 'untouched', 'disarray', 'domineer', 'scars', 'contaminated', 'opinionated', 'acrimony', 'exhaust', 'emaciated', 'unwillingness', 'wack', 'senile', 'discontinuity', 'gangster', 'clash', 'acerbic', 'confrontation', 'scandals', 'villainously', 'deceive', 'unsettled', 'insolently', 'spitefully', 'troubled', 'trashy', 'enemy', 'solemn', 'berate', 'disturb', 'adversary', 'insincerely', 'ranting', 'retards', 'indiscriminate', 'mirage', 'uproot', 'pity', 'disillusions', 'misunderstanding', 'irony', 'petrify', 'revolting', 'brutal', 'choke', 'ridiculously', 'incompetence', 'gossip', 'annoying', 'confounded', 'glare', 'weed', 'overstates', 'skeptical', 'confusing', 'felon', 'finicky', 'berserk', 'insensitive', 'intolerable', 'unintelligible', 'bleakness', 'depravedly', 'little-known', 'brutality', 'suspicion', 'conceded', 'untenable', 'contrive', 'audacity', 'shatter', 'quarrels', 'deviate', 'measly', 'injustices', 'devoid', 'peculiarly', 'stagnant', 'costly', 'uncompetitive', 'greed', 'exasperatingly', 'puny', 'mists', 'disregardful', 'assassin', 'frustrations', 'antagonize', 'melancholy', 'superficiality', 'discouragement', 'disobedient', 'irritations', 'disregard', 'dastard', 'rot', 'grotesque', 'writhe', 'vexingly', 'drought', 'dastardly', 'unsavory', '2-faced', 'dehumanization', 'lethargy', 'doggedly', 'losers', 'recklessness', 'bombard', 'insensitivity', 'perversely', 'nasty', 'inattentive', 'depressing', 'meaningless', 'haste', 'pratfall', 'incapably', 'strut', 'destroyer', 'spewed', 'over-priced', 'inexcusably', 'disinclined', 'subtract', 'vestiges', 'expropriate', 'thoughtlessly', 'troubling', 'discordance', 'rubbish', 'impulsive', 'devastating', 'dauntingly', 'panders', 'unusably', 'unqualified', 'cry', 'hindrance', 'flicker', 'dripped', 'dogged', 'lurk', 'irresolute', 'irrelevance', 'unlawful', 'bitingly', 'expropriation', 'bumped', 'fury', 'hazard', 'indiscreet', 'limitation', 'mocks', 'objectionable', 'excessive', 'overacted', 'oversimplify', 'irrationals', 'outrageousness', 'scapegoat', 'vibrating', 'creeping', 'demolish', 'unpleasantries', 'worn', 'desertion', 'foully', 'clamor', 'disarm', 'fumes', 'grating', 'litigious', 'repudiate', 'worsening', 'straggler', 'damages', 'rip-off', 'cons', 'concen', 'letch', 'heartless', 'hypocritically', 'laid-off', 'admonisher', 'despondency', 'disheartening', 'stagnation', 'unconstitutional', 'uneven', 'overthrow', 'monotonous', 'torture', 'spoilages', 'ugliness', 'blunders', 'rife', 'disliking', 'droop', 'unequal', 'recession', 'scandalized', 'throbbed', 'condemnable', 'dismissive', 'heartbreakingly', 'harried', 'over-acted', 'inanely', 'ambivalence', 'rue', 'idle', 'distort', 'stooge', 'stooges', 'cussed', 'brusque', 'absurd', 'friction', 'pathetically', 'disgustful', 'sham', 'unusable', 'dust', 'indecisive', 'venom', 'miserly', 'dishonorablely', 'deplorable', 'coward', 'isolated', 'atrocities', 'conceit', 'illusions', 'undercutting', 'lagged', 'nightmarish', 'carnage', 'impiety', 'tentative', 'lewd', 'divergent', 'static', 'devilish', 'hated', 'intrusive', 'inconsiderate', 'manic', 'recklessly', 'tanks', 'browbeat', 'blinding', 'gracelessly', 'heathen', 'sink', 'inarticulate', 'infuriatingly', 'drippy', 'languid', 'remorse', 'gape', 'stuck', 'ingrate', 'injudicious', 'despised', 'insensitively', 'lackluster', 'miss', 'dislike', 'ranted', 'defiantly', 'delay', 'judders', 'maliciousness', 'intrusion', 'chunky', 'mist', 'relentless', 'slower', 'blow', 'streaky', 'vice', 'volatile', 'run-down', 'foreboding', 'bumpping', 'obstruct', 'neglected', 'humiliation', 'lewdness', 'destroy', 'haggard', 'pretentious', 'scuffs', 'destains', 'stutters', 'trouble', 'hawkish', 'creep', 'hedonistic', 'sarcasm', 'leakage', 'lousy', 'sober', 'perverse', 'obscenity', 'refutation', 'smells', 'contort', 'grumpy', 'naive', 'provocative', 'watered-down', 'imbalance', 'dullard', 'decadent', 'dissatisfaction', 'perversity', 'renunciation', 'concessions', 'flareups', 'unavoidably', 'gruesome', 'unappealing', 'lonesome', 'criticizing', 'unnaturally', 'whimper', 'pigs', 'scratch', 'misalign', 'ill-treated', 'inferior', 'undependability', 'skeptically', 'bunk', 'overact', 'wrinkled', 'negatives', 'blurry', 'sorry', 'miscreant', 'mourn', 'ultimatums', 'ruts', 'nebulously', 'farcical', 'stigma', 'evils', 'selfish', 'dreadfulness', 'exagerates', 'infirm', 'ruins', 'obscures', 'wobbles', 'restlessness', 'knife', 'picky', 'unyielding', 'goofy', 'beggar', 'shoddy', 'dismayed', 'malcontented', 'rollercoaster', 'self-defeating', 'obstructs', 'ambiguous', 'inexplainable', 'dishonest', 'drowning', 'fissures', 'impose', 'massacre', 'hypocrisy', 'obstructing', 'offender', 'depressions', 'joker', 'mistrustful', 'asunder', 'hobble', 'uncivilized', 'spendy', 'scandels', 'antagonistic', 'crooks', 'inflict', 'rascal', 'revulsion', 'difficulty', 'jobless', 'mortified', 'disagreeable', 'hubris', 'beggarly', 'listless', 'savagery', 'disastrous', 'inapt', 'superstitious', 'flake', 'scorching', 'incoherently', 'ignore', 'poverty', 'rust', 'unresolved', 'pricier', 'disable', 'complex', 'instigators', 'repudiation', 'chasten', 'hack', 'haze', 'mockingly', 'qualms', 'demon', 'unfaithful', 'inferiority', 'immorality', 'angrily', 'fastidiously', 'imprecate', 'famine', 'primitive', 'virulent', 'bewitch', 'downfall', 'complaint', 'corrupted', 'aspersion', 'limit', 'irritably', 'misunderstandings', 'disdainful', 'untested', 'creeps', 'exhausted', 'self-criticism', 'warlike', 'funky', 'floundering', 'misery', 'admonishingly', 'catastrophies', 'bickering', 'explosive', 'inconsequentially', 'drains', 'insecurity', 'ho-hum', 'calumniously', 'slut', 'swindle', 'lackeys', 'disturbance', 'refutes', 'fever', 'negativity', 'discrepant', 'mangle', 'sugar-coated', 'disbelief', 'sputter', 'insulted', 'contravene', 'detestable', 'fiend', 'uneasy', 'mire', 'weirdly', 'weakness', 'tantrum', 'inefficacious', 'desititute', 'tainted', 'avalanche', 'urgent', 'demonized', 'sobering', 'drab', 'hissed', 'immaterial', 'deviation', 'hollow', 'infuriating', 'vexing', 'obscurity', 'spookiest', 'accusing', 'brutalising', 'abrasive', 'dissidents', 'obscene', 'disagreeably', 'shun', 'discomfititure', 'uncomfortably', 'mournfully', 'addict', 'unknown', 'coldly', 'oppression', 'queer', 'paralyzed', 'blasphemous', 'back-logged', 'backbite', 'hideous', 'brazenness', 'gibberish', 'instable', 'extort', 'complain', 'squeak', 'admonition', 'flickering', 'imperiously', 'opposition', 'insolence', 'wasting', 'infections', 'pandemonium', 'punk', 'destruction', 'hostage', 'hurtful', 'overwhelmingly', 'unhappiness', 'thoughtless', 'diffidence', 'onerously', 'delays', 'noxious', 'rude', 'smugly', 'squabble', 'reluctance', 'haunt', 'disconsolate', 'onerous', 'abrade', 'misguided', 'excruciating', 'cataclysmic', 'inelegance', 'naively', 'lackey', 'discouragingly', 'malady', 'stumps', 'diametrically', 'belligerence', 'subvert', 'giddy', 'wrong', 'omission', 'sensationalize', 'foolishly', 'untimely', 'odder', 'lawbreaking', 'irrelevant', 'heretical', 'martyrdom', 'mistress', 'incompatability', 'numb', 'imprecisely', 'abyss', 'bitch', 'demise', 'startle', 'farce', 'calumnious', 'losing', 'reckless', 'catastrophe', 'insurrection', 'declines', 'disagreed', 'dispensable', 'shameless', 'subjugate', 'lag', 'betraying', 'unnerving', 'impious', 'ignorance', 'misrepresent', 'prejudicial', 'aggravating', 'degrading', 'wimpy', 'bloodshed', 'bafflement', 'strident', 'occluded', 'fake', 'prideful', 'zaps', 'brashly', 'blunt', 'disapprove', 'undependable', 'procrastinates', 'obstinate', 'rattles', 'reject', 'reluctantly', 'loud', 'distracting', 'stumped', 'skeptic', 'excruciatingly', 'disadvantaged', 'thorny', 'touchy', 'downturn', 'incompetent', 'inexorable', 'miserably', 'irked', 'doom', 'vulnerable', 'allergy', 'deficiency', 'incitement', 'unbearable', 'disfavor', 'mistrust', 'pales', 'flagrantly', 'smutty', 'contaminate', 'pitiful', 'catastrophes', 'egomania', 'cruelties', 'repulsiveness', 'repulse', 'gimmicky', 'posturing', 'bemused', 'stifle', 'backache', 'expensive', 'misreading', 'overstate', 'horrible', 'graceless', 'stealing', 'ineptitude', 'dictatorial', 'geezer', 'denigrate', 'smelly', 'fatuously', 'retardedness', 'lemon', 'slow', 'cruelness', 'barbarous', 'haggle', 'untrue', 'misinformed', 'flee', 'uproarous', 'derogatory', 'mar', 'detest', 'disvalue', 'ill-defined', 'timidness', 'cannibal', 'officious', 'shamefulness', 'accost', 'exile', 'obnoxiously', 'disinterest', 'inaccuracy', 'painfull', 'squeaky', 'inexpert', 'despondence', 'contaminates', 'smelling', 'saggy', 'self-interest', 'limitations', 'humming', 'multi-polarization', 'loses', 'sneeringly', 'disgust', 'sadden', 'disinterested', 'unsettlingly', 'scared', 'gross', 'incongruous', 'pessimistically', 'backwood', 'undetermined', 'critical', 'split', 'acridly', 'grief', 'lechery', 'attack', 'pan', 'redundancy', 'retard', 'slogs', 'rift', 'hell', 'hoodwink', 'negative', 'mystery', 'obsessively', 'jitters', 'grievances', 'precariously', 'unwisely', 'vengefully', 'drain', 'weak', 'inefficiency', 'languor', 'fatefully', 'irksome', 'perverted', 'perplexed', 'stereotypically', 'unfeeling', 'screwed', 'discompose', 'worthlessly', 'profanity', 'perfidious', 'baffle', 'revoke', 'wrangle', 'prickles', 'pugnaciously', 'scrambles', 'chaos', 'gasp', 'plagiarize', 'scornfully', 'culprit', 'gainsay', 'malcontent', 'puzzlement', 'nettlesome', 'destitution', 'improbable', 'anguish', 'corrosions', 'exagerate', 'flout', 'impossibly', 'salacious', 'indecisively', 'unexpectedly', 'consternation', 'short-lived', 'gimmicking', 'contention', 'indefensible', 'woeful', 'bewildering', 'crumpled', 'idiocies', 'tease', 'credulous', 'abysmal', 'extraneous', 'imminently', 'grievous', 'frigid', 'inaccurate', 'mess', 'uncouth', 'madly', 'stubbornly', 'mawkishness', 'disaccord', 'addicting', 'impudence', 'discourteous', 'crumples', 'feebleminded', 'pittance', 'extermination', 'diabolical', 'disappoints', 'pains', 'recalcitrant', 'jeopardize', 'rumours', 'strictly', 'derisively', 'slave', 'slogged', 'dings', 'tawdry', 'sporadic', 'sting', 'downcast', 'long-winded', 'unprofitable', 'unemployed', 'dispiritedly', 'exorbitantance', 'mysterious', 'cracks', 'shrouded', 'incompetently', 'fragile', 'muscle-flexing', 'sulk', 'wanton', 'gnawing', 'aimless', 'deign', 'inaptitude', 'sermonize', 'insanity', 'fleeting', 'despoil', 'harmful', 'anarchy', 'helplessness', 'hurt', 'leaks', 'messes', 'over-hyped', 'overbearing', 'restrictive', 'stew', 'egregiously', 'bash', 'lapse', 'bestial', 'showdown', 'disputable', 'hallucination', 'jumpy', 'panick', 'traped', 'unwillingly', 'zealot', 'quarrel', 'illogical', 'convoluted', 'disconcerting', 'crowdedness', 'swamped', 'bleakly', 'renounce', 'disintegrated', 'overpayed', 'drop-out', 'disavow', 'vengeance', 'defrauding', 'itching', 'sinister', 'smear', 'implicate', 'collusion', 'unworkable', 'hatred', 'spoilage', 'spoiled', 'stink', 'crushed', 'danger', 'shallow', 'deteriorate', 'trick', 'aggressiveness', 'denunciations', 'dreary', 'brood', 'downheartedly', 'liar', 'misleadingly', 'ill-treatment', 'spooky', 'bland', 'bullshit', 'noisier', 'pugnacious', 'trash', 'evasion', 'messy', 'lamentable', 'discomfort', 'pricey', 'snub', 'stinging', 'syndrome', 'shortness', 'pariah', 'relentlessly', 'unjustly', 'ambush', 'imposers', 'demoralizing', 'neurotically', 'caustically', 'immoderate', 'lambast', 'nitpick', 'revert', 'cramped', 'prik', 'opportunistic', 'rancor', 'sloow', 'complacent', 'substandard', 'enrage', 'faltered', 'manipulation', 'suicide', 'ungrateful', 'floored', 'overstated', 'shamelessly', 'onslaught', 'doldrums', 'misses', 'mortification', 'sorrow', 'swipe', 'flaky', 'deceivers', 'over-balanced', 'accusingly', 'overdo', 'complicit', 'puppet', 'viciously', 'troublingly', 'falsify', 'pain', 'bruised', 'denounce', 'squeals', 'accusations', 'dark', 'involuntarily', 'autocrat', 'chronic', 'deaf', 'douchbag', 'bore', 'erratic', 'extinguish', 'furious', 'guile', 'belittled', 'despoiler', 'hustler', 'mendacity', 'disturbed', 'oppressive', 'crashing', 'perturb', 'precipitate', 'uncomfortable', 'harridan', 'bemoan', 'get-rich', 'risky', 'plea', 'dictator', 'disconcerted', 'remorselessly', 'diappointed', 'persecution', 'wince', 'disagreement', 'resentment', 'hard', 'remorseful', 'recoil', 'anomalous', 'bankrupt', 'sharply', 'tormented', 'arbitrary', 'passiveness', 'discontent', 'hissing', 'direly', 'sinisterly', 'turbulent', 'lapses', 'cringed', 'disadvantages', 'unjust', 'trashed', 'fawningly', 'subservience', 'subversively', 'inhospitable', 'startlingly', 'bull----', 'foolish', 'dissident', 'hamper', 'inessential', 'inflammed', 'fictitious', 'nuisance', 'haphazard', 'aggrieved', 'irredeemable', 'nosey', 'selfishly', 'wripping', 'erroneously', 'temptation', 'obliterate', 'usurp', 'pitiable', 'worthless', 'feeblely', 'burn', 'indelicate', 'incautious', 'maltreatment', 'drones', 'obstructed', 'irreplacible', 'invidious', 'uninformed', 'bothered', 'brittle', 'discomfit', 'hacks', 'gripe', 'upsets', 'delinquent', 'dragging', 'emphatic', 'superficially', 'partisans', 'damnation', 'affliction', 'fractious', 'beg', 'd*mn', 'job-killing', 'catastrophically', 'coarse', 'manipulative', 'forbidden', 'deceptively', 'frigging', 'insincerity', 'hideously', 'fidget', 'sticky', 'sickening', 'threat', 'unfinished', 'thumbs-down', 'delirium', 'bemoaning', 'dinky', 'lazy', 'bulkier', 'denying', 'refusal', 'subjection', 'donside', 'treacherously', 'unproductive', 'passive', 'break', 'bragger', 'overweight', 'derisiveness', 'retreated', 'aborts', 'sneer', 'bias', 'undermines', 'bumping', 'displeasing', 'ineloquent', 'dread', 'stormy', 'anti-proliferation', 'freezing', 'barren', 'incendiary', 'cocky', 'cronyism', 'overemphasize', 'cynical', 'dungeon', 'inhospitality', 'admonishment', 'refused', 'stupidity', 'underlings', 'embarrassment', 'disappointingly', 'lumpy', 'flaws', 'dissapointed', 'aggravation', 'disagreeing', 'expel', 'fanciful', 'devastated', 'glitches', 'betrayer', 'obsessiveness', 'offend', 'tricked', 'uncreative', 'ominously', 'reticent', 'racy', 'unfortunately', 'indecently', 'longing', 'ghosting', 'rebellious', 'overwhelming', 'sloooow', 'annoyingly', 'execrate', 'ghastly', 'insultingly', 'phobic', 'screech', 'strenuous', 'dejected', 'bristle', 'impatience', 'head-aches', 'beastly', 'denies', 'hellion', 'egotistical', 'presumptuous', 'unsustainable', 'cheat', 'disobedience', 'fatuity', 'repulsively', 'scoff', 'tramp', 'unprepared', 'violation', 'unwell', 'seethe', 'aversion', 'faint', 'cramping', 'battered', 'impolitely', 'contagious', 'infringe', 'dumping', 'propaganda', 'prejudices', 'fleer', 'bid-rigging', 'disobey', 'rascals', 'pernicious', 'outmoded', 'thrash', 'distrusting', 'alarming', 'idiocy', 'vengefulness', 'chaff', 'capricious', 'whining', 'preoccupy', 'terribleness', 'degradation', 'fault', 'hardliners', 'impertinent', 'maddeningly', 'election-rigger', 'misjudge', 'lawlessness', 'subjected', 'pettifog', 'humid', 'peculiar', 'insufficiently', 'filth', 'criticism', 'taint', 'uproariously', 'inopportune', 'miscreants', 'disapointed', 'frighten', 'irritate', 'inappropriate', 'brute', 'aggrieve', 'illiterate', 'scathing', 'besiege', 'abscond', 'devastates', 'selfinterested', 'fragmented', 'snarl', 'disavowal', 'smallish', 'tiring', 'uncollectible', 'lackadaisical', 'dense', 'mournful', 'pimple', 'broken', 'achey', 'suspiciously', 'quitter', 'crumbling', 'reprovingly', 'bungler', 'gloomy', 'indulge', 'overheat', 'reprove', 'mocking', 'struggle', 'yawn', 'weaknesses', 'spurious', 'brazen', 'impediment', 'bigotry', 'oversight', 'resent', 'unraveled', 'jealously', 'forlorn', 'pleas', 'unsuccessfully', 'crook', 'ludicrous', 'sass', 'unusually', 'punishable', 'hardheaded', 'dripping', 'caustic', 'misunderstood', 'suspicions', 'blistering', 'travesty', 'bitterly', 'antipathy', 'painfully', 'miserable', 'rigidity', 'far-fetched', 'tired', 'drop-outs', 'painful', 'galls', 'unimaginable', 'mockery', 'collude', 'sickeningly', 'brainless', 'disastrously', 'harden', 'shimmy', 'delusions', 'prosecute', 'nagging', 'harbors', 'unuseable', 'stampede', 'freeze', 'challenging', 'blockhead', 'panicked', 'orphan', 'daunting', 'terrible', 'apathy', 'anti-', 'viper', 'egotism', 'invalid', 'scorn', 'unbearablely', 'sillily', 'obstruction', 'peeved', 'fanatically', 'creaking', 'riled', 'chatter', 'heckle', 'rejects', 'fume', 'vibration', 'needy', 'tedious', 'hopelessly', 'excuse', 'smolder', 'unbelievable', 'inactive', 'unfaithfully', 'unseemly', 'sap', 'unilateralism', 'feign', 'setback', 'stall', 'vomits', 'doddering', 'oddity', 'drained', 'obtrusive', 'traitor', 'uneasiness', 'laughingstock', 'effrontery', 'fierce', 'hothouse', 'leaking', 'impetuous', 'overdone', 'shockingly', 'pout', 'apprehensive', 'importunate', 'fastidious', 'mawkishly', 'oblique', 'rhetoric', 'lags', 'niggles', 'sluts', 'truant', 'shunned', 'uproarious', 'slug', 'subpoenas', 'mundane', 'punish', 'tediously', 'mortify', 'vehement', 'dope', 'traumatized', 'vile', 'insidiously', 'mock', 'disaffect', 'tortuous', 'craze', 'debase', 'idiotically', 'nauseating', 'repression', 'scolded', 'wayward', 'irrecoverableness', 'abrupt', 'belittling', 'distasteful', 'perish', 'ruthlessly', 'flirty', 'setbacks', 'ailing', 'disorder', 'irragularity', 'defamations', 'indiscriminately', 'grudges', 'manipulators', 'apprehensions', 'maniacal', 'backaches', 'mulish', 'unproven', 'vainly', 'commotion', 'fateful', 'insensible', 'unfounded', 'infuriate', 'displace', 'capitulate', 'slaves', 'accuses', 'cash-strapped', 'idiot', 'slap', 'complicated', 'tiresome', 'desolate', 'boggle', 'atrophy', 'ax', 'domineering', 'misconceptions', 'cruel', 'notoriety', 'rejected', 'embattled', 'shrew', 'taxing', 'somber', 'laughably', 'discourage', 'wounds', 'abusive', 'kook', 'inundated', 'futilely', 'alarmed', 'clog', 'virulence', 'dumped', 'dissonance', 'insanely', 'impede', 'villify', 'cliche', 'exterminate', 'fascist', 'flimflam', 'ruinous', 'dismalness', 'issue', 'spoon-feed', 'issues', 'insufficient', 'mashed', 'backwardness', 'impatient', 'unstable', 'violate', 'partisan', 'unwatchable', 'intoxicate', 'whore', 'demonizes', 'shocked', 'wrath', 'disgustfully', 'fastuous', 'hasty', 'miscalculation', 'incongruously', 'tarnishing', 'self-serving', 'lying', 'isolate', 'downfallen', 'shrug', 'brutalities', 'iniquitous', 'madder', 'perversion', 'regretted', 'slog', 'straggle', 'bondage', 'objections', 'prick', 'tortured', 'isolation', 'unsteadily', 'lovelorn', 'bullshyt', 'flaking', 'weary', 'slowed', 'undocumented', 'ill-designed', 'jealous', 'unexplained', 'frail', 'illusion', 'fell', 'stiffness', 'coerce', 'irreversible', 'unsound', 'venomous', 'inflammatory', 'distressed', 'impetuously', 'cunts', 'ultimatum', 'impure', 'enraged', 'inconceivable', 'poisonous', 'brainwash', 'attacks', 'stricken', 'sucky', 'liability', 'fulminate', 'obese', 'diss', 'puppets', 'infringements', 'hardhearted', 'remorseless', 'woefully', 'spurn', 'maladjustment', 'rip', 'scant', 'cheap', 'insults', 'irrecoverablenesses', 'lawless', 'error', 'disparage', 'restrict', 'blurt', 'overbearingly', 'weaker', 'embarrass', 'furor', 'woe', 'cloud', 'blockage', 'cutthroat', 'crush', 'downhill', 'apprehension', 'dungeons', 'insurmountably', 'devilry', 'prohibit', 'slander', 'unjustified', 'weariness', 'drunk', 'violent', 'din', 'illicit', 'coercion', 'unnatural', 'displaced', 'goon', 'insubstantial', 'anxiously', 'crappy', 'disliked', 'grieve', 'insupportably', 'bleeding', 'languorous', 'fallaciousness', 'questionable', 'worried', 'evade', 'prison', 'deluded', 'impunity', 'damnable', 'harm', 'pathetic', 'disgraced', 'bombardment', 'vehemently', 'fear', 'nastily', 'disinclination', 'farcical-yet-provocative', 'disgraceful', 'gaudy', 'crabby', 'fried', 'accursed', 'flighty', 'forlornly', 'douchebag', 'goof', 'indifferent', 'overrun', 'commotions', 'repugnantly', 'shark', 'unacceptablely', 'flirt', 'rupture', 'injustice', 'asinine', 'sty', 'tricky', 'burning', 'threatening', 'perplexing', 'crazy', 'insidious', 'radicals', 'unnoticed', 'frighteningly', 'drunkard', 'hegemony', 'grapple', 'frets', 'scandalous', 'misunderstand', 'object', 'stuttering', 'tanked', 'offensive', 'frustratingly', 'contrived', 'stumble', 'blasted', 'unworthy', 'inordinately', 'sack', 'err', 'inconsequent', 'indeterminable', 'denunciate', 'lament', 'loose', 'mistake', 'sarcastic', 'wiles', 'anomaly', 'struggling', 'powerless', 'unlawfulness', 'worse', 'recourses', 'shortage', 'ill-favored', 'ignominy', 'biased', 'distastefully', 'dreadful', 'life-threatening', 'fractiously', 'breach', 'pestilent', 'snarky', 'defective', 'unreliability', 'appallingly', 'killing', 'reactionary', 'reprimand', 'pickets', 'unlikely', 'contemptuously', 'ignominious', 'disintegration', 'strain', 'grouse', 'lengthy', 'enflame', 'inoperable', 'hassled', 'insufferable', 'heretic', 'compulsive', 'outcry', 'flare', 'moronic', 'sidetracked', 'perplexity', 'sorrowful', 'barbarously', 'upheaval', 'amiss', 'disgusted', 'draconian', 'shimmer', 'inconsequential', 'malignant', 'undercut', 'imperialist', 'unforeseen', 'downside', 'braggart', 'dissension', 'overturn', 'authoritarian', 'dangerous', 'dull', 'hideousness', 'shipwreck', 'madman', 'byzantine', 'angry', 'exhausts', 'rumple', 'subversive', 'unthinkably', 'inequality', 'wretchedness', 'kaput', 'quack', 'wrongly', 'inordinate', 'problematic', 'cripple', 'wobbled', 'inculcate', 'lurking', 'traumatic', 'repressive', 'itchy', 'famished', 'rigid', 'enfeeble', 'smoke', 'beset', 'chastise', 'stalls', 'horrifies', 'depressed', 'backwoods', 'abominably', 'cancerous', 'broken-hearted', 'indignation', 'cheerless', 'mediocre', 'missed', 'mortifying', 'acridness', 'wheedle', 'wickedness', 'appall', 'freaks', 'funnily', 'punitive', 'temper', 'disdainfully', 'horrified', 'flair', 'innuendo', 'liars', 'niggle', 'tank', 'hothead', 'morbid', 'torrent', 'cringes', 'irrational', 'inelegant', 'satirize', 'tiringly', 'sloww', 'liable', 'ill-fated', 'misconception', 'precarious', 'scramble', 'unipolar', 'fleeing', 'congestion', 'drawbacks', 'inconsolable', 'scrap', 'toll', 'totalitarian', 'discordant', 'crashed', 'weird', 'audaciousness', 'womanizer', 'ironic', 'disturbing', 'unpleasant', 'corrosion', 'unproving', 'blah', 'dreadfully', 'vengeful', 'gimmicked', 'deceptive', 'fruitless', 'heavy-handed', 'needless', 'sugar-coat', 'cringe', 'dirtbags', 'downer', 'bigotries', 'facetious', 'lethargic', 'blabber', 'obtuse', 'traitorously', 'annoyance', 'tyranny', 'slime', 'complication', 'eviscerate', 'disabled', 'incomprehension', 'tenuous', 'worryingly', 'bent', 'frenzied', 'mindlessly', 'illegally', 'irksomenesses', 'bewildered', 'dissatisfactory', 'intefere', 'flares', 'inexorably', 'revoltingly', 'craftly', 'impending', 'outburst', 'crap', 'affront', 'uninsured', 'hiliarious', 'sick', 'calamity', 'restricted', 'crashes', 'omit', 'raped', 'contentious', 'oppressiveness', 'banishment', 'god-awful', 'dragged', 'deviously', 'entrapment', 'inconceivably', 'irate', 'unrelenting', 'vulgar', 'erratically', 'cancer', 'ambiguity', 'assassinate', 'misdirection', 'disintegrates', 'ferociously', 'misread', 'prattle', 'accusation', 'heinous', 'tepid', 'imprecise', 'eyesore', 'outbursts', 'perturbed', 'taunts', 'thoughtlessness', 'shamefully', 'fuck', 'inevitable', 'exorbitantly', 'banal', 'imposing', 'misbehavior', 'abnormal', 'massacres', 'ostracize', 'evasive', 'discriminatory', 'murderous', 'weep', 'drags', 'undesirable', 'unconvincingly', 'bugs', 'cursed', 'irritating', 'wrought', 'provoke', 'stark', 'unaffordable', 'imperfectly', 'distrust', 'ineffectualness', 'mistakes', 'doubts', 'rotten', 'disquiet', 'stupidest', 'aggrivation', 'deprecate', 'despair', 'nastiness', 'debasement', 'died', 'decrepitude', 'exasperated', 'mawkish', 'poorly', 'petty', 'haters', 'upseting', 'boil', 'incredulously', 'throbbing', 'miser', 'ineloquently', 'bait', 'hasseling', 'meltdown', 'hatefulness', 'scoffingly', 'irrationally', 'expunge', 'tangled', 'wearisome', 'sacrificed', 'tyrannically', 'rash', 'incorrigibly', 'fidgety', 'villianous', 'irrepressible', 'bullies', 'dubitable', 'decrement', 'frenetically', 'shortchange', 'smelled', 'trivial', 'bleeds', 'jolt', 'stress', 'screwy', 'badly', 'scoldingly', 'crooked', 'fails', 'dents', 'unconfirmed', 'ill-natured', 'difficult', 'impolite', 'indiscriminating', 'crippling', 'irately', 'casualty', 'preposterous', 'full-blown', 'harassment', 'regreted', 'dissembler', 'distaste', 'breaking', 'fainthearted', 'scandal', 'licentious', 'procrastinate', 'bowdlerize', 'bores', 'midget', 'spilling', 'dunce', 'fist', 'manipulate', 'ineligible', 'negate', 'anti-semites', 'lawbreaker', 'obstinately', 'invalidity', 'allergies', 'misgiving', 'shamelessness', 'insurmountable', 'bomb', 'funny', 'burns', 'laconic', 'regrettably', 'futility', 'shortcoming', 'antithetical', 'brazenly', 'calamitously', 'coercive', 'interruptions', 'unsteadiness', 'afflictive', 'protested', 'quarrellous', 'overstatement', 'disdain', 'mindless', 'predicament', 'grudgingly', 'moot', 'leakages', 'risk', 'unrealistic', 'debilitating', 'loner', 'anxieties', 'bump', 'self-coup', 'doubtfully', 'nauseatingly', 'resistance', 'scarred', 'bulkyness', 'offenses', 'sicken', 'irreparable', 'bothersome', 'damper', 'insufficiency', 'exhort', 'leaky', 'confront', 'brimstone', 'strangle', 'interruption', 'nag', 'snobs', 'baseless', 'anemic', 'shortsightedness', 'dupe', 'careless', 'impossiblity', 'heresy', 'anxiety', 'gravely', 'reprehensible', 'scorchingly', 'implode', 'fool', 'weaken', 'stigmatize', 'miff', 'abused', 'shirker', 'disrespectablity', 'plasticky', 'confusion', 'ineptly', 'menace', 'misaligned', 'criticisms', 'cheater', 'cranky', 'entangle', 'fretful', 'hazy', 'lonely', 'sneakily', 'tempest', 'despotic', 'ridiculous', 'uncompromising', 'rebuff', 'detracts', 'flees', 'lambaste', 'irrationality', 'defamation', 'calamitous', 'invisible', 'pedantic', 'subdued', 'bitter', 'hedge', 'womanizing', 'superstition', 'payback', 'unfulfilled', 'raping', 'intransigent', 'rankle', 'immovable', 'insufferably', 'unorthodox', 'irretrievable', 'losses', 'scuff', 'squealing', 'abruptly', 'scourge', 'baffling', 'motionless', 'overblown', 'rattle', 'audaciously', 'fallaciously', 'forsake', 'mad', 'desert', 'bashed', 'worrier', 'disillusionment', 'eccentricity', 'shrill', 'brutally', 'hung', 'squeal', 'blatant', 'loopholes', 'impasse', 'haywire', 'assault', 'debility', 'injury', 'timidly', 'vibrates', 'hotbeds', 'grimace', 'bully', 'exhaustion', 'devastatingly', 'deploringly', 'jerky', 'simplistically', 'debacle', 'ineffectually', 'harboring', 'picketing', 'infiltrator', 'deficiencies', 'smuttiest', 'gawk', 'foulness', 'dropouts', 'zombie', 'demonic', 'repel', 'punch', 'enervate', 'erosion', 'sleazy', 'obsolete', 'unsecure', 'loss', 'dissent', 'squabbling', 'frustrated', 'insincere', 'disservice', 'downsides', 'inexperience', 'slur', 'deploring', 'distressing', 'excuses', 'loathing', 'regressive', 'shemale', 'damn', 'darkness', 'scarcely', 'hard-hit', 'inefficient', 'allegations', 'helplessly', 'jerk', 'zapped', 'fucking', 'boisterous', 'capriciously', 'inappropriately', 'incense', 'hypocritical', 'treasonous', 'rile', 'absurdity', 'flimsy', 'impair', 'unkindly', 'grim', 'hateful', 'imperil', 'criminal', 'smack', 'lacks', 'despairingly', 'defy', 'adulteration', 'villains', 'disasterous', 'starkly', 'creaks', 'foolhardy', 'misapprehend', 'aggressive', 'freak', 'belated', 'groundless', 'adverse', 'non-confidence', 'sly', 'enjoin', 'grainy', 'unexpected', 'snobish', 'nauseate', 'fatalistic', 'discontented', 'frenzy', 'unscrupulously', 'snob', 'degrade', 'evildoer', 'severity', 'jabber', 'debatable', 'dismay', 'hallucinate', 'ill-sorted', 'overzealously', 'repugnance', 'indolent', 'belligerently', 'impropriety', 'estranged', 'quandary', 'unaccessible', 'craps', 'undid', 'evil', 'loath', 'beware', 'stuffy', 'genocide', 'dogmatic', 'bullyingly', 'dishonestly', 'implausibly', 'mope', 'tragedy', 'heedless', 'bellicose', 'irregular', 'conflicting', 'disintegrate', 'ungovernable', 'belligerent', 'displease', 'dissatisfy', 'divisively', 'failures', 'lone', 'nepotism', 'dishearteningly', 'deprived', 'slooow', 'grouchy', 'inequitable', 'harmed', 'apathetic', 'adamantly', 'wreaks', 'choleric', 'hooligan', 'dismayingly', 'parody', 'misbecoming', 'dissed', 'stunt', 'miscalculate', 'nitpicking', 'inconsequently', 'slack', 'touts', 'bruises', 'cheaply', 'collapse', 'distract', 'breakdown', 'fatuous', 'felonious', 'glitch', 'mishandle', 'disagree', 'paranoid', 'skimpy', 'unreasonable', 'marginal', 'criticized', 'entanglement', 'partiality', 'avenge', 'thumb-down', 'froze', 'calamities', 'disrespect', 'fatique', 'worry', 'cloudy', 'unbelievably', 'lose', 'polluters', 'nonresponsive', 'embarrassingly', 'steal', 'unlamentably', 'deadlock', 'leak', 'junky', 'inflexible', 'agonizing', 'discourteously', 'ruining', 'rumor', 'implication', 'scarce', 'oppressively', 'bombastic', 'ill-conceived', 'servitude', 'overwhelmed', 'grossly', 'overkill', 'freakishly', 'damning', 'suffocate', 'hardball', 'smother', 'sues', 'insatiable', 'condemnation', 'encroachment', 'negation', 'disruptive', 'hogs', 'plaything', 'complains', 'superficial', 'antiquated', 'defile', 'pinch', 'insinuate', 'regretful', 'conspire', 'exploit', 'tyrannical', 'acerbate', 'unwieldy', 'degenerately', 'confined', 'randomly', 'war-like', 'anarchism', 'pander', 'calumny', 'bulky', 'stumbled', 'sanctimonious', 'unethical', 'irrationalities', 'ugliest', 'snagged', 'virulently', 'incomprehensible', 'disadvantage', 'boycott', 'desperate', 'aghast', 'break-up', 'despairing', 'inadequately', 'dick', 'fallacy', 'annihilate', 'wretchedly', 'smug', 'dislikes', 'cheapen', 'harass', 'worrisome', 'struggles', 'warned', 'disputed', 'ruffian', 'unauthentic', 'laughable', 'tragic', 'unhappily', 'uncomfy', 'anxiousness', 'mischief', 'undone', 'bruise', 'fustigate', 'uncooperative', 'beleaguer', 'arcane', 'gullible', 'twist', 'gaffe', 'fleed', 'disaster', 'exacerbate', 'hectic', 'distortion', 'spoil', 'contradictory', 'exploitation', 'atrocity', 'hostilities', 'fabricate', 'topple', 'concerned', 'grind', 'infamy', 'flakieness', 'frustrates', 'distraughtly', 'nightmare', 'stupified', 'overplay', 'angriness', 'unlamentable', 'longingly', 'arduously', 'inclement', 'emphatically', 'slowww', 'embroil', 'pig', 'regret', 'fallacies', 'skulk', 'bleed', 'crummy', 'impolitic', 'unjustifiably', 'intense', 'sneak', 'fatcats', 'farcically', 'wrinkles', 'deadly', 'slump', 'cheated', 'guiltily', 'sweaty', 'hypocrite', 'unachievable', 'inadvisably', 'horrid', 'mordantly', 'indistinguishable', 'infuriated', 'bewilderingly', 'horrendously', 'oversimplification', 'die', 'grievously', 'sag', 'aloof', 'bewilderment', 'protests', 'poisonously', 'reprehensive', 'anti-social', 'burned', 'encroach', 'fibber', 'garish', 'oppress', 'combative', 'irks', 'savaged', 'faulty', 'brutalize', 'detested', 'greasy', 'bitchy', 'fictional', 'decadence', 'remorsefully', 'threats', 'discrimination', 'fall', 'inhibition', 'whips', 'struggled', 'rants', 'fanatical', 'banish', 'deceitfully', 'disallow', 'ruined', 'scrambling', 'rival', 'growl', 'revengeful', 'undermined', 'fallacious', 'condemns', 'twists', 'back-wood', 'desperation', 'bravado', 'proprietary', 'barbarian', 'ramshackle', 'qualm', 'sub-par', 'discriminate', 'destitute', 'depression', 'illogically', 'darken', 'mangled', 'dissatisfies', 'outcast', 'fatalistically', 'abominable', 'narrower', 'suspicious', 'deprive', 'averse', 'hampered', 'gauche', 'inaction', 'bereavement', 'outlaw', 'inevitably', 'alarmingly', 'damaged', 'fearfully', 'involuntary', 'inequalities', 'taut', 'exhorbitant', 'skittishly', 'vomit', 'crime', 'desultory', 'creepy', 'troublesomely', 'decline', 'pauper', 'bewail', 'complaining', 'regretfully', 'slowest', 'argumentative', 'inexpiable', 'addicts', 'dissolution', 'corrupting', 'abominate', 'checkered', 'horrify', 'mislead', 'phony', 'solicitude', 'upsettingly', 'unacceptable', 'babble', 'infest', 'adversarial', 'spoils', 'disapproving', 'ironies', 'militancy', 'unreachable', 'indecision', 'ignoble', 'subservient', 'symptoms', 'oppositions', 'reproachful', 'reprehension', 'undue', 'peril', 'irredeemably', 'crazily', 'cruelly', 'apocalyptic', 'foe', 'overzealous', 'alarm', 'unimportant', 'vociferous', 'lure', 'detestably', 'insubordinate', 'frictions', 'back-woods', 'blurred', 'dissuade', 'franticly', 'nightmarishly', 'demean', 'disapprobation', 'sickness', 'maladjusted', 'depress', 'predatory', 'protracted', 'unforgiving', 'belie', 'detrimental', 'shaky', 'stubbornness', 'plunderer', 'pale', 'chastisement', 'hysteria', 'malevolent', 'testily', 'unwanted', 'wound', 'blemish', 'torturing', 'irritated', 'overrated', 'idiots', 'spinster', 'anti-us', 'immoral', 'ailment', 'unhelpful', 'sickly', 'assail', 'suppress', 'weakening', 'disloyal', 'disconcertingly', 'flak', 'insulting', 'self-destructive', 'uncontrolled', 'rocky', 'damage', 'lacked', 'lagging', 'butcher', 'pertinaciously', 'submissive', 'vindictiveness', 'subversion', 'flagrant', 'calumnies', 'abort', 'blaspheme', 'detesting', 'incivility', 'indiscretion', 'irresponsible', 'loathsomely', 'problem', 'bs', 'protest', 'refuses', 'troubles', 'irksomeness', 'archaic', 'desolately', 'mislike', 'extremists', 'fruitlessly', 'moody', 'traitorous', 'irk', 'dirts', 'jutter', 'acrimoniously', 'negligent', 'drips', 'oppose', 'shrivel', 'disappointing', 'smash', 'humiliating', 'galling', 'disrepute', 'dissemble', 'inaccurately', 'hestitant', 'mockeries', 'mourner', 'puzzled', 'coupists', 'suck', 'deviousness', 'mishap', 'unprove', 'embroiled', 'fat', 'malevolence', 'unrelentingly', 'wedge', 'despot', 'barbarically', 'instability', 'disparaging', 'lethal', 'anger', 'pique', 'terrorize', 'adulterate', 'infidel', 'undignified', 'tattered', 'censure', 'time-consuming', 'exaggeration', 'oversights', 'surrender', 'goad', 'smudged', 'bruising', 'brash', 'discouraging', 'inflame', 'treachery', 'unsuspecting', 'dissocial', 'squash', 'tarnishes', 'unfunded', 'hells', 'fret', 'quibbles', 'peeled', 'cataclysmal', 'petrified', 'leech', 'clueless', 'pertinacious', 'distraught', 'doubt', 'molest', 'repugn', 'freezes', 'mediocrity', 'stutter', 'grieving', 'failed', 'tetchy', 'unsettle', 'smuttier', 'deplete', 'disproportionate', 'insolent', 'picket', 'stridently', 'murderer', 'inextricably', 'concens', 'stringent', 'falls', 'corrode', 'calumniation', 'condemn', 'misfortune', 'splitting', 'fetid', 'implausible', 'overawe', 'nefariously', 'high-priced', 'epidemic', 'misguide', 'distraughtness', 'conflicts', 'interrupt', 'crafty', 'revenge', 'ferocity', 'oddities', 'twisted', 'blather', 'detract', 'insupportable', 'scrambled', 'complained', 'suffer', 'declining', 'pessimism', 'ludicrously', 'disrespectable', 'misleading', 'taunt', 'tortures', 'break-ups', 'overdue', 'absurdness', 'indignity', 'importune', 'spewing', 'embarrassing', 'tyrant', 'radical', 'impulsively', 'obscure', 'diabolic', 'overwhelm', 'rail', 'snags', 'dislocated', 'cynicism', 'crumble', 'allergic', 'die-hard', 'grumpily', 'swollen', 'loneliness', 'scoundrel', 'commiserate', 'curse', 'errors', 'rhetorical', 'monstrosities', 'violently', 'batty', 'damned', 'admonish', 'disoriented', 'insouciance', 'afflict', 'dirt', 'horrendous', 'irreformable', 'low-rated', 'scandalously', 'second-tier', 'frightfully', 'passe', 'shriek', 'haughtily', 'indiscreetly', 'agonize', 'invader', 'imprison', 'stab', 'regrettable', 'quarrellously', 'impoverish', 'testy', 'incommensurate', 'pest', 'madden', 'trauma', 'unrest', 'stun', 'sh*t', 'guilty', 'unproves', 'blindingly', 'sue', 'resigned', 'sinfully', 'tout', 'bedlamite', 'emergency', 'conscons', 'rampant', 'regress', 'refute', 'slow-moving', 'offensively', 'unsatisfactory', 'infamously', 'complaints', 'fugitive', 'helpless', 'neurotic', 'deterioration', 'freaking', 'perilously', 'traumatically', 'debaucher', 'shabby', 'awfully', 'equivocal', 'left-leaning', 'objection', 'shady', 'spade', 'tardy', 'throb', 'disgruntle', 'unavailable', 'extremist', 'sad', 'congested', 'overshadow', 'oversize', 'clumsy', 'grumpish', 'bored', 'inaudible', 'thug', 'severe', 'doomsday', 'uneventful', 'lifeless', 'bribery', 'deplore', 'refuted', 'disbelieve', 'reproach', 'fallout', 'slowwww', 'water-down', 'fatigued', 'dumps', 'skittish', 'ravage', 'unnerve', 'impeach', 'loot', 'disordered', 'layoff-happy', 'utterly', 'blurring', 'squeaks', 'underpowered', 'illegitimate', 'havoc', 'discombobulate', 'crass', 'inaccuracies', 'tense', 'pitilessly', 'aborted', 'mistrustfully', 'disaffirm', 'suspect', 'injurious', 'paradoxically', 'frenetic', 'contaminating', 'blackmail', 'harshly', 'martyrdom-seeking', 'bloated', 'confession', 'lack', 'ricer', 'figurehead', 'spiteful', 'terror', 'feverish', 'pillory', 'mispronounced', 'infernal', 'senselessly', 'harpy', 'deprave', 'knave', 'gall', 'overstatements', 'distains', 'lier', 'sadly', 'roadblocks', 'unreadable', 'gritty', 'hardliner', 'jittery', 'unnecessary', 'gallingly', 'spitefulness', 'stereotype', 'wripped', 'depressingly', 'autocratic', 'elimination', 'menial', 'retaliatory', 'subpoena', 'zealously', 'horde', 'costlier', 'conservative', 'exasperation', 'slanderously', 'castigate', 'temerity', 'wasted', 'dissention', 'forebodingly', 'slanderer', 'condescension', 'seedy', 'bicker', 'caricature', 'egotistically', 'sorely', 'disparagingly', 'rant', 'restriction', 'junk', 'kills', 'mobster', 'hate', 'unspecified', 'incomparably', 'whores', 'deformed', 'disappointment', 'mania', 'prejudice', 'disclaim', 'seriousness', 'cackle', 'instigator', 'self-interested', 'fatcat', 'infringement', 'freakish', 'despotism', 'vibrate', 'carelessness', 'inundate', 'hypocrites', 'jeopardy', 'disappointments', 'repulsed', 'doubtful', 'intimidation', 'turmoil', 'decrepit', 'nonexistent', 'limits', 'stupid', 'unsteady', 'uproar', 'cravenly', 'sufferers', 'unfairly', 'confound', 'dissing', 'exorbitant', 'calumniate', 'blister', 'furiously', 'headache', 'spook', 'unviewable', 'abuses', 'betray', 'motley', 'repulsing', 'sunk', 'obnoxious', 'heavyhearted', 'raked', 'loathly', 'disses', 'unease', 'irreconcilable', 'tingling', 'arrogance', 'belittle', 'fiendish', 'gimmicks', 'gripes', 'nebulous', 'degeneration', 'startling', 'undermining', 'useless', 'jeers', 'odd', 'fiasco', 'unwise', 'errant', 'obscured', 'gruesomely', 'betrays', 'conflicted', 'unimaginably', 'unlucky', 'condemned', 'screwed-up', 'tarnished', 'finagle', 'unnervingly', 'inconsistencies', 'worsen', 'mispronounces', 'seething', 'premeditated', 'buckle', 'defiant', 'glower', 'annoys', 'crushing', 'flounder', 'tenuously', 'dodgey', 'ineffectiveness', 'mischievous', 'wallow', 'languish', 'debt', 'limited', 'disquietude', 'threesome', 'ache', 'stolen', 'bad', 'exasperate', 'imperious', 'repress', 'vexation', 'meddlesome', 'daunt', 'nettle', 'overzelous', 'mushy', 'desecrate', 'indifference', 'loophole', 'conceited', 'mismanage', 'relapse', 'shit', 'sloppily', 'unproved', 'snare', 'contend', 'knotted', 'irresolvable', 'chill', 'lamentably', 'stiff', 'backward', 'loveless', 'unneeded', 'deadbeat', 'vagueness', 'stammer', 'anti-white', 'antagonism', 'false', 'perverts', 'stringently', 'cracked', 'hassle', 'sabotage', 'mistaken', 'regrets', 'forceful', 'hefty', 'disrespecting', 'sucks', 'lull', 'lied', 'repulsive', 'bothering', 'disapointment', 'unintelligile', 'bluring', 'plebeian', 'hurts', 'worst', 'worrying', 'misinform', 'pry', 'stain', 'concern', 'inadverently', 'pointless', 'slumping', 'envious', 'unjustifiable', 'uproarously', 'confuses', 'feint', 'unuseably', 'terrorism', 'critics', 'rusts', 'starvation', 'distressingly', 'unclear', 'maledict', 'monstrous', 'scar', 'smell', 'appalling', 'occluding', 'adamant', 'scare', 'confrontational', 'morons', 'lurch', 'needlessly', 'busts', 'one-sided', 'blatantly', 'grudging', 'racists', 'feeble', 'disquietingly', 'downturns', 'disrespectful', 'incessant', 'heckled', 'gutless', 'sucker', 'noisy', 'disorient', 'misgivings', 'fascism', 'meager', 'subordinate', 'annoy', 'daze', 'accuse', 'brutish', 'unleash', 'sugarcoated', 'downhearted', 'indiscernible', 'lacking', 'vain', 'mordant', 'frantically', 'over-awe', 'mudslinging', 'hysteric', 'stereotypical', 'unsure', 'raging', 'slaughter', 'biases', 'defunct', 'disloyalty', 'spite', 'disquieting', 'intimidate', 'phobia', 'protesting', 'bungling', 'miserableness', 'battering', 'crisis', 'diabolically', 'incoherent', 'cautionary', 'bungle', 'demolisher', 'fathomless', 'indignantly', 'knock', 'fat-cat', 'panic', 'warily', 'fanatic', 'woebegone', 'wreak', 'monstrously', 'jutters', 'conspirator', 'miscellaneous', 'scream', 'transgression', 'wily', 'scarier', 'imminence', 'restless', 'superfluous', 'desperately', 'immobilized', 'clogs', 'uncivil', 'assult', 'damaging', 'disrupt', 'jeeringly', 'killer', 'irritable', 'scandalize', 'torturous', 'uncompromisingly', 'unsupported', 'confess', 'jeer', 'conspiracy', 'endanger', 'ignominiously', 'flairs', 'simplistic', 'hopelessness', 'judder', 'savages', 'ruthless', 'defect', 'abuse', 'fussy', 'sadness', 'dispiriting', 'perfunctory', 'timidity', 'insubstantially', 'monstrosity', 'dangerousness', 'unobserved', 'critic', 'insignificant', 'breakups', 'shameful', 'sob', 'snappish', 'heartbreaker', 'enraging', 'pertinacity', 'glum', 'infiltrators', 'meddle', 'paralize', 'loathe', 'oddest', 'unfamiliar', 'fallen', 'disingenuously', 'deceitfulness', 'cunt', 'draining', 'raving', 'ineffective'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzWuXxEq9INJ"
      },
      "source": [
        "The words in the list are general, but we can add some domain-specific word (\"`|`\" is the \"set union\" operator)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHAevZFs9INK"
      },
      "source": [
        "airline_pos_words = hu_liu_pos | {\"upgrade\"}\n",
        "airline_neg_words = hu_liu_neg | {\"wtf\", \"wait\", \"waiting\", \"epicfail\", \"mechanical\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w7GIElE9INL"
      },
      "source": [
        "_Performance note:_ we use sets here (denoted with braces: `{...}`) rather than lists (with square brackets: `[...]`) to make lookup faster"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy45mfQ79INL",
        "outputId": "fe86d734-4c8d-4378-b743-f07357a46e9b"
      },
      "source": [
        "%%timeit -n 1000000 \n",
        "# -n represents the number of loops, i.e. the number of times the code will be executed\n",
        "# 5 is the test repeat count; the tests are repeated several times. The fastest time of those 5 is then taken.\n",
        "\n",
        "\"e\" in [\"a\", \"b\", \"c\", \"d\", \"e\"]   # list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000000 loops, best of 5: 95.3 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADOFvNSD9INN",
        "outputId": "cd00a790-d51b-4c8a-d072-9d752acf37a7"
      },
      "source": [
        "%%timeit -n 1000000\n",
        "\"e\" in {\"a\", \"b\", \"c\", \"d\", \"e\"}   # set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000000 loops, best of 5: 34.7 ns per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8XH_H6d9INP"
      },
      "source": [
        "### Text tokenization\n",
        "\n",
        "We have to decompose tweets into the single words they contain in order to search for the opinion words within it\n",
        "\n",
        "A _tokenization_ algorithm splits a text string into a sequence of _tokens_ each representing a single word (or other entities such as numbers and punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSDplc_P9INP"
      },
      "source": [
        "A simple tokenization algorithm can consist in removing all characters different from letters and spaces from text, than splitting text in words using spaces as boundaries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJORMSRs9INP"
      },
      "source": [
        "import re\n",
        "\n",
        "# Considering \"This isn't a test, or is it?\" sentence as text\n",
        "# re.sub(\"[^A-Za-z ]\", \"\", text) will transform it as 'This isnt a test or is it'. \n",
        "# In general, it removes (that is equivalent to: substitute with \"\") every character that is not a upperase/lowercase letter or space\n",
        "def my_tokenizer(text):\n",
        "    return re.sub(\"[^A-Za-z ]\", \"\", text).split(\" \") # split(\" \") is used to split the sentence in a list of strings using the space \" \" as separator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw9xbtIU9INQ"
      },
      "source": [
        "An example usage is..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W6juY_S9INR",
        "outputId": "0f91acdb-a144-4fd4-b768-ce1a9ebdb4f8"
      },
      "source": [
        "my_tokenizer(\"This isn't a test, or is it?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'isnt', 'a', 'test', 'or', 'is', 'it']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFoRFRJM9INS"
      },
      "source": [
        "NLTK provides a finer tokenization algorithm, based on a knowledge model of the English language: in order to make it work, we have first to download the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnBPTc5E9INT",
        "outputId": "d43b9609-8b33-421a-cf5f-78f5f105c785"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS5JsR0E9INU"
      },
      "source": [
        "We can then use the `word_tokenize` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su1bApvb9INU",
        "outputId": "360527b3-219b-45fb-b9fe-afd7140bb260"
      },
      "source": [
        "nltk.word_tokenize(\"This isn't a test, or is it?\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuN515Y9INW"
      },
      "source": [
        "Other than keeping punctuation marks as separate tokens, NLTK was able to correctly split \"isn't\" into its two component words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trAmVK-69INX"
      },
      "source": [
        "### Sentiment scoring\n",
        "\n",
        "We define a function to compute the \"sentiment score\" of some text, computed as the difference between counts of positive and negative opinion words contained in it. Notice we have to convert all words in lowercase to be sure to find them in the lists."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walyIml89INX"
      },
      "source": [
        "def sentiment_score(text, pos_words, neg_words):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    # count 1 for each word present in the positive words list\n",
        "    pos_matches = sum(1 for word in words if word.lower() in pos_words)\n",
        "    # same count with the negative words list\n",
        "    neg_matches = sum(1 for word in words if word.lower() in neg_words)\n",
        "    # return the difference between the two counts\n",
        "    return pos_matches - neg_matches"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEiDe6fv9INZ"
      },
      "source": [
        "This functions accept the lists of positive and negative words as input, we can wrap it in a version specific for the \"airline\" opinion words lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njkdCZha9INZ"
      },
      "source": [
        "def airline_sentiment_score(text):\n",
        "    return sentiment_score(text, airline_pos_words, airline_neg_words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwKz63o99INb"
      },
      "source": [
        "Example: a sentence with one positive word..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsCtI9SU9INb",
        "outputId": "7db3dd14-37fe-47ab-a8d0-59785ee742fb"
      },
      "source": [
        "airline_sentiment_score(\"This is an awesome test!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aQ1fUrK9INd"
      },
      "source": [
        "Let's consider a small set of sample sentences to evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DvZj3Qg59INd"
      },
      "source": [
        "sample = [\n",
        "    \"You're awesome and I love you\",\n",
        "    \"I hate and hate and hate. So angry. Die!\",\n",
        "    \"Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVxGd4jj9INf"
      },
      "source": [
        "We can use `map` to apply the scoring function to each of the samples and get the sequence of corresponding scores wrapped in a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hzGXMsQ9INf"
      },
      "source": [
        "sample_scores = list(map(airline_sentiment_score, sample))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ5dPnud9INh",
        "outputId": "7684d9d8-42eb-47b6-b0fb-58bca6afc8d4"
      },
      "source": [
        "sample_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2, -5, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I306cBAA9INj"
      },
      "source": [
        "Using a pandas DataFrame, we can get a table of sample sentences matched with scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "kWoqjh6f9INk",
        "outputId": "7ad8aaf0-aca0-4103-aaf2-385774f522da"
      },
      "source": [
        "pd.DataFrame({\"score\": sample_scores, \"text\": sample})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>You're awesome and I love you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5</td>\n",
              "      <td>I hate and hate and hate. So angry. Die!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   score                                                                                    text\n",
              "0      2                                                           You're awesome and I love you\n",
              "1     -5                                                I hate and hate and hate. So angry. Die!\n",
              "2      4  Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4iDxy-y9INl"
      },
      "source": [
        "As we can see, the scoring function correctly evaluates straightforward sentences, although it fails to detect more elaborate text (e.g. using sarcasm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAPiIBPC9INl"
      },
      "source": [
        "Let's apply the scoring functions to all tweets for one of the companies, e.g. Delta. We wrap scores in a pandas Series so we can use its functionalities."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHfh_kQf9INm"
      },
      "source": [
        "delta_scores = pd.Series(map(airline_sentiment_score, tweets[\"text\"][tweets[\"airline\"] == \"delta\"]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XANhbzGVgva_",
        "outputId": "bd692817-1b80-43bc-a62c-2463e2773097"
      },
      "source": [
        "delta_scores"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       0\n",
              "3      -1\n",
              "4       0\n",
              "       ..\n",
              "1140   -1\n",
              "1141   -1\n",
              "1142    0\n",
              "1143    0\n",
              "1144    0\n",
              "Length: 1145, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTqV-3Y19INn"
      },
      "source": [
        "We can get for example the mean score of tweets..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SX8uoX49INo",
        "outputId": "a2d22dbe-c7ca-481b-e4b6-d1391811f67e"
      },
      "source": [
        "delta_scores.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.23406113537117904"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAM9PgZ9INp"
      },
      "source": [
        "...and even plot an histogram of the distribution of scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "IdnDfrX49INq",
        "outputId": "972958b4-0c4c-4868-b5b6-856057cf9af4"
      },
      "source": [
        "delta_scores.plot.hist()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1eba51bd50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0TSBjii9INr"
      },
      "source": [
        "Let's now work with the whole collection of tweets related to all airlines\n",
        "\n",
        "We compute sentiment scores for each tweet by applying the `airline_sentiment_score` function to the `text` columns; scores are saved in a `score` column added to a copy of the `tweets` DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-DsQ0Pd39INr"
      },
      "source": [
        "tweets_with_scores = tweets.copy()\n",
        "tweets_with_scores[\"score\"] = tweets_with_scores[\"text\"].apply(airline_sentiment_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOG2mmQe9INs"
      },
      "source": [
        "Let's see some random rows from it..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "O6sqT54S9INt",
        "outputId": "4f090b18-a2fa-4cb5-bf74-d6f7b6333395"
      },
      "source": [
        "tweets_with_scores.sample(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4212</th>\n",
              "      <td>united</td>\n",
              "      <td>Pretty sure that tonight will be the first time I ever buy the LiveTV programming on a @united f...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2719</th>\n",
              "      <td>southwestair</td>\n",
              "      <td>@lessonpix @SouthwestAirÂ is starting TPA-MEM service soon. Anytime you want to eat BBQ in MEM le...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1521</th>\n",
              "      <td>americanair</td>\n",
              "      <td>@AmericanAir stinks! I was on the phone for 35 minutes with an agent who then hung up on me. Not...</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2910</th>\n",
              "      <td>southwestair</td>\n",
              "      <td>bought my ticket. Want to get away with @SouthwestAir is the way to go!</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4213</th>\n",
              "      <td>united</td>\n",
              "      <td>Nicer than biz on @United http://t.co/7n6vOVPEwj</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           airline  ... score\n",
              "4212        united  ...     1\n",
              "2719  southwestair  ...     0\n",
              "1521   americanair  ...    -2\n",
              "2910  southwestair  ...     0\n",
              "4213        united  ...     1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6S53XS9INu"
      },
      "source": [
        "### Summarizing sentiment for each company\n",
        "\n",
        "Letâ€™s focus our analysis only on very negative (score <= 2) and very positive (score >= 2) tweets, adding columns which identify them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNKPLeHv9INu"
      },
      "source": [
        "tweets_with_scores[\"very_pos\"] = tweets_with_scores[\"score\"] >= 2\n",
        "tweets_with_scores[\"very_neg\"] = tweets_with_scores[\"score\"] <= -2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUiKdp6G9INx"
      },
      "source": [
        "We group the frame by companies, keeping just the columns indicating very positive or negative tweets and counting the number of them for each group"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BLlyCc2u9INx"
      },
      "source": [
        "twitter_score = tweets_with_scores.groupby(\"airline\")[[\"very_pos\", \"very_neg\"]].sum().sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsmBFK-U9INz"
      },
      "source": [
        "Let's view the obtained grouped table..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "KEzM87Un9IN0",
        "outputId": "d21e40c2-089c-4a5c-d1f7-7346ac9fb6ee"
      },
      "source": [
        "twitter_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>very_pos</th>\n",
              "      <th>very_neg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>116</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>122</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>116</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              very_pos  very_neg\n",
              "airline                         \n",
              "americanair        118        31\n",
              "delta              116        55\n",
              "jetblue             10         2\n",
              "southwestair       122        34\n",
              "united             116        99"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In3HBOxx9IN2"
      },
      "source": [
        "`airline` is now the _index_ of the frame: values of the index identify each row (much like a primary key in a database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQLL_qnb9IN2"
      },
      "source": [
        "For every company, we compute the sum of very positive and very negative tweets..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8cE82zg9IN2"
      },
      "source": [
        "twitter_score[\"all_count\"] = twitter_score.very_pos + twitter_score.very_neg"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFcIG4YN9IN4"
      },
      "source": [
        "...then we compute a \"global sentiment score\" as the percentage between the count of positive tweets and the total count of tweets above"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UwlgKs19IN5"
      },
      "source": [
        "twitter_score[\"score\"] = 100 * twitter_score.very_pos / twitter_score.all_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNz_-VSt9IN7"
      },
      "source": [
        "Let's now list the companies ranked by their score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "KlEyMUuX9IN7",
        "outputId": "36d6774f-7b49-4b5d-8b00-87a1d7de0e98"
      },
      "source": [
        "twitter_score.sort_values(\"score\", ascending=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>very_pos</th>\n",
              "      <th>very_neg</th>\n",
              "      <th>all_count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>83.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "      <td>149</td>\n",
              "      <td>79.195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>122</td>\n",
              "      <td>34</td>\n",
              "      <td>156</td>\n",
              "      <td>78.205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>116</td>\n",
              "      <td>55</td>\n",
              "      <td>171</td>\n",
              "      <td>67.836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>116</td>\n",
              "      <td>99</td>\n",
              "      <td>215</td>\n",
              "      <td>53.953</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              very_pos  very_neg  all_count   score\n",
              "airline                                            \n",
              "jetblue             10         2         12  83.333\n",
              "americanair        118        31        149  79.195\n",
              "southwestair       122        34        156  78.205\n",
              "delta              116        55        171  67.836\n",
              "united             116        99        215  53.953"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pav5BKXF9IN8"
      },
      "source": [
        "To simplify subsequent tests, we create a function which, given a series of scores for tweets, executes the steps above to extract summary scores for each airline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VNj8OLsF9IN8"
      },
      "source": [
        "def get_summary_scores(tweet_scores):\n",
        "    very_pos_tweets = tweet_scores >= 2\n",
        "    very_neg_tweets = tweet_scores <= -2\n",
        "    very_pos = very_pos_tweets.groupby(tweets[\"airline\"]).sum()\n",
        "    very_neg = very_neg_tweets.groupby(tweets[\"airline\"]).sum()\n",
        "    total = very_pos + very_neg\n",
        "    return 100 * (very_pos / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Img7WOX9IN-"
      },
      "source": [
        "### Comparing results with known customer satisfaction\n",
        "\n",
        "We can extract known information about the general satisfaction of airline companies from the ACSI (_American Customer Satisfaction Index_) website\n",
        "\n",
        "A table of the satisfaction index by year about airline companies is available at http://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\n",
        "\n",
        "We can import such data and use it to validate the satisfaction score extracted from Twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWYVF1x09IN-"
      },
      "source": [
        "pandas provides the `read_html` function to get DataFrames by scraping tables from a Web page (the `lxml` and `BeautifulSoup4` packages must be installed)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzQcr8ci9IN-"
      },
      "source": [
        "import ssl\n",
        "# it overrides the default function for context creation with the function to create an unverified context\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "acsi_table = pd.read_html(\n",
        "    \"https://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\",\n",
        "    header=0, index_col=0)[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "id": "_-CPi6_M9IOA",
        "outputId": "1b12a7bf-c309-458a-86a8-4c799530cb6a"
      },
      "source": [
        "acsi_table.iloc[:10,-5:] "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>PreviousYear%Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Southwest</th>\n",
              "      <td>80.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>79.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>-1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JetBlue</th>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>77.0</td>\n",
              "      <td>-1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Airlines</th>\n",
              "      <td>73.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United</th>\n",
              "      <td>67.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American</th>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Others</th>\n",
              "      <td>73.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>5.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Allegiant</th>\n",
              "      <td>74.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>72.0</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frontier</th>\n",
              "      <td>62.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>66.0</td>\n",
              "      <td>68.0</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              18    19    20    21  PreviousYear%Change\n",
              "Delta       74.0  75.0  77.0  79.0                  2.6\n",
              "Southwest   80.0  79.0  79.0  79.0                  0.0\n",
              "Alaska      79.0  80.0  78.0  77.0                 -1.3\n",
              "JetBlue     79.0  79.0  78.0  77.0                 -1.3\n",
              "Airlines    73.0  74.0  75.0  76.0                  1.3\n",
              "United      67.0  70.0  75.0  75.0                  0.0\n",
              "American    74.0  73.0  74.0  75.0                  1.4\n",
              "All Others  73.0  71.0  70.0  74.0                  5.7\n",
              "Allegiant   74.0  71.0  74.0  72.0                 -2.7\n",
              "Frontier    62.0  64.0  66.0  68.0                  3.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4mE8sbW9IOB"
      },
      "source": [
        "We select the column \"13\" for the year when tweets were extracted (use \"21\" in case you are analyzing current tweets) and the rows related to analyzed companies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jJfNKq39IOB"
      },
      "source": [
        "airline_names = [\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        "acsi_score = acsi_table.loc[airline_names, \"13\"].astype(float).sort_index() # loc() function let us select only certain columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg7Ug9C9IOE",
        "outputId": "30b0508e-cd2a-4fd4-e0d9-f2ee0298e93d"
      },
      "source": [
        "acsi_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "American     65.0\n",
              "Delta        68.0\n",
              "JetBlue      83.0\n",
              "Southwest    81.0\n",
              "United       62.0\n",
              "Name: 13, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5F0584r9IOF"
      },
      "source": [
        "In case you miss the required libraries, here are two alternative instructions to create the ACSI scores series without using the `read_html` function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wroivXas9IOF"
      },
      "source": [
        "# 2021 (current_tweets)\n",
        "acsi_score = pd.Series(\n",
        "          [      79.0 ,     77.0 ,      75.0 ,   79.0 ,    75.0 ],\n",
        "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        ").sort_index()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpIwLxb39IOG",
        "outputId": "58c78eee-addb-498c-8610-8f9c088c182f"
      },
      "source": [
        "# 2013 (archive_tweets)\n",
        "acsi_score = pd.Series(\n",
        "          [      81.0 ,     83.0 ,      65.0 ,   68.0 ,    62.0 ],\n",
        "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        ").sort_index()\n",
        "\n",
        "acsi_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "American     65.0\n",
              "Delta        68.0\n",
              "JetBlue      83.0\n",
              "Southwest    81.0\n",
              "United       62.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOIy6Cvd9IOH"
      },
      "source": [
        "We extracted a single column of the table along with the index containing company names: we change names in order to match the index from `twitter_scores`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-B_8edSA9IOH"
      },
      "source": [
        "acsi_score.index = (acsi_score.index\n",
        "                    .str.lower()\n",
        "                    .str.replace(\"american\", \"americanair\")\n",
        "                    .str.replace(\"southwest\", \"southwestair\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJTUitHH9IOI",
        "outputId": "e26f388e-2066-4d39-bcb3-e34a68c685ce"
      },
      "source": [
        "acsi_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "americanair     65.0\n",
              "delta           68.0\n",
              "jetblue         83.0\n",
              "southwestair    81.0\n",
              "united          62.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDcu3Kfx9IOJ"
      },
      "source": [
        "We have now the `acsi_score` series and the `score` column of the `twitter_score` frame indexed with the same labels, but in different order: we can merge them into a new frame to align the series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "hhtsXGno9IOJ",
        "outputId": "0b7b9bb8-6ac6-4063-84a6-a86f582ee701"
      },
      "source": [
        "pd.DataFrame({\"twitter\": twitter_score[\"score\"], \"acsi\": acsi_score})"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitter</th>\n",
              "      <th>acsi</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>79.195</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>67.836</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>83.333</td>\n",
              "      <td>83.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>78.205</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>53.953</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              twitter  acsi\n",
              "airline                    \n",
              "americanair    79.195  65.0\n",
              "delta          67.836  68.0\n",
              "jetblue        83.333  83.0\n",
              "southwestair   78.205  81.0\n",
              "united         53.953  62.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZhczxte9IOK"
      },
      "source": [
        "We can now evaluate the degree of agreement between the two scores: we may do it graphically using a _scatter plot_..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pFLxT67U9IOK",
        "outputId": "f7026269-f534-45fd-e6e2-39e3ab16b2f7"
      },
      "source": [
        "plt.scatter(twitter_score[\"score\"], acsi_score, s=50) # plt.scatter() function is used to plot points. 's' parameters can be use to set the point dimension\n",
        "plt.plot([50, 100], [50, 100], \"r--\")  # plot a x=y segment. First two parameters represents the coordinates of the segment, while the third one let us draw red dashes\n",
        "plt.xlabel(\"Twitter score\")\n",
        "plt.ylabel(\"ACSI score\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL-_tWRJ9IOL"
      },
      "source": [
        "Each point indicates the scores of a company, the dashed line indicates where scores match: the most the points are close to the line, the most the scores agree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ8Q-miJ9IOM"
      },
      "source": [
        "To properly verify the agreement of the two scores, we measure the _Pearson's correlation coefficient_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fLMeuQd9IOM",
        "outputId": "5212ac17-b64a-4e3a-fcc3-490c63934182"
      },
      "source": [
        "from scipy.stats import pearsonr\n",
        "pearson_coeff, pvalue = pearsonr(twitter_score[\"score\"], acsi_score)\n",
        "pearson_coeff, pvalue"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.7229235158616781, 0.167611728008456)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igRoHtv-9ION"
      },
      "source": [
        "The first value is the Pearson's coefficient, while the second value is the associated p-value, i.e. the probability that the correlation between the two series was obtained by chance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1wEVYlPl1Wh"
      },
      "source": [
        "To decide if the two ACSI distributions and ours are equivalent it is necessary\n",
        "1. set a confidence level, for example $0.80$\n",
        "2. check if $pvalue < (1-0.80) = 0.20$; \n",
        "\n",
        "\n",
        "In this case pvalue is $< 0.20$ so we decide that the difference between the two distributions is the result of chance, i.e. the difference is not statistically significant, in other words they are equivalent."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps1-Zgh-lkMw",
        "outputId": "e5f6aae8-5226-4f41-b516-6b267e55140b"
      },
      "source": [
        "confidence_level = 0.80\n",
        "alpha = (1 - confidence_level)\n",
        "\n",
        "if pvalue < alpha:\n",
        "  print(\"Our distribution and ACSI one are equivalent!\")\n",
        "else:\n",
        "  print(\"Our distribution and ACSI one are different!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our distribution and ACSI one are equivalent!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x0CVCda9ION"
      },
      "source": [
        "### Exercise 1: interpreting negations\n",
        "\n",
        "In the `sentiment_score` function, when we look for positive or negative words, we do not consider whether they are negated\n",
        "\n",
        "**A)** The `sentiment_score_neg` function below implements the same logic of `sentiment_score` so that it can be more easily changed: modify it in order to count any positive word immediately preceded by \"not\" (case-insensitive) as negative and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_ebKPt09IOP"
      },
      "source": [
        "def sentiment_score_neg(text, pos_words, neg_words):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    score = 0\n",
        "    for i in range(len(words)):\n",
        "        word_score = 0\n",
        "        if words[i] in pos_words:\n",
        "            word_score = 1\n",
        "        elif words[i] in neg_words:\n",
        "            word_score = -1\n",
        "        score += word_score\n",
        "    return score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eozF1o_R9IOQ"
      },
      "source": [
        "**B)** Create a series `tweet_scores_neg` (using the `sentiment_score_neg` function developed in the previous point) with scores of tweets in `tweets[\"text\"]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYBWW05y9IOQ"
      },
      "source": [
        "**C)** Compute the mean absolute difference between this previous score and the new score of each tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8wVHZ-R9IOQ"
      },
      "source": [
        "**D)** Use the `get_summary_scores` defined above to get a series `twitter_score_neg` with summary scores for each airline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9sRf63e9IOQ"
      },
      "source": [
        "**E)** Verify the correlation between the new Twitter score and the ACSI score using a scatter plot and Pearson's coefficient as above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygvv94X9IOQ"
      },
      "source": [
        "## Activity 2: Sentiment Analysis at sentence and feature level\n",
        "\n",
        "We reuse techniques seen above to perform sentiment analysis at sentence and feature level on reviews of hotels\n",
        "\n",
        "TripAdvisor used to provide a summary of hotel ratings against 6 different features: **Location, Sleep Quality, Rooms, Service, Value, Cleanliness**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwNfCgBU9IOR"
      },
      "source": [
        "### Activity plan\n",
        "\n",
        "1. Define lists of opinion and feature words\n",
        "  - for opinion words, we reuse the lists of Hu and Liu from above\n",
        "2. Break reviews into sentences\n",
        "3. Detect sentences dealing with a specific feature and score its sentiment\n",
        "4. Summarize evaluation of each hotel and each feature\n",
        "5. Compare features of each hotel\n",
        "6. Compare results with scores on TripAdvisor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf0Kw1v49IOR"
      },
      "source": [
        "### Loading reviews\n",
        "\n",
        "We provide a ZIP file with reviews of 6 different Hotels in Chicago, in a format similar to that of airline tweets used above (one file per hotel, one review per line)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kOhA6CRF9IOR"
      },
      "source": [
        "download(\"hotel-reviews.zip\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/hotel-reviews.zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMYKO7r39IOT",
        "outputId": "80ff896b-5bfe-46a0-87df-bc89101618ed"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import re\n",
        "\n",
        "all_reviews = {} # Init an empty dictionary that will be used to collect all the reviews\n",
        "\n",
        "# Define the regular expression that matches the reviews filenames.\n",
        "filename_pattern = re.compile(\"usa_illinois_chicago_([a-z_]+).txt\") # ([a-z_]+) means: \"one or more groups of alphabetic characters followed by an underscore\"\n",
        "\n",
        "with ZipFile(\"hotel-reviews.zip\") as zip: # open the zip file and read the files inside\n",
        "\n",
        "    for filename in zip.namelist(): # we repeat the following statements for each file inside the zip in order to collect the text of each hotel. 1 file --> 1 hotel\n",
        "        print(filename)\n",
        "        # match() returns a match object if one or more characters at the beginning of string match this regular expression, None otherwise. \n",
        "        # Then we call the group() method on the match object: group(1) returns the matched content of the first parenthesized subgroup in the regular expression\n",
        "        hotel = filename_pattern.match(filename).group(1) \n",
        "\n",
        "        print(hotel)\n",
        "\n",
        "        with zip.open(filename) as f: # open each txt file to read its content (i.e the reviews texts)\n",
        "            # for each file: decode each line of the file to UTF-8 encoding (to properly read the string), delete spaces at beginning/end of the string using strip()\n",
        "            # put each transformed line in a list using list()\n",
        "            # put the list of lines of the current file in a new entry of all_reviews dictionary\n",
        "            all_reviews[hotel] = list(line.decode(errors=\"ignore\").strip() for line in f) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usa_illinois_chicago_affinia_chicago.txt\n",
            "affinia_chicago\n",
            "usa_illinois_chicago_hyatt_regency_chicago.txt\n",
            "hyatt_regency_chicago\n",
            "usa_illinois_chicago_intercontinental_chicago.txt\n",
            "intercontinental_chicago\n",
            "usa_illinois_chicago_james_chicago.txt\n",
            "james_chicago\n",
            "usa_illinois_chicago_swissotel_chicago.txt\n",
            "swissotel_chicago\n",
            "usa_illinois_chicago_the_palmer_house_hilton.txt\n",
            "the_palmer_house_hilton\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aGIOvin9IOU"
      },
      "source": [
        "As an example, we will use reviews for the Intercontinental hotel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjuPCyyq9IOV"
      },
      "source": [
        "reviews_interc = all_reviews[\"intercontinental_chicago\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "WHYJMRsK9IOX",
        "outputId": "86d757be-5dbd-4ece-ce55-efeecda87537"
      },
      "source": [
        "reviews_interc[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'A great spot! We have always been pleased with our stays at Intercontinental hotels. Chicago was especially pleasant with a helpful staff.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 196
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbemiaFE9IOY"
      },
      "source": [
        "### Lists of feature words\n",
        "\n",
        "To detect sentences dealing with a specific feature, we search for feature-related keywords\n",
        "\n",
        "Using only the names of the 6 features as keywords, would produce few results: lists of _feature words_ which are synonyms or anyhow else related to each feature is created (manually in this case)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S-3DBtSl9IOZ"
      },
      "source": [
        "feature_words = {\n",
        "    'location': {'location', 'airport', 'center', 'island', 'lake', 'ocean',\n",
        "                 'sea', 'around', 'university', 'romantic', 'coast', 'beach',\n",
        "                 'disco', 'nightlife'},\n",
        "    'sleepquality': {'silence','sleep','night','noise','nightlife'},\n",
        "    'rooms': {'room', 'rooms', 'space', 'bed', 'bath', 'bathroom', 'toilet',\n",
        "              'degrade', 'disorder','shower','jacuzzi','frigo'},\n",
        "    'service': {'service','pet','friendly','swimming', 'pool', 'pools', 'spa',\n",
        "                'waiters', 'severs', 'waiter', 'manservant', 'cordial',\n",
        "                'hearty', 'restorative', 'disagreeable', 'unpleasant',\n",
        "                'restaurant', 'food', 'breakfast', 'lunch', 'dinner', 'bar'},\n",
        "    'value': {'cheap','affordable','afford','woth', 'price', 'value', 'cost',\n",
        "              'expensive', 'economical', 'depreciate', 'discount', 'luxury',\n",
        "              'hall', 'meal'},\n",
        "    'cleanliness': {'clean', 'cleanliness', 'place', 'neatness', 'sweeping',\n",
        "                    'dirty', 'soiled', 'grubby', 'foul', 'mucky'}\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa3tsTGX9IOa"
      },
      "source": [
        "### Breaking reviews into sentences\n",
        "\n",
        "We break reviews into single sentences, assuming that each sentence deals with (at most) one of the features\n",
        "\n",
        "Breaking text into sentences (_sentence tokenization_) is not straightforward: sentences usually end with a period (\".\"), but may also end with other punctuation (\"!\", \"?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLGtjlvH9IOa"
      },
      "source": [
        "This is an example of function for sentence tokenization, which splits text on \".\", \"?\" and \"!\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtYfbWuB9IOa"
      },
      "source": [
        "def my_sent_tokenizer(text):\n",
        "    return re.split(\"[\\\\.\\\\?!]\", text) #\\\\ operator escapes the dot and question mark characters. This is needed because '.' and '?' are special characters in regex syntax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-qawU1O9IOb",
        "outputId": "57424001-be31-48d8-fcab-84542e339e06"
      },
      "source": [
        "my_sent_tokenizer(reviews_interc[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['A great spot',\n",
              " ' We have always been pleased with our stays at Intercontinental hotels',\n",
              " ' Chicago was especially pleasant with a helpful staff',\n",
              " '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 199
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsr537m99IOe"
      },
      "source": [
        "However this function fails when these characters are used in the middle of a sentence, e.g. in an ellipsis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwOjGfT9IOe",
        "outputId": "b3ad3583-d06c-4a0a-8c1a-2b37ebd308f4"
      },
      "source": [
        "my_sent_tokenizer(\"This works... or not? Maybe not.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This works', '', '', ' or not', ' Maybe not', '']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGF6ez9s9IOf"
      },
      "source": [
        "Similarly to the word tokenizer used above, NLTK provides a sentence tokenizer based on knowledge of English language to detect such exceptions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urU6hiB9IOg",
        "outputId": "2422018a-8f0e-4f23-b796-140653a22ca8"
      },
      "source": [
        "nltk.sent_tokenize(\"This works... or not? Maybe not.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['This works... or not?', 'Maybe not.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFIWabkV9IOh"
      },
      "source": [
        "Using this tokenization function, we turn the list of reviews into a list of single sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz-aaqP39IOh"
      },
      "source": [
        "sentences_interc = [sent for review in reviews_interc for sent in nltk.sent_tokenize(review)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWUuSZu49IOi"
      },
      "source": [
        "### Detecting features and opinions in sentences\n",
        "\n",
        "We define a function which counts, for each feature, the number of sentences in a given list expressing a positive or negative judgement about it"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qxb70Fj9IOi"
      },
      "source": [
        "def feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words):\n",
        "    # initialize to 0 counts of positive and negative sentences per feature\n",
        "    pos_counts = {feat: 0 for feat in feature_words.keys()}\n",
        "    neg_counts = {feat: 0 for feat in feature_words.keys()} \n",
        "    # {\n",
        "    #  \"value\": 0,\n",
        "    #  \"service\": 0,\n",
        "    #  ...\n",
        "    # }\n",
        "\n",
        "    for sent in sentences: # analyze each sentence in the sentences list passed as argument to this function\n",
        "\n",
        "        # evaluate sentiment of sentence\n",
        "        word_list = nltk.word_tokenize(sent) # e.g. nltk.word_tokenize(\"This isn't a test, or is it?\") --> ['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']\n",
        "        pos_word_count = sum(1 for word in word_list if word in pos_words) # Sum 1 for each positive word found in the sentence. E.g. 2\n",
        "        neg_word_count = sum(1 for word in word_list if word in neg_words) # Sum 1 for each negative word found in the sentence. E.g. 3\n",
        "        sent_score = pos_word_count - neg_word_count # E.g. 2 - 3 = -1\n",
        "\n",
        "        # detect features in sentence\n",
        "        word_set = set(word_list) # e.g. {'this', 'is', \"n't\", \"a\", \"test\", \",\", \"or\", \"it\", \"?\"}   No words are repeated since we use a set!\n",
        "        for feat, keywords in feature_words.items(): # loop over each feature (e.g. value, service, ...) to analyze features in the current sentence (i.e. the variable named 'sent')\n",
        "            if word_set & keywords: # if the intersection between the sentence word set and the feature keywords is not empty (i.e. the sentence contains at least one of the current feature keywords)\n",
        "                if sent_score > 0: # if the sentence polarity is positive\n",
        "                    pos_counts[feat] += 1 # increment by one the positive counter of the current feature we are analyzing\n",
        "                elif sent_score < 0: # if the sentence polarity is negative\n",
        "                    neg_counts[feat] += 1 # increment by one the negative counter of the current feature we are analyzing\n",
        "\n",
        "    # At the end of the positive/negative counts for each feature, we create a new dataframe containing the features as rows and the two counters as columns\n",
        "    return pd.DataFrame({\"pos_count\": pos_counts, \"neg_count\": neg_counts})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmR31Yb9IOj"
      },
      "source": [
        "For each list of sentences, the function returns a DataFrame with counts of positive and negative sentences for each feature\n",
        "\n",
        "Let's apply it for example to reviews of Intercontinental"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sl6kJjaF9IOk"
      },
      "source": [
        "scores_interc = feature_pos_neg_counts(sentences_interc, feature_words, hu_liu_pos, hu_liu_neg)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "ODajRR8-9IOk",
        "outputId": "58060c0e-11ff-4421-ea06-035b6efa56f3"
      },
      "source": [
        "scores_interc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_count</th>\n",
              "      <th>neg_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <td>231</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sleepquality</th>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rooms</th>\n",
              "      <td>423</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>370</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleanliness</th>\n",
              "      <td>131</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pos_count  neg_count\n",
              "location            231         18\n",
              "sleepquality         50         28\n",
              "rooms               423         92\n",
              "service             370         55\n",
              "value                70         34\n",
              "cleanliness         131         11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5smNWpx9IOl"
      },
      "source": [
        "### Summarizing evaluation of hotel features\n",
        "\n",
        "Similarly to above, we compute for each feature a sentiment score in a 0-50 scale from the ratio of positive sentences about a feature w.r.t. their total"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvyHtRYs9IOm"
      },
      "source": [
        "scores_interc[\"tot_count\"] = scores_interc.pos_count + scores_interc.neg_count"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NxSaH52X9IOn"
      },
      "source": [
        "scores_interc[\"score\"] = round(50 * scores_interc.pos_count / scores_interc.tot_count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "TPqAtJN99IOo",
        "outputId": "ba49dcf2-6d8e-42d5-95f5-1512c9197942"
      },
      "source": [
        "scores_interc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_count</th>\n",
              "      <th>neg_count</th>\n",
              "      <th>tot_count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <td>231</td>\n",
              "      <td>18</td>\n",
              "      <td>249</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sleepquality</th>\n",
              "      <td>50</td>\n",
              "      <td>28</td>\n",
              "      <td>78</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rooms</th>\n",
              "      <td>423</td>\n",
              "      <td>92</td>\n",
              "      <td>515</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>370</td>\n",
              "      <td>55</td>\n",
              "      <td>425</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "      <td>104</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleanliness</th>\n",
              "      <td>131</td>\n",
              "      <td>11</td>\n",
              "      <td>142</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pos_count  neg_count  tot_count  score\n",
              "location            231         18        249   46.0\n",
              "sleepquality         50         28         78   32.0\n",
              "rooms               423         92        515   41.0\n",
              "service             370         55        425   44.0\n",
              "value                70         34        104   34.0\n",
              "cleanliness         131         11        142   46.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCoak-S39IOp"
      },
      "source": [
        "In order to easily repeat this process for every hotel, we wrap it in a function which takes as input the list of reviews and returns the Series with the final scores per feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL4QJitL9IOp"
      },
      "source": [
        "def feature_scores(reviews, feature_words, pos_words, neg_words):\n",
        "    sentences = [sent for review in reviews for sent in nltk.sent_tokenize(review)]\n",
        "    counts = feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words)\n",
        "    total = counts.pos_count + counts.neg_count\n",
        "    return round(50 * counts.pos_count / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF2X1PJN9IOq",
        "outputId": "b07cc998-e4d1-4e66-f392-be1b7ee37bc4"
      },
      "source": [
        "feature_scores(reviews_interc, feature_words, hu_liu_pos, hu_liu_neg)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "location        46.0\n",
              "sleepquality    32.0\n",
              "rooms           41.0\n",
              "service         44.0\n",
              "value           34.0\n",
              "cleanliness     46.0\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovCL19qT9IOr"
      },
      "source": [
        "Let's create a DataFrame with feature scores for all analyzed hotels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnPw_fR_9IOr"
      },
      "source": [
        "scores = pd.DataFrame({hotel: feature_scores(reviews, feature_words, hu_liu_pos, hu_liu_neg) for hotel, reviews in all_reviews.items()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "eZMYfs7G9IOs",
        "outputId": "479fb1bc-67b1-4a26-a41a-9c309512da98"
      },
      "source": [
        "print(scores)\n",
        "\n",
        "scores.T   # transpose the table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              affinia_chicago  ...  the_palmer_house_hilton\n",
            "location                 45.0  ...                     45.0\n",
            "sleepquality             25.0  ...                     26.0\n",
            "rooms                    42.0  ...                     37.0\n",
            "service                  45.0  ...                     40.0\n",
            "value                    39.0  ...                     35.0\n",
            "cleanliness              46.0  ...                     44.0\n",
            "\n",
            "[6 rows x 6 columns]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>sleepquality</th>\n",
              "      <th>rooms</th>\n",
              "      <th>service</th>\n",
              "      <th>value</th>\n",
              "      <th>cleanliness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>affinia_chicago</th>\n",
              "      <td>45.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hyatt_regency_chicago</th>\n",
              "      <td>45.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intercontinental_chicago</th>\n",
              "      <td>46.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>james_chicago</th>\n",
              "      <td>47.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swissotel_chicago</th>\n",
              "      <td>44.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the_palmer_house_hilton</th>\n",
              "      <td>45.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          location  sleepquality  ...  value  cleanliness\n",
              "affinia_chicago               45.0          25.0  ...   39.0         46.0\n",
              "hyatt_regency_chicago         45.0          27.0  ...   30.0         42.0\n",
              "intercontinental_chicago      46.0          32.0  ...   34.0         46.0\n",
              "james_chicago                 47.0          30.0  ...   35.0         46.0\n",
              "swissotel_chicago             44.0          32.0  ...   34.0         46.0\n",
              "the_palmer_house_hilton       45.0          26.0  ...   35.0         44.0\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRg2vywT9IOv"
      },
      "source": [
        "We can create a bar plot to compare the hotels by each feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "Z77JJX999IOv",
        "outputId": "028951bb-4033-4b13-d958-bbb851ab20b1"
      },
      "source": [
        "scores.plot.bar()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f1eb7f1afd0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr17VRMp9IOw"
      },
      "source": [
        "### Comparing scores with TripAdvisor\n",
        "\n",
        "Obtained scores can be compared with the feature ratings which were computed by TripAdvisor up to some time ago\n",
        "\n",
        "![hotel ratings](https://www.dropbox.com/s/pq6q9ugsaessow6/hotel-ratings.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k9gENE_9IOw"
      },
      "source": [
        "## Activity 3: Classification of Reviews via Supervised Training\n",
        "\n",
        "**Goal:** classify user reviews of movies extracted from IMDB as positive or negative\n",
        "\n",
        "Contrarily to previous activities, this time we will train a classificaton model on existing reviews instead of using manually set keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXWxfW1Q9IOw"
      },
      "source": [
        "### Loading reviews\n",
        "\n",
        "We load reviews from a GZIP-compressed CSV file of 10,000 movie reviews, alternated between positive and negative"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyb5edlH9IOx"
      },
      "source": [
        "download(\"acl-10k.csv.gz\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/acl-10k.csv.gz\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pUWkUCnB9IOy"
      },
      "source": [
        "reviews = pd.read_csv(\"acl-10k.csv.gz\", sep=\"\\t\", header=None, names=[\"label\", \"text\"], compression=\"gzip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 239
        },
        "id": "gYE_BFzX9IOz",
        "outputId": "b69579c0-385d-45fd-f54c-1acf16c4633c"
      },
      "source": [
        "reviews.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                                                                                 text\n",
              "0   pos  Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...\n",
              "1   neg  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...\n",
              "2   pos  If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...\n",
              "3   neg  Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...\n",
              "4   pos  Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 203
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U172DUlL9IO0"
      },
      "source": [
        "In order to validate the goodness of automated classification, we use the _hold-out_ approach: a part of the reviews is used to train a classifier, while the remaining ones are used to assess its accuracy\n",
        "\n",
        "Let's select the first half of the reviews as the _training set_ and the second half as the _test set_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxsrEToT9IO0"
      },
      "source": [
        "reviews_train = reviews[:5000] # first 5000 reviews\n",
        "reviews_test = reviews[5000:] # last 5000 reviews"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSndGPba9IO1"
      },
      "source": [
        "### Bag of Words and Vector Space Model\n",
        "\n",
        "In order to train and use a classifier on reviews, we have to define the _features_ which represent them\n",
        "\n",
        "With the _Bag of Words_ model we represent each review as the set of words contained in it, regardless of their order\n",
        "\n",
        "Once defined a set of known words, we can represent each review with a vector indicating for each word the number of occurrencies in the text; a set of reviews can be be consequently represented as a _document-term matrix_ with a row vector for each review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Wvi4Uo9IO1"
      },
      "source": [
        "Let's define a list of example text documents..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CV26ZAf49IO1"
      },
      "source": [
        "docs = [\n",
        "    \"the sky is blue\",\n",
        "    \"sky is blue and sky is beautiful\",\n",
        "    \"the beautiful sky is so blue\",\n",
        "    \"i love blue cheese\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MossE1cR9IO2"
      },
      "source": [
        "A `CountVectorizer` extracts a vector for each document with counts of distinct words in it: we start from creating an \"empty\" vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeRiIqIZ9IO2"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abjwprh_9IO3"
      },
      "source": [
        "We use the `fit_transform` method passing the list of documents to\n",
        "\n",
        "- \"build\" the vector space with dimensions corresponding to words within them (_fit_)\n",
        "- return the document-term matrix representing them (_transform_)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaqE_cGv9IO3",
        "outputId": "250877a5-b08e-4559-df4a-3856858761b7"
      },
      "source": [
        "dtm = vect.fit_transform(docs)\n",
        "dtm # 4 x 9 matrix, 4 rows represent the number of documents, 9 columns represent the number of distinct words found within them"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 18 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNyRpX6J9IO4"
      },
      "source": [
        "The obtained `dtm` matrix contains a row for each document and a column for each distinct word found within documents: we can obtain a list of the words \"learned\" by the vectorizer..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsirTqtE9IO4",
        "outputId": "2e5585d5-550f-4336-bea3-2c2086807ba7"
      },
      "source": [
        "vect.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['and', 'beautiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vDbPWyr9IO5"
      },
      "source": [
        "Let's view the matrix as a DataFrame, labeling rows and columns with corresponding documents and features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "C8xOa6zB9IO5",
        "outputId": "c48d35c6-55f0-4c1d-b56e-06fc51486269"
      },
      "source": [
        "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the sky is blue</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sky is blue and sky is beautiful</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the beautiful sky is so blue</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i love blue cheese</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  and  beautiful  blue  ...  sky  so  the\n",
              "the sky is blue                     0          0     1  ...    1   0    1\n",
              "sky is blue and sky is beautiful    1          1     1  ...    2   0    0\n",
              "the beautiful sky is so blue        0          1     1  ...    1   1    1\n",
              "i love blue cheese                  0          0     1  ...    0   0    0\n",
              "\n",
              "[4 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoJFPERf9IO6"
      },
      "source": [
        "As we can see, the matrix indicates for each document the number of occurrencies of each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRH85pEK9IO6"
      },
      "source": [
        "Using the `transform` method, we can represent further documents in the same vector space"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNvHGGTU9IO6"
      },
      "source": [
        "new_docs = [\"loving this blue sky today\"]\n",
        "new_dtm = vect.transform(new_docs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "k3ZWv5yl9IO7",
        "outputId": "133c1be6-888e-4025-fce6-6bb07b17d84d"
      },
      "source": [
        "pd.DataFrame(new_dtm.toarray(), index=new_docs, columns=vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>loving this blue sky today</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            and  beautiful  blue  cheese  ...  love  sky  so  the\n",
              "loving this blue sky today    0          0     1       0  ...     0    1   0    0\n",
              "\n",
              "[1 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdXF5wcL9IO-"
      },
      "source": [
        "Notice that some words of the new document (e.g. \"loving\") are lost in the representation, because they are not known in the vector space, but this is generally a minor problem if the vector space is built on many documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEB3lHRu9IO_"
      },
      "source": [
        "### Training a classifier\n",
        "\n",
        "We use the vector space model to represent reviews passed to a classifier: let's create a new vector space..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AaeFZphn9IPA"
      },
      "source": [
        "vect = CountVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxVsu06v9IPB"
      },
      "source": [
        "...and fit it to reviews of the training set only (as we assume to _not_ know in advance documents of the test set), obtaining the document-term matrix representing them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ19rE7L9IPB"
      },
      "source": [
        "dtm_train = vect.fit_transform(reviews_train.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvHsj5Jh9IPC"
      },
      "source": [
        "We can get the total count of extracted feature words..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUqEZwSn9IPC",
        "outputId": "e0a46590-f069-443c-f1b6-9602eff24769"
      },
      "source": [
        "len(vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9puiLl9IPD"
      },
      "source": [
        "...and see some of them (they are in alphabetical order)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8nvNkQL9IPD",
        "outputId": "90ff81c6-79aa-4b08-87da-b6d1cb0fee74"
      },
      "source": [
        "vect.get_feature_names()[1000:1005]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['affections', 'affects', 'afficinados', 'affiliated', 'affiliation']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEbpXAp49IPE"
      },
      "source": [
        "The document-term matrix is _sparse_, meaning that most of its elements are zero. We can verify the ratio of non-zero elements by converting them to booleans and computing the mean value (all non-zero values become 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ4TYTLb9IPE",
        "outputId": "36d3c3f0-f8ef-4eb8-8947-df82fc8fe932"
      },
      "source": [
        "dtm_train.astype(bool).mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0037657973092192322"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-5Ij_zz9IPF"
      },
      "source": [
        "Such matrix is represented in memory with a space-efficient data structure which explicitly stores non-zero values only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MtpO5hF9IPF"
      },
      "source": [
        "Now we can train any classification model on the generated vectors: let's use for example logistic regression, SVM and some bayesian models.\n",
        "\n",
        "As for the vectorizer, we first create the \"empty\" model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UV3gt-5wxKxW"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB() # Naive Bayes classifier for multinomial models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDV_JuKf-ieE"
      },
      "source": [
        "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd6GUeZ6yEno"
      },
      "source": [
        "from sklearn.naive_bayes import BernoulliNB # Naive Bayes classifier for multivariate Bernoulli models.\n",
        "# The default parameter named \"binarize\" will transform each input vector in a\n",
        "# binary vector based on the specified threshold (0.0)\n",
        "model = BernoulliNB(binarize=0.0) # if input > 0.0 then 1 else 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyakhXB4z-v"
      },
      "source": [
        "Like MultinomialNB, this classifier is suitable for discrete data but it usually works better with few features and **short docs**. \n",
        "Indeed, this latter Naive Bayes model will perform better (Accuracy: $\\approx$ 77% vs $\\approx$ 81%) than the multinomial version since we are dealing with short texts.\n",
        "\n",
        "The difference is that while MultinomialNB works better with occurrence counts, BernoulliNB is designed for binary/boolean features! Since we have the frequency count for each term, we have to convert it into a binary variable but the BernoulliNB implementation already do this mapping!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rNKFlWZ09Ko"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC() # default kernel is set to RBF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dY6AnK61uJ6"
      },
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "model = LinearSVC(max_iter = 5000) # max_iter param represents the maximum number of iterations performed by the optimization algorithm used to train the model by the sklearn library"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYCAZu2v4C1L"
      },
      "source": [
        "SVM generally does just as well on textual data without using kernels because the multidimensional space is so vast that the probability of finding a separation hyperplane is similar to that of finding a nonlinear separation.\n",
        "In other words you can notice that with or without a kernel the result does not change significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_lVIQnAS-A"
      },
      "source": [
        "Let's go on creating a logistic regression model..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1jtFH7fT9IPF"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver=\"liblinear\") # liblinear is an optimization algorithm recommended for small volume (small number of rows) and high dimension (high number of columns) datasets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8die02Q9IPH"
      },
      "source": [
        "...then we fit it to the training set, passing the vector representation of the reviews along with their actual labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yda-8J79IPH",
        "outputId": "35c96949-df01-453e-dc9e-6de457e9b995"
      },
      "source": [
        "model.fit(dtm_train, reviews_train.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TiT04TP9IPI"
      },
      "source": [
        "### Using the classifier\n",
        "\n",
        "Once the classifier is trained, we can use it to estimate labels for further reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quyMXP829IPI"
      },
      "source": [
        "new_reviews = [\"What an awesome movie!\", \"It was really boring\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN_eCM4V9IPI"
      },
      "source": [
        "We first have to use the vectorizer to extract their representation in the vector space..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TImYsSgC9IPJ"
      },
      "source": [
        "dtm_new = vect.transform(new_reviews)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1JhS_eH9IPJ"
      },
      "source": [
        "...then we use the `predict` method of the model to get corresponding predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH3B9x-A9IPJ",
        "outputId": "ab869d65-51f2-4b36-f303-03d18ce2f8ae"
      },
      "source": [
        "model.predict(dtm_new)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['pos', 'neg'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XAeXqW9IPK"
      },
      "source": [
        "### Evaluating the classifier\n",
        "\n",
        "We can evaluate the goodness of the classifier by getting predicted labels for reviews in the test set and comparing them with known actual labels\n",
        "\n",
        "Given data and actual labels of the test set, the `score` method of the model computes the _accuracy_ as the ratio of test reviews for which classification is correct\n",
        "\n",
        "We first obtain the document-term matrix for the test set..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5t3vPmrv9IPK"
      },
      "source": [
        "dtm_test = vect.transform(reviews_test.text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p-rRVcK9IPM"
      },
      "source": [
        "...then we call the `score` method on it and on the known labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUGulqIl9IPM",
        "outputId": "833d4339-b8fb-4e0d-9539-9464b437df27"
      },
      "source": [
        "model.score(dtm_test, reviews_test.label) # classification accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8188"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rSJPrJY9IPN"
      },
      "source": [
        "### Creating a pipeline\n",
        "\n",
        "In all the operations above (training, predicting, evaluating) we had to manually convert text reviews into their vector representations before passing them to the model\n",
        "\n",
        "scikit-learn allows to create _pipelines_, which combine a prediction model with a sequence of one or more pre-processing steps into a single object\n",
        "\n",
        "We first create the pipeline by specifying its components, in this case the vectorizer and the actual classifier; each component has a name, allowing it to be referenced after creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGRxjDKU9IPO"
      },
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "model = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()), # Step 1\n",
        "    (\"classifier\", LogisticRegression(max_iter=500)) # Step 2\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS6yzG6m9IPO"
      },
      "source": [
        "Now, we can use the pipeline as we used the model above, but passing directly the text of reviews, as the vectorizer is automatically fit to reviews used to fit the model and used to transform all reviews passed to the classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXol6wfi9IPP"
      },
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);\n",
        "# \";\" is used to suppress output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9h8m8L9IPP",
        "outputId": "d30c4b03-3fdb-4671-c631-833103a16fa9"
      },
      "source": [
        "model.predict(new_reviews)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['pos', 'neg'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EYlXN3g9IPQ",
        "outputId": "2ecc58d9-c7ca-42ca-ee2d-507133a3160d"
      },
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8186"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L8flQBB9IPS"
      },
      "source": [
        "We obtain the same result as above, but with cleaner code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_s0lFHW9IPS"
      },
      "source": [
        "### Applying tf.idf term weighting\n",
        "\n",
        "The `CountVectorizer` generates vectors with simple counts of occurrencies of terms within a document, without considering the relative importance of such terms with respect to each other\n",
        "\n",
        "The _tf.idf_ term weighting scheme uses a formula with two factors to better evaluate the weight of each term in each document\n",
        "\n",
        "- The _tf_ factor evaluates the _local_ importance of a term in a document: it is usually the usual count of occurrencies of the term (or its logarithm)\n",
        "- The _idf_ factor evaluates the _global_ importance of a term in the set of documents: it is higher for terms appearing in fewer documents, as they are supposed to be more specific\n",
        "\n",
        "In order to use tf.idf in place of raw counts of occurrencies, we simply use `TfidfVectorizer` in place of `CountVectorizer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTWh-mql9IPS"
      },
      "source": [
        "Let's see for example the tf.idf applied to example documents used above..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "1adRlwwO9IPS",
        "outputId": "6c037b95-e0b4-4924-f6e0-5d283087f985"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer()\n",
        "dtm = vect.fit_transform(docs)\n",
        "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the sky is blue</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.399</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sky is blue and sky is beautiful</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the beautiful sky is so blue</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i love blue cheese</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    and  beautiful   blue  ...    sky     so    the\n",
              "the sky is blue                   0.000      0.000  0.399  ...  0.488  0.000  0.603\n",
              "sky is blue and sky is beautiful  0.441      0.347  0.230  ...  0.562  0.000  0.000\n",
              "the beautiful sky is so blue      0.000      0.432  0.286  ...  0.350  0.548  0.432\n",
              "i love blue cheese                0.000      0.000  0.346  ...  0.000  0.000  0.000\n",
              "\n",
              "[4 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TC1RFxK9IPU"
      },
      "source": [
        "We can see e.g. in the last document that \"cheese\" has an higher importance than \"blue\", being a less common and thus more discriminating word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6DC0EG49IPU"
      },
      "source": [
        "We employ tf.idf in our classification pipeline by replacing `CountVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ByQMYMeM9IPU"
      },
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C2jNFgP9IPW"
      },
      "source": [
        "As above, we fit the model on the training set and then evaluate it on the test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GmSW_6aS9IPW"
      },
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrIM5UFU9IPX",
        "outputId": "83522984-d6d4-4b91-fbb5-d47bb982b2c3"
      },
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8412"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRfG6tH99IPY"
      },
      "source": [
        "### Looking for the most influential words\n",
        "\n",
        "Logistic regression computes the likelihood of a review being positive (or negative) according to the following formula:\n",
        "$$ h_\\theta(\\mathbf{x})=\\frac{1}{1+\\exp\\left(-\\theta_0-\\sum_{i=1}^n{\\theta_i\\cdot x_i}\\right)} $$\n",
        "\n",
        "Every $x_i$ variable indicates the element $i$ of an input vector (i.e. the weight of the $i$-th word in the dictionary), while $\\theta_i$ is the model parameter indicating how much the word contributes to the review being estimated as positive or negative\n",
        "\n",
        "By looking at values of the parameters, we can find out which words contribute the most at the reviews being labeled as positive or negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e7YGzS49IPZ"
      },
      "source": [
        "The $\\theta_i$ parameters are available as the `coef_` attribute of the `LogisticRegression` model, we get it from the pipeline and print some values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbbzwNtK9IPZ",
        "outputId": "412aee58-2cc5-47bf-9962-1884f4bda1d9"
      },
      "source": [
        "model_classifier = model.named_steps[\"classifier\"]\n",
        "\n",
        "model_classifier.coef_[0, :4]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.05094521, -0.01434774, -0.0256676 ,  0.04577293])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUAtgdBA9IPa"
      },
      "source": [
        "In order to make sense of the values, we get from the `TfidfVectorizer` the names of features and match them to values using a series"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPsPGgMQ9IPa"
      },
      "source": [
        "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
        "model_coefs = pd.Series(model_classifier.coef_[0],\n",
        "                        model_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXPsMfL_9IPb"
      },
      "source": [
        "We sort the values in ascending order"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EiVr4aC9IPc"
      },
      "source": [
        "model_coefs.sort_values(inplace=True) # inplace=True let us sort the original pandas Series stored in model_coefs variable. Otherwise sort_values would return a copy of the sorted series without sorting the original one."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMLV2Y5O9IPc"
      },
      "source": [
        "Now at the top of the series we find the terms with the lowest coefficients, which make the model decision most tend to the \"negative\" class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ZpIVzE9IPd",
        "outputId": "6a1ac5a8-8162-4fd7-926e-8f41bbcf1b08"
      },
      "source": [
        "model_coefs.head(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "bad      -5.200\n",
              "worst    -4.123\n",
              "awful    -2.801\n",
              "waste    -2.771\n",
              "boring   -2.760\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idX8RZY09IPe"
      },
      "source": [
        "...while at the bottom of the series we find terms with the highest coefficients, whose presence makes the review positive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ThCVy2X9IPe",
        "outputId": "6373b1ff-c4a1-4224-901a-76082172856c"
      },
      "source": [
        "model_coefs.tail(5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "and      2.434\n",
              "well     2.517\n",
              "love     2.688\n",
              "best     3.217\n",
              "great    4.528\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeg3twi49IPf"
      },
      "source": [
        "In this way, we can generally find out the most important terms in deciding the orientation of a review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pULaHu9z9IPf"
      },
      "source": [
        "### Regularization of parameters\n",
        "\n",
        "The logistic regression model uses _regularization_ to prevent parameters from having very high absolute values, which may lead to overfitting\n",
        "\n",
        "The C parameter controls the regularization strength: smaller values lead to stronger regularization, while larger values make the model fit more to training data\n",
        "\n",
        "This parameter can be tuned to improve the model accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78n6wGbC9IPg"
      },
      "source": [
        "Let's try for example to raise the C parameter from its default value 1 to 10, thus lowering the regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flxU_m1R9IPg"
      },
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression(C=10))\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNlSMPQt9IPh"
      },
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQNnmdaj9IPh",
        "outputId": "397eccd1-cb85-4184-e5a6-d007566fd521"
      },
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.829"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePLEJs_79IPi"
      },
      "source": [
        "In this case accuracy slightly drops, possibly due to overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72a-QgZt9IPi"
      },
      "source": [
        "If we check for model parameters, their absolute value are now higher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2613CtoE9IPi"
      },
      "source": [
        "model_classifier = model.named_steps[\"classifier\"]\n",
        "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
        "model_coefs = pd.Series(model_classifier.coef_[0],\n",
        "                        model_vectorizer.get_feature_names())\n",
        "model_coefs.sort_values(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Qb8jwP9IPk",
        "outputId": "db1cbd71-d359-4618-b5ac-78a63da7e333"
      },
      "source": [
        "model_coefs.head(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "worst   -9.775\n",
              "bad     -9.499\n",
              "awful   -6.673\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1bH_gF9IPl",
        "outputId": "765a2222-c17c-4baf-c79f-4d2f15529fc5"
      },
      "source": [
        "model_coefs.tail(3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "perfect    6.164\n",
              "best       7.489\n",
              "great      8.936\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-9mDJ7Z9IPm"
      },
      "source": [
        "### Reducing the dimensionality\n",
        "\n",
        "Considering the number of distinct terms across all training reviews, the dimensionality of the vector space is very high"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBGZBkZE9IPm",
        "outputId": "6deb6ad1-16df-4c73-d029-a36729d14192"
      },
      "source": [
        "len(model_vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36272"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLdnbUD69IPm"
      },
      "source": [
        "Methods exist to reduce the dimensionality in order to lower the time required for training the model with very small repercussion on its accuracy\n",
        "\n",
        "One possibility is to not consider words appearing only in very few reviews, such as very specific terms or misspelled words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6EMtre29IPn"
      },
      "source": [
        "We can configure the vectorizer with the `min_df` parameter to exclude terms appearing e.g. in less than 3 training reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ZuZ4H-9IPn"
      },
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3)), # df stands for document frequency.\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlU4nBov9IPo"
      },
      "source": [
        "Let's fit the model as above..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84ujhE7B9IPo"
      },
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGd227X9IPo"
      },
      "source": [
        "Looking at the fit vectorizer, the number of dimensions is now much lower..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koXs4jxM9IPp",
        "outputId": "7c4347a9-ef8a-4219-ef31-59614db5b4db"
      },
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16127"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d-ti6q79IPp"
      },
      "source": [
        "...but the accuracy is close to the previous value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R5wO9wf9IPq",
        "outputId": "0517a598-664a-4405-8b85-09a1471c6785"
      },
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8424"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDT9_dtm9IPq"
      },
      "source": [
        "### Stemming\n",
        "\n",
        "Another way to reduce dimensionality is to group similar terms into an unique feature\n",
        "\n",
        "_Stemming_ is the extraction of the morphological root (_stem_) of a word: using stems of words as features in place of words themselves, we obtain a single feature for possibly several single terms with a common stem (e.g. {run, runned, running} --> \"run\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RamgdDXU9IPq"
      },
      "source": [
        "We start creating a `PorterStemmer` object, providing a `stem` method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmpatPc29IPr"
      },
      "source": [
        "ps = nltk.stem.PorterStemmer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc0qOEK9IPr",
        "outputId": "a434f7ca-faff-44bd-f77e-a7664a373f37"
      },
      "source": [
        "ps.stem(\"stem\"), ps.stem(\"stemming\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('stem', 'stem')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl_591k6v6TZ",
        "outputId": "c28dafe8-0cdf-4616-e2c3-1e76155ad1ae"
      },
      "source": [
        "ps.stem(\"run\"), ps.stem(\"runned\"), ps.stem(\"running\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('run', 'run', 'run')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwlX4rHf9IPt"
      },
      "source": [
        "We can use that to create a function which uses NLTK to tokenize text into words and return a sequence of stems instead of complete words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZStwuomf9IPu"
      },
      "source": [
        "def tokenize_with_stemming(text):\n",
        "    return [ps.stem(token) for token # for each word in the tokenized text apply the ps.stem() function\n",
        "        in nltk.tokenize.word_tokenize(text)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZxdVWzM9IPv",
        "outputId": "99687405-d14c-4acf-faab-49aac1680aea"
      },
      "source": [
        "tokenize_with_stemming(\"We have shown many examples!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['We', 'have', 'shown', 'mani', 'exampl', '!']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIs6UWap9IPw"
      },
      "source": [
        "In a vectorizer, we can set the `tokenizer` parameter to use our custom tokenization function in place of scikit-learn default one"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie7GW6VM9IPw"
      },
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_stemming)),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oxp_WkP9IPx"
      },
      "source": [
        "We can then fit the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guFzXQvr9IPx"
      },
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dMVXv-9IPy"
      },
      "source": [
        "The number of feature is further reduced"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_35EZ_i69IPy",
        "outputId": "ec46428b-acc8-44c7-982c-837cea16a4c5"
      },
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12543"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iysRIvF9IPz"
      },
      "source": [
        "Computing the accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYBlI3gx9IPz",
        "outputId": "9b5709ec-fff4-4268-a467-15ab5e9d6e14"
      },
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbXQzbdz9IP0"
      },
      "source": [
        "...we see in this case a minor loss "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6QpBeJP9IP0"
      },
      "source": [
        "### n-grams\n",
        "\n",
        "An _n-gram_ is a sequence of n consecutive words in a text: in the common cases with n equal to 2 and 3, they are called _bigrams_ and _trigrams_\n",
        "\n",
        "n-grams can be used in addition or replacement to single words as features to represent reviews: they can be useful to spot meaningful expressions composed of more than one word, although we will also get many n-grams with no significant meaning\n",
        "\n",
        "For example, in the sentence \"Sentiment analysis is not bad\" we have meaningful bigrams indicating a concept (\"Sentiment analysis\") and an opinion (\"not bad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObnuLgHv9IP0"
      },
      "source": [
        "Setting the `ngram_range` parameter of a vectorizer to a tuple `(a,b)`, it will use as features all n-grams with n between a and b; the default value is `(1, 1)`, meaning that only single words (\"1-grams\") are considered\n",
        "\n",
        "Let's see what happens by setting `(1, 2)`, i.e. considering both single words and bigrams, still limiting features to those appearing in 3 reviews at least"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsRwMuQR9IP0"
      },
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3, ngram_range=(1, 2))), # using 1-grams and 2-grams\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSOpCexo9IP1"
      },
      "source": [
        "Fit the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha-KoggH9IP1"
      },
      "source": [
        "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]); #reviews_train.text = reviews_train[\"text\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py-_TiXu9IP4"
      },
      "source": [
        "Adding bigrams to single words, the dimensionality is sensibly higher..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA6B_k8q9IP4",
        "outputId": "2189a47e-98e0-4d0e-fc21-fc1bc9a2a8b8"
      },
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names()) # \"sentiment\" + \"sentiment analysis\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "71800"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1Xe-wy9IP5"
      },
      "source": [
        "...but in this case we successfully increase the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zKZ1Eq_9IP5",
        "outputId": "75bb7e5a-4725-4fac-ff76-cdfa76c54a9f"
      },
      "source": [
        "model.score(reviews_test[\"text\"], reviews_test[\"label\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.851"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_k_q0uh9IP5"
      },
      "source": [
        "### Sentiment analysis with NLTK\n",
        "\n",
        "NLTK integrates specific functions for sentiment analysis, allowing to evaluate the subjectivity and the sentiment of text\n",
        "\n",
        "Let's see for example how to classify reviews using VADER (_Valence Aware Dictionary for sEntiment Reasoning_), a lexicon and rule-based sentiment estimator specifically oriented to social media, of which NLTK provides an implementation\n",
        "\n",
        "- **Reference:** Hutto, C. J., and Eric Gilbert. \"VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text.\" _Eighth International AAAI Conference on Weblogs and Social Media_. 2014."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCSzAi59IP6"
      },
      "source": [
        "Download the necessary data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmAuvsax9IP6",
        "outputId": "0d434b4d-6bd7-496b-be6c-33dd3d4b6dce"
      },
      "source": [
        "nltk.download(\"vader_lexicon\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_-UnfYU9IP6"
      },
      "source": [
        "Import the class and create an analyzer object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNOc25rqu1GP",
        "outputId": "7d9af9a3-30b9-4868-fa14-093eadc38057"
      },
      "source": [
        "!pip install twython # nltk.sentiment dependency"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting twython\n",
            "  Downloading https://files.pythonhosted.org/packages/24/80/579b96dfaa9b536efde883d4f0df7ea2598a6f3117a6dd572787f4a2bcfb/twython-3.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from twython) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from twython) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.4.0->twython) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.1.0->twython) (2.10)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.8.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnZ6wPt_9IP6"
      },
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader = SentimentIntensityAnalyzer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoLmF1HV9IP7"
      },
      "source": [
        "We can see some words in the VADER lexicon along with the positive or negative orientation assigned to them: we can see that typical social media language is recognized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5T7h5oA9IP7",
        "outputId": "15b1c075-e2e3-4e46-e0fc-c4670104dc80"
      },
      "source": [
        "vader.lexicon[\"excellent\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2.7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOoK2PH9IP8",
        "outputId": "ab5e1efc-0e1d-4fd4-dda8-710653abd37c"
      },
      "source": [
        "vader.lexicon[\"sux\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGFlq5j59IP8",
        "outputId": "26d193b5-72ca-4fcc-900a-4f02d8c699f3"
      },
      "source": [
        "vader.lexicon[\"wtf\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-2.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 170
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z-AOTKC9IP9",
        "outputId": "76ff4d86-d220-45e2-a7ca-53d16dda8200"
      },
      "source": [
        "vader.lexicon[\":-)\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.3"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwkZwp419IP_"
      },
      "source": [
        "Using the `polarity_score` method, given some text, we obtain a dictionary stating the probability of the sentence being either positive, negative or sentiment-neutral.\n",
        "\n",
        "The `compound` score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-Tk-NI9IP_",
        "outputId": "dea48dcd-f70f-456a-dbfd-765ac4b20270"
      },
      "source": [
        "vader.polarity_scores(\"Not a bad movie\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.431, 'neg': 0.0, 'neu': 0.412, 'pos': 0.588}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMFpr1YA9IQA",
        "outputId": "16827950-9f37-4fa2-bfb3-aaefdc4787f6"
      },
      "source": [
        "vader.polarity_scores(\"I wouldn't recommend this movie\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': -0.2755, 'neg': 0.413, 'neu': 0.587, 'pos': 0.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-28eatr59IQC",
        "outputId": "1b788f3b-b2f1-410b-c3b5-8125e9972b0c"
      },
      "source": [
        "vader.polarity_scores(\"This movie is candidated to 3 Academy awards\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'compound': 0.4588, 'neg': 0.0, 'neu': 0.667, 'pos': 0.333}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 174
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnBSC1np9IQE"
      },
      "source": [
        "We can see that the model is reasonably good in detecting compound statements such as negations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6s63IFF9IQE"
      },
      "source": [
        "Let's create a function that, given a review, returns a \"pos\" or \"neg\" label according to VADER scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNMhwi1i9IQE"
      },
      "source": [
        "def vader_classify(text):\n",
        "    scores = vader.polarity_scores(text)\n",
        "    return \"pos\" if scores[\"pos\"] >= scores[\"neg\"] else \"neg\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW-iJVP-9IQF"
      },
      "source": [
        "Using the `apply` method of series, we apply the function to each review text obtaining a series of pos/neg labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUtWVwWa9IQF"
      },
      "source": [
        "vader_preds = reviews_test[\"text\"].apply(vader_classify)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIS92sBh9IQH"
      },
      "source": [
        "We compare this series with actual labels, obtaining a boolean series stating for which reviews the classifier indicated the correct label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPTLs0SR9IQH"
      },
      "source": [
        "vader_hits = vader_preds == reviews_test[\"label\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9_JcA9v9IQJ",
        "outputId": "aea5d71e-47dc-4484-d1cc-f52636cb72d3"
      },
      "source": [
        "vader_hits.values[:9]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True, False,  True])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWYLf4HU9IQL"
      },
      "source": [
        "Computing the mean, we obtain the ratio of `True` values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT_IrQIf9IQL",
        "outputId": "c8829e1f-b84c-4e29-e739-3e8f25a8f89b"
      },
      "source": [
        "vader_hits.mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6936"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSM4e3_9IQM"
      },
      "source": [
        "Here VADER achieves a lower accuracy than our supervised model, which however required a large set of pre-labeled reviews to be trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKe42xjW9IQM"
      },
      "source": [
        "### Exercise 2: test new methods on tweets\n",
        "\n",
        "In this activity we have seen two sentiment classification methods\n",
        "- using a classifier trained on the labeled reviews used here\n",
        "- using the pretrained VADER model\n",
        "\n",
        "Test both these new methods on airline tweets from the first activity, giving each tweet a score of -5 or 5 according to the negative or positive response of the classifier, then compare as above summary scores obtained by both methods with ACSI scores\n",
        "\n",
        "Which of the two methods do you expect to be more accurate?"
      ]
    }
  ]
}