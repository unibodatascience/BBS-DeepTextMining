{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/unibodatascience/BBS-TextMining/blob/master/1_opinion_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ff1tWjz9IMU"
      },
      "source": [
        "# Opinion Mining & Sentiment Analysis - part 1: Lab Activities\n",
        "\n",
        "**Text Mining unit**\n",
        "\n",
        "_Prof. Gianluca Moro, DISI, University of Bologna_\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Universit√† di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNVEJNfK9IMV"
      },
      "source": [
        "## Setup\n",
        "\n",
        "Import external libraries (thus verifying they are correctly installed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mahnniQH9IMV"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "import nltk"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqGAJAwE9IMY"
      },
      "source": [
        "If using IPython/Jupyter, run the following to render plots inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4F4jCZtw9IMY"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XQSMiSN9IMa"
      },
      "source": [
        "Set some options in pandas for printing DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p72mmuD39IMb"
      },
      "outputs": [],
      "source": [
        "pd.options.display.max_colwidth = 100\n",
        "pd.options.display.precision = 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naIH999P9IMd"
      },
      "source": [
        "Define a utility function to download data files if they are not already present in working directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N8v0EsMy9IMd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELPuiZa99IMf"
      },
      "source": [
        "## Activity 1: Twitter-based Opinion Mining\n",
        "\n",
        "**Goal:** evaluate from Twitter how much customers are satisfied of airline companies\n",
        "\n",
        "1. Collect tweets mentioning airline companies\n",
        "2. Define lists of opinion keywords\n",
        "3. Evaluate sentiment of each tweet\n",
        "4. Summarize sentiment for each airline company\n",
        "5. Extract customer satisfaction for companies from the ACSI website\n",
        "6. Compare scores estimated from Twitter with those extracted from ACSI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAkDuqRx9IMf"
      },
      "source": [
        "This is a list of the Twitter accounts of airline companies taken into consideration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZwtwx3F9IMg"
      },
      "outputs": [],
      "source": [
        "airlines = [\n",
        "    \"delta\",\n",
        "    \"americanair\",\n",
        "    \"jetblue\",\n",
        "    \"southwestair\",\n",
        "    \"united\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeYYAQJN9IMj"
      },
      "source": [
        "### Collect tweets citing airline companies\n",
        "\n",
        "Recent tweets matching a given query can be searched using the Twitter Search API; many libraries exist for Python and other languages providing easy access to the API\n",
        "\n",
        "We see here how to obtain tweets using the `TwitterSearch` package, installable with `pip install TwitterSearch`; a Twitter account with an associated mobile number is needed in order to use the API\n",
        "\n",
        "If you can't or don't want to use your Twitter account and/or install the package, you can use a set of pre-collected tweets we provide"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OoGLa6FsR9P",
        "outputId": "6faaa6d6-c88a-4a2c-ba47-3099c443e1a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: TwitterSearch==1.0.2 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (1.0.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.3.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from TwitterSearch==1.0.2) (1.3.1)\n",
            "Requirement already satisfied: requests>=1.0.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from TwitterSearch==1.0.2) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (3.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (2022.5.18.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (2.0.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=1.0.0->TwitterSearch==1.0.2) (1.26.9)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests-oauthlib>=0.3.0->TwitterSearch==1.0.2) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install TwitterSearch==1.0.2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HORmDG1V9IMj"
      },
      "source": [
        "#### Creating a Twitter application\n",
        "\n",
        "In order to use Twitter APIs you need API keys: follow these steps to obtain one\n",
        "\n",
        "1. Go to https://developer.twitter.com/en/apps and login with your Twitter account\n",
        "2. Click the \"Create New App\" button, fill the form with short descriptive values (you may use e.g. \"http://example.com\" as the URL) and confirm\n",
        "3. Click on the app you just created and open the \"Key and Access Tokens\" tab\n",
        "4. For better security, ensure to set the Access Level to Read-only\n",
        "5. Click on the \"Create my access token\" button below\n",
        "\n",
        "You will need strings labeled with _Consumer Key_, _Consumer Secret_, _Access Token_ and _Access Token Secret_ shown in the page to use the API\n",
        "\n",
        "Create and load here the json file exactly like this filling it with your twitter data into the 4 strings\n",
        "\n",
        "{  \n",
        "    \"consumer_key\": \"\",  \n",
        "    \"consumer_secret\": \"\",  \n",
        "    \"access_token\": \"\",   \n",
        "    \"access_token_secret\": \"\"  \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tCYLFbaTyZ2"
      },
      "source": [
        "#### Loading keys\n",
        "\n",
        "Load the necessary Twitter security keys from file. \n",
        "\n",
        "*Software Security note*: avoid to leave secret keys hardcoded or write them in shell commands. Prefer keeping them in protected files or using secrets management tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4T4LzxiT1UX"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "with open('twitter_keys.json') as f:\n",
        "  keys = json.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYBhW_i09IMk"
      },
      "source": [
        "#### Authenticating\n",
        "\n",
        "Import the necessary classes and create a `TwitterSearch` object providing the API codes obtained above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5muh0UR9IMk"
      },
      "outputs": [],
      "source": [
        "from TwitterSearch import TwitterSearch, TwitterSearchOrder\n",
        "\n",
        "ts = TwitterSearch(\n",
        "    consumer_key = keys[\"consumer_key\"],\n",
        "    consumer_secret = keys[\"consumer_secret\"], \n",
        "    access_token = keys[\"access_token\"], \n",
        "    access_token_secret = keys[\"access_token_secret\"] \n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnKcbMR79IMm"
      },
      "source": [
        "#### Obtaining tweets\n",
        "\n",
        "Create a `TwitterSearchOrder` indicating the tweets to search: we start for example by searching tweets about Delta Air Lines, whose Twitter account is \"@delta\"; by default the search will return up to 100 tweets, the upper limit set by Twitter for each request"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bfMohlNI9IMn"
      },
      "outputs": [],
      "source": [
        "tso = TwitterSearchOrder()\n",
        "tso.set_keywords([\"@delta\"]) # for query syntax see https://twittersearch.readthedocs.io/en/latest/advanced_usage_tso.html \n",
        "tso.set_language(\"en\")\n",
        "tso.set_include_entities(False)  # such as hashtags, symbols, user_mentions, urls\n",
        "tso.set_count(5) # To limit the search to five tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_MWWTcN9IMo"
      },
      "source": [
        "We can now issue the request to the Twitter API\n",
        "\n",
        "**Warning:** the Twitter API has usage rate limitations, `search_tweets` and other API methods will temporarily stop working if executed many times in few minutes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2GkB71N9IMp",
        "outputId": "c68dcb46-e0a3-469c-b5a5-7c7f33e65469"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'meta': {'date': 'Tue, 31 May 2022 11:36:16 GMT', 'pragma': 'no-cache', 'server': 'tsa_f', 'status': '200 OK', 'expires': 'Tue, 31 Mar 1981 05:00:00 GMT', 'set-cookie': 'lang=en; Path=/, guest_id=v1%3A165399697647078398; Max-Age=34214400; Expires=Sat, 01 Jul 2023 11:36:16 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'content-type': 'application/json;charset=utf-8', 'cache-control': 'no-cache, no-store, must-revalidate, pre-check=0, post-check=0', 'last-modified': 'Tue, 31 May 2022 11:36:16 GMT', 'x-transaction': 'f107afd9aa88c206', 'content-length': '2915', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'br', 'x-xss-protection': '0', 'x-rate-limit-limit': '180', 'x-rate-limit-reset': '1653997299', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '172', 'x-twitter-response-tags': 'BouncerCompliant', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '154', 'x-connection-hash': '76c18be0cf83e8713365d7d6f0257b6b51e7738715208a9050b04bfd6c50c04c'},\n",
              " 'content': {'statuses': [{'created_at': 'Tue May 31 11:35:49 +0000 2022',\n",
              "    'id': 1531600331196583937,\n",
              "    'id_str': '1531600331196583937',\n",
              "    'text': '@Delta I do really apologize for the inconvenience, as much as I love to assist you regarding with your concern but‚Ä¶ https://t.co/7uxcY0QJe2',\n",
              "    'truncated': True,\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              "    'in_reply_to_status_id': 1531040304316416000,\n",
              "    'in_reply_to_status_id_str': '1531040304316416000',\n",
              "    'in_reply_to_user_id': 5920532,\n",
              "    'in_reply_to_user_id_str': '5920532',\n",
              "    'in_reply_to_screen_name': 'Delta',\n",
              "    'user': {'id': 27519218,\n",
              "     'id_str': '27519218',\n",
              "     'name': 'Indamix',\n",
              "     'screen_name': 'marbac',\n",
              "     'location': '',\n",
              "     'description': '',\n",
              "     'url': None,\n",
              "     'entities': {'description': {'urls': []}},\n",
              "     'protected': False,\n",
              "     'followers_count': 28,\n",
              "     'friends_count': 113,\n",
              "     'listed_count': 0,\n",
              "     'created_at': 'Sun Mar 29 22:23:07 +0000 2009',\n",
              "     'favourites_count': 3140,\n",
              "     'utc_offset': None,\n",
              "     'time_zone': None,\n",
              "     'geo_enabled': False,\n",
              "     'verified': False,\n",
              "     'statuses_count': 941,\n",
              "     'lang': None,\n",
              "     'contributors_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'is_translation_enabled': False,\n",
              "     'profile_background_color': '9AE4E8',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_tile': True,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1413528537634680842/fmFzpEdn_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1413528537634680842/fmFzpEdn_normal.jpg',\n",
              "     'profile_link_color': '0084B4',\n",
              "     'profile_sidebar_border_color': 'BDDCAD',\n",
              "     'profile_sidebar_fill_color': 'DDFFCC',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'has_extended_profile': False,\n",
              "     'default_profile': False,\n",
              "     'default_profile_image': False,\n",
              "     'following': False,\n",
              "     'follow_request_sent': False,\n",
              "     'notifications': False,\n",
              "     'translator_type': 'none',\n",
              "     'withheld_in_countries': []},\n",
              "    'geo': None,\n",
              "    'coordinates': None,\n",
              "    'place': None,\n",
              "    'contributors': None,\n",
              "    'is_quote_status': False,\n",
              "    'retweet_count': 0,\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'retweeted': False,\n",
              "    'lang': 'en'},\n",
              "   {'created_at': 'Tue May 31 11:35:20 +0000 2022',\n",
              "    'id': 1531600211457581058,\n",
              "    'id_str': '1531600211457581058',\n",
              "    'text': 'RT @bbexawards: üèÜ If your business recognises its purpose and meaning before profits, enter to win our special award, the Purpose Before Pr‚Ä¶',\n",
              "    'truncated': False,\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
              "    'in_reply_to_status_id': None,\n",
              "    'in_reply_to_status_id_str': None,\n",
              "    'in_reply_to_user_id': None,\n",
              "    'in_reply_to_user_id_str': None,\n",
              "    'in_reply_to_screen_name': None,\n",
              "    'user': {'id': 121123109,\n",
              "     'id_str': '121123109',\n",
              "     'name': 'WeAreTheCity',\n",
              "     'screen_name': 'WeAreTheCity',\n",
              "     'location': 'United Kingdom',\n",
              "     'description': '#WATCTop100‚ö°Ô∏è ¬∑ Supporting women careers since 2008 with 160k members, helping over 110 companies to retain and develop talent üåç',\n",
              "     'url': 'https://t.co/SdzIxdeWhA',\n",
              "     'entities': {'url': {'urls': [{'url': 'https://t.co/SdzIxdeWhA',\n",
              "         'expanded_url': 'http://wearethecity.com',\n",
              "         'display_url': 'wearethecity.com',\n",
              "         'indices': [0, 23]}]},\n",
              "      'description': {'urls': []}},\n",
              "     'protected': False,\n",
              "     'followers_count': 17227,\n",
              "     'friends_count': 4428,\n",
              "     'listed_count': 541,\n",
              "     'created_at': 'Mon Mar 08 14:01:51 +0000 2010',\n",
              "     'favourites_count': 43194,\n",
              "     'utc_offset': None,\n",
              "     'time_zone': None,\n",
              "     'geo_enabled': True,\n",
              "     'verified': False,\n",
              "     'statuses_count': 74495,\n",
              "     'lang': None,\n",
              "     'contributors_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'is_translation_enabled': False,\n",
              "     'profile_background_color': 'C0DEED',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "     'profile_background_tile': True,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1523944726562578438/FUj9-DP4_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1523944726562578438/FUj9-DP4_normal.jpg',\n",
              "     'profile_banner_url': 'https://pbs.twimg.com/profile_banners/121123109/1653413679',\n",
              "     'profile_link_color': 'D92B9C',\n",
              "     'profile_sidebar_border_color': 'C0DEED',\n",
              "     'profile_sidebar_fill_color': 'DDEEF6',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'has_extended_profile': False,\n",
              "     'default_profile': False,\n",
              "     'default_profile_image': False,\n",
              "     'following': False,\n",
              "     'follow_request_sent': False,\n",
              "     'notifications': False,\n",
              "     'translator_type': 'none',\n",
              "     'withheld_in_countries': []},\n",
              "    'geo': None,\n",
              "    'coordinates': None,\n",
              "    'place': None,\n",
              "    'contributors': None,\n",
              "    'retweeted_status': {'created_at': 'Tue May 31 11:08:36 +0000 2022',\n",
              "     'id': 1531593482292297729,\n",
              "     'id_str': '1531593482292297729',\n",
              "     'text': 'üèÜ If your business recognises its purpose and meaning before profits, enter to win our special award, the Purpose B‚Ä¶ https://t.co/7YxPBPI5RM',\n",
              "     'truncated': True,\n",
              "     'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "     'source': '<a href=\"https://www.heyorca.com\" rel=\"nofollow\">HeyOrca</a>',\n",
              "     'in_reply_to_status_id': None,\n",
              "     'in_reply_to_status_id_str': None,\n",
              "     'in_reply_to_user_id': None,\n",
              "     'in_reply_to_user_id_str': None,\n",
              "     'in_reply_to_screen_name': None,\n",
              "     'user': {'id': 1379480879211364352,\n",
              "      'id_str': '1379480879211364352',\n",
              "      'name': 'Lloyds Bank British Business Excellence Awards',\n",
              "      'screen_name': 'bbexawards',\n",
              "      'location': '',\n",
              "      'description': 'üèÜ The largest business awards programme in the UK\\n‚≠ê Celebrating resilience, innovation, and creativity in #BritishBusiness\\nüëÄ Get ready for 2022\\n\\n#FTSE #SMEs',\n",
              "      'url': 'https://t.co/nwK25nu6LB',\n",
              "      'entities': {'url': {'urls': [{'url': 'https://t.co/nwK25nu6LB',\n",
              "          'expanded_url': 'https://bit.ly/3dZO5ye',\n",
              "          'display_url': 'bit.ly/3dZO5ye',\n",
              "          'indices': [0, 23]}]},\n",
              "       'description': {'urls': []}},\n",
              "      'protected': False,\n",
              "      'followers_count': 216,\n",
              "      'friends_count': 534,\n",
              "      'listed_count': 1,\n",
              "      'created_at': 'Tue Apr 06 17:07:39 +0000 2021',\n",
              "      'favourites_count': 461,\n",
              "      'utc_offset': None,\n",
              "      'time_zone': None,\n",
              "      'geo_enabled': True,\n",
              "      'verified': False,\n",
              "      'statuses_count': 436,\n",
              "      'lang': None,\n",
              "      'contributors_enabled': False,\n",
              "      'is_translator': False,\n",
              "      'is_translation_enabled': False,\n",
              "      'profile_background_color': 'F5F8FA',\n",
              "      'profile_background_image_url': None,\n",
              "      'profile_background_image_url_https': None,\n",
              "      'profile_background_tile': False,\n",
              "      'profile_image_url': 'http://pbs.twimg.com/profile_images/1379481525687881729/WCaiy6Ev_normal.jpg',\n",
              "      'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1379481525687881729/WCaiy6Ev_normal.jpg',\n",
              "      'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1379480879211364352/1618407899',\n",
              "      'profile_link_color': '1DA1F2',\n",
              "      'profile_sidebar_border_color': 'C0DEED',\n",
              "      'profile_sidebar_fill_color': 'DDEEF6',\n",
              "      'profile_text_color': '333333',\n",
              "      'profile_use_background_image': True,\n",
              "      'has_extended_profile': True,\n",
              "      'default_profile': True,\n",
              "      'default_profile_image': False,\n",
              "      'following': False,\n",
              "      'follow_request_sent': False,\n",
              "      'notifications': False,\n",
              "      'translator_type': 'none',\n",
              "      'withheld_in_countries': []},\n",
              "     'geo': None,\n",
              "     'coordinates': None,\n",
              "     'place': None,\n",
              "     'contributors': None,\n",
              "     'is_quote_status': False,\n",
              "     'retweet_count': 2,\n",
              "     'favorite_count': 2,\n",
              "     'favorited': False,\n",
              "     'retweeted': False,\n",
              "     'possibly_sensitive': False,\n",
              "     'lang': 'en'},\n",
              "    'is_quote_status': False,\n",
              "    'retweet_count': 2,\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'retweeted': False,\n",
              "    'lang': 'en'},\n",
              "   {'created_at': 'Tue May 31 11:33:21 +0000 2022',\n",
              "    'id': 1531599709181202432,\n",
              "    'id_str': '1531599709181202432',\n",
              "    'text': 'Delta Air Lines Compensation Alert! Were you scheduled to be on flight DL45 from Dublin Airport to John F Kennedy I‚Ä¶ https://t.co/wThhnpObrK',\n",
              "    'truncated': True,\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'source': '<a href=\"https://mobile.twitter.com\" rel=\"nofollow\">Twitter Web App</a>',\n",
              "    'in_reply_to_status_id': None,\n",
              "    'in_reply_to_status_id_str': None,\n",
              "    'in_reply_to_user_id': None,\n",
              "    'in_reply_to_user_id_str': None,\n",
              "    'in_reply_to_screen_name': None,\n",
              "    'user': {'id': 1111253803142131712,\n",
              "     'id_str': '1111253803142131712',\n",
              "     'name': 'Flight Patrol',\n",
              "     'screen_name': 'Flight_Patrol',\n",
              "     'location': '',\n",
              "     'description': 'Flight Compensation Company‚úà\\nClaim up to ‚Ç¨600/¬£556 in compensation for \\n#DelayedFlights #CancelledFlights & #DeniedBoarding in the past 6 years. #KnowYourRights',\n",
              "     'url': 'https://t.co/1rJwWPuIDt',\n",
              "     'entities': {'url': {'urls': [{'url': 'https://t.co/1rJwWPuIDt',\n",
              "         'expanded_url': 'https://flightpatrol.com/',\n",
              "         'display_url': 'flightpatrol.com',\n",
              "         'indices': [0, 23]}]},\n",
              "      'description': {'urls': []}},\n",
              "     'protected': False,\n",
              "     'followers_count': 820,\n",
              "     'friends_count': 164,\n",
              "     'listed_count': 4,\n",
              "     'created_at': 'Thu Mar 28 13:08:47 +0000 2019',\n",
              "     'favourites_count': 499,\n",
              "     'utc_offset': None,\n",
              "     'time_zone': None,\n",
              "     'geo_enabled': True,\n",
              "     'verified': False,\n",
              "     'statuses_count': 3366,\n",
              "     'lang': None,\n",
              "     'contributors_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'is_translation_enabled': False,\n",
              "     'profile_background_color': 'F5F8FA',\n",
              "     'profile_background_image_url': None,\n",
              "     'profile_background_image_url_https': None,\n",
              "     'profile_background_tile': False,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1230179289871585280/KXdsacaL_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1230179289871585280/KXdsacaL_normal.jpg',\n",
              "     'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1111253803142131712/1594130158',\n",
              "     'profile_link_color': '1DA1F2',\n",
              "     'profile_sidebar_border_color': 'C0DEED',\n",
              "     'profile_sidebar_fill_color': 'DDEEF6',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'has_extended_profile': False,\n",
              "     'default_profile': True,\n",
              "     'default_profile_image': False,\n",
              "     'following': False,\n",
              "     'follow_request_sent': False,\n",
              "     'notifications': False,\n",
              "     'translator_type': 'none',\n",
              "     'withheld_in_countries': []},\n",
              "    'geo': None,\n",
              "    'coordinates': None,\n",
              "    'place': None,\n",
              "    'contributors': None,\n",
              "    'is_quote_status': False,\n",
              "    'retweet_count': 0,\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'retweeted': False,\n",
              "    'possibly_sensitive': False,\n",
              "    'lang': 'en'},\n",
              "   {'created_at': 'Tue May 31 11:30:35 +0000 2022',\n",
              "    'id': 1531599016261300225,\n",
              "    'id_str': '1531599016261300225',\n",
              "    'text': 'RT @AndreaTVNews: NEW: @Delta is cutting 7,600 flights from its July and August schedules. This includes 31 flights from @CVGairport. The a‚Ä¶',\n",
              "    'truncated': False,\n",
              "    'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "    'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
              "    'in_reply_to_status_id': None,\n",
              "    'in_reply_to_status_id_str': None,\n",
              "    'in_reply_to_user_id': None,\n",
              "    'in_reply_to_user_id_str': None,\n",
              "    'in_reply_to_screen_name': None,\n",
              "    'user': {'id': 13224032,\n",
              "     'id_str': '13224032',\n",
              "     'name': 'FOX19 NOW',\n",
              "     'screen_name': 'FOX19',\n",
              "     'location': 'Cincinnati, OH',\n",
              "     'description': 'The official account of FOX19 NOW, WXIX-TV in Cincinnati, OH. Content shared via tweets to @fox19 may be republished online or on air',\n",
              "     'url': 'https://t.co/ExCGMCxp2P',\n",
              "     'entities': {'url': {'urls': [{'url': 'https://t.co/ExCGMCxp2P',\n",
              "         'expanded_url': 'http://www.FOX19NOW.com',\n",
              "         'display_url': 'FOX19NOW.com',\n",
              "         'indices': [0, 23]}]},\n",
              "      'description': {'urls': []}},\n",
              "     'protected': False,\n",
              "     'followers_count': 126311,\n",
              "     'friends_count': 14534,\n",
              "     'listed_count': 1046,\n",
              "     'created_at': 'Thu Feb 07 22:22:12 +0000 2008',\n",
              "     'favourites_count': 3165,\n",
              "     'utc_offset': None,\n",
              "     'time_zone': None,\n",
              "     'geo_enabled': True,\n",
              "     'verified': True,\n",
              "     'statuses_count': 296970,\n",
              "     'lang': None,\n",
              "     'contributors_enabled': False,\n",
              "     'is_translator': False,\n",
              "     'is_translation_enabled': False,\n",
              "     'profile_background_color': '022330',\n",
              "     'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme15/bg.png',\n",
              "     'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme15/bg.png',\n",
              "     'profile_background_tile': False,\n",
              "     'profile_image_url': 'http://pbs.twimg.com/profile_images/1493060663001985035/t72jSSsa_normal.jpg',\n",
              "     'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1493060663001985035/t72jSSsa_normal.jpg',\n",
              "     'profile_banner_url': 'https://pbs.twimg.com/profile_banners/13224032/1629138510',\n",
              "     'profile_link_color': 'B30000',\n",
              "     'profile_sidebar_border_color': 'A8C7F7',\n",
              "     'profile_sidebar_fill_color': 'C0DFEC',\n",
              "     'profile_text_color': '333333',\n",
              "     'profile_use_background_image': True,\n",
              "     'has_extended_profile': False,\n",
              "     'default_profile': False,\n",
              "     'default_profile_image': False,\n",
              "     'following': False,\n",
              "     'follow_request_sent': False,\n",
              "     'notifications': False,\n",
              "     'translator_type': 'none',\n",
              "     'withheld_in_countries': []},\n",
              "    'geo': None,\n",
              "    'coordinates': None,\n",
              "    'place': None,\n",
              "    'contributors': None,\n",
              "    'retweeted_status': {'created_at': 'Tue May 31 11:05:36 +0000 2022',\n",
              "     'id': 1531592725371437057,\n",
              "     'id_str': '1531592725371437057',\n",
              "     'text': 'NEW: @Delta is cutting 7,600 flights from its July and August schedules. This includes 31 flights from @CVGairport.‚Ä¶ https://t.co/VwqWIISsoF',\n",
              "     'truncated': True,\n",
              "     'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "     'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
              "     'in_reply_to_status_id': None,\n",
              "     'in_reply_to_status_id_str': None,\n",
              "     'in_reply_to_user_id': None,\n",
              "     'in_reply_to_user_id_str': None,\n",
              "     'in_reply_to_screen_name': None,\n",
              "     'user': {'id': 1043084801987756032,\n",
              "      'id_str': '1043084801987756032',\n",
              "      'name': 'Andrea Finney',\n",
              "      'screen_name': 'AndreaTVNews',\n",
              "      'location': 'Cincinnati, Ohio',\n",
              "      'description': 'FOX 19 Now Morning News Anchor - I tweet about news ... sorta. Arkansas girl ü§ó ** Opinions are my own** IG: JustDreaTV  Facebook: andreafinneytv',\n",
              "      'url': 'https://t.co/PDwVAvqWgR',\n",
              "      'entities': {'url': {'urls': [{'url': 'https://t.co/PDwVAvqWgR',\n",
              "          'expanded_url': 'http://www.fox19now.com',\n",
              "          'display_url': 'fox19now.com',\n",
              "          'indices': [0, 23]}]},\n",
              "       'description': {'urls': []}},\n",
              "      'protected': False,\n",
              "      'followers_count': 972,\n",
              "      'friends_count': 193,\n",
              "      'listed_count': 25,\n",
              "      'created_at': 'Fri Sep 21 10:29:31 +0000 2018',\n",
              "      'favourites_count': 1027,\n",
              "      'utc_offset': None,\n",
              "      'time_zone': None,\n",
              "      'geo_enabled': False,\n",
              "      'verified': True,\n",
              "      'statuses_count': 1875,\n",
              "      'lang': None,\n",
              "      'contributors_enabled': False,\n",
              "      'is_translator': False,\n",
              "      'is_translation_enabled': False,\n",
              "      'profile_background_color': 'F5F8FA',\n",
              "      'profile_background_image_url': None,\n",
              "      'profile_background_image_url_https': None,\n",
              "      'profile_background_tile': False,\n",
              "      'profile_image_url': 'http://pbs.twimg.com/profile_images/1343134556115902466/8puisKWf_normal.jpg',\n",
              "      'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1343134556115902466/8puisKWf_normal.jpg',\n",
              "      'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1043084801987756032/1634737917',\n",
              "      'profile_link_color': '1DA1F2',\n",
              "      'profile_sidebar_border_color': 'C0DEED',\n",
              "      'profile_sidebar_fill_color': 'DDEEF6',\n",
              "      'profile_text_color': '333333',\n",
              "      'profile_use_background_image': True,\n",
              "      'has_extended_profile': True,\n",
              "      'default_profile': True,\n",
              "      'default_profile_image': False,\n",
              "      'following': False,\n",
              "      'follow_request_sent': False,\n",
              "      'notifications': False,\n",
              "      'translator_type': 'none',\n",
              "      'withheld_in_countries': []},\n",
              "     'geo': None,\n",
              "     'coordinates': None,\n",
              "     'place': None,\n",
              "     'contributors': None,\n",
              "     'is_quote_status': False,\n",
              "     'retweet_count': 4,\n",
              "     'favorite_count': 3,\n",
              "     'favorited': False,\n",
              "     'retweeted': False,\n",
              "     'possibly_sensitive': False,\n",
              "     'lang': 'en'},\n",
              "    'is_quote_status': False,\n",
              "    'retweet_count': 4,\n",
              "    'favorite_count': 0,\n",
              "    'favorited': False,\n",
              "    'retweeted': False,\n",
              "    'lang': 'en'}],\n",
              "  'search_metadata': {'completed_in': 0.024,\n",
              "   'max_id': 1531600331196583937,\n",
              "   'max_id_str': '1531600331196583937',\n",
              "   'next_results': '?max_id=1531599016261300224&q=%40delta&lang=en&count=5',\n",
              "   'query': '%40delta',\n",
              "   'refresh_url': '?since_id=1531600331196583937&q=%40delta&lang=en',\n",
              "   'count': 5,\n",
              "   'since_id': 0,\n",
              "   'since_id_str': '0'}}}"
            ]
          },
          "execution_count": 227,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tsresp = ts.search_tweets(tso)\n",
        "tsresp  # Print the search result retrieved as JSON object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzIvL9l5lqZ8",
        "outputId": "f10efb78-9d57-4426-ce65-13a86b263f73"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'created_at': 'Tue May 31 11:35:49 +0000 2022',\n",
              "  'id': 1531600331196583937,\n",
              "  'id_str': '1531600331196583937',\n",
              "  'text': '@Delta I do really apologize for the inconvenience, as much as I love to assist you regarding with your concern but‚Ä¶ https://t.co/7uxcY0QJe2',\n",
              "  'truncated': True,\n",
              "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "  'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              "  'in_reply_to_status_id': 1531040304316416000,\n",
              "  'in_reply_to_status_id_str': '1531040304316416000',\n",
              "  'in_reply_to_user_id': 5920532,\n",
              "  'in_reply_to_user_id_str': '5920532',\n",
              "  'in_reply_to_screen_name': 'Delta',\n",
              "  'user': {'id': 27519218,\n",
              "   'id_str': '27519218',\n",
              "   'name': 'Indamix',\n",
              "   'screen_name': 'marbac',\n",
              "   'location': '',\n",
              "   'description': '',\n",
              "   'url': None,\n",
              "   'entities': {'description': {'urls': []}},\n",
              "   'protected': False,\n",
              "   'followers_count': 28,\n",
              "   'friends_count': 113,\n",
              "   'listed_count': 0,\n",
              "   'created_at': 'Sun Mar 29 22:23:07 +0000 2009',\n",
              "   'favourites_count': 3140,\n",
              "   'utc_offset': None,\n",
              "   'time_zone': None,\n",
              "   'geo_enabled': False,\n",
              "   'verified': False,\n",
              "   'statuses_count': 941,\n",
              "   'lang': None,\n",
              "   'contributors_enabled': False,\n",
              "   'is_translator': False,\n",
              "   'is_translation_enabled': False,\n",
              "   'profile_background_color': '9AE4E8',\n",
              "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "   'profile_background_tile': True,\n",
              "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1413528537634680842/fmFzpEdn_normal.jpg',\n",
              "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1413528537634680842/fmFzpEdn_normal.jpg',\n",
              "   'profile_link_color': '0084B4',\n",
              "   'profile_sidebar_border_color': 'BDDCAD',\n",
              "   'profile_sidebar_fill_color': 'DDFFCC',\n",
              "   'profile_text_color': '333333',\n",
              "   'profile_use_background_image': True,\n",
              "   'has_extended_profile': False,\n",
              "   'default_profile': False,\n",
              "   'default_profile_image': False,\n",
              "   'following': False,\n",
              "   'follow_request_sent': False,\n",
              "   'notifications': False,\n",
              "   'translator_type': 'none',\n",
              "   'withheld_in_countries': []},\n",
              "  'geo': None,\n",
              "  'coordinates': None,\n",
              "  'place': None,\n",
              "  'contributors': None,\n",
              "  'is_quote_status': False,\n",
              "  'retweet_count': 0,\n",
              "  'favorite_count': 0,\n",
              "  'favorited': False,\n",
              "  'retweeted': False,\n",
              "  'lang': 'en'},\n",
              " {'created_at': 'Tue May 31 11:35:20 +0000 2022',\n",
              "  'id': 1531600211457581058,\n",
              "  'id_str': '1531600211457581058',\n",
              "  'text': 'RT @bbexawards: üèÜ If your business recognises its purpose and meaning before profits, enter to win our special award, the Purpose Before Pr‚Ä¶',\n",
              "  'truncated': False,\n",
              "  'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "  'source': '<a href=\"https://about.twitter.com/products/tweetdeck\" rel=\"nofollow\">TweetDeck</a>',\n",
              "  'in_reply_to_status_id': None,\n",
              "  'in_reply_to_status_id_str': None,\n",
              "  'in_reply_to_user_id': None,\n",
              "  'in_reply_to_user_id_str': None,\n",
              "  'in_reply_to_screen_name': None,\n",
              "  'user': {'id': 121123109,\n",
              "   'id_str': '121123109',\n",
              "   'name': 'WeAreTheCity',\n",
              "   'screen_name': 'WeAreTheCity',\n",
              "   'location': 'United Kingdom',\n",
              "   'description': '#WATCTop100‚ö°Ô∏è ¬∑ Supporting women careers since 2008 with 160k members, helping over 110 companies to retain and develop talent üåç',\n",
              "   'url': 'https://t.co/SdzIxdeWhA',\n",
              "   'entities': {'url': {'urls': [{'url': 'https://t.co/SdzIxdeWhA',\n",
              "       'expanded_url': 'http://wearethecity.com',\n",
              "       'display_url': 'wearethecity.com',\n",
              "       'indices': [0, 23]}]},\n",
              "    'description': {'urls': []}},\n",
              "   'protected': False,\n",
              "   'followers_count': 17227,\n",
              "   'friends_count': 4428,\n",
              "   'listed_count': 541,\n",
              "   'created_at': 'Mon Mar 08 14:01:51 +0000 2010',\n",
              "   'favourites_count': 43194,\n",
              "   'utc_offset': None,\n",
              "   'time_zone': None,\n",
              "   'geo_enabled': True,\n",
              "   'verified': False,\n",
              "   'statuses_count': 74495,\n",
              "   'lang': None,\n",
              "   'contributors_enabled': False,\n",
              "   'is_translator': False,\n",
              "   'is_translation_enabled': False,\n",
              "   'profile_background_color': 'C0DEED',\n",
              "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "   'profile_background_tile': True,\n",
              "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1523944726562578438/FUj9-DP4_normal.jpg',\n",
              "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1523944726562578438/FUj9-DP4_normal.jpg',\n",
              "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/121123109/1653413679',\n",
              "   'profile_link_color': 'D92B9C',\n",
              "   'profile_sidebar_border_color': 'C0DEED',\n",
              "   'profile_sidebar_fill_color': 'DDEEF6',\n",
              "   'profile_text_color': '333333',\n",
              "   'profile_use_background_image': True,\n",
              "   'has_extended_profile': False,\n",
              "   'default_profile': False,\n",
              "   'default_profile_image': False,\n",
              "   'following': False,\n",
              "   'follow_request_sent': False,\n",
              "   'notifications': False,\n",
              "   'translator_type': 'none',\n",
              "   'withheld_in_countries': []},\n",
              "  'geo': None,\n",
              "  'coordinates': None,\n",
              "  'place': None,\n",
              "  'contributors': None,\n",
              "  'retweeted_status': {'created_at': 'Tue May 31 11:08:36 +0000 2022',\n",
              "   'id': 1531593482292297729,\n",
              "   'id_str': '1531593482292297729',\n",
              "   'text': 'üèÜ If your business recognises its purpose and meaning before profits, enter to win our special award, the Purpose B‚Ä¶ https://t.co/7YxPBPI5RM',\n",
              "   'truncated': True,\n",
              "   'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              "   'source': '<a href=\"https://www.heyorca.com\" rel=\"nofollow\">HeyOrca</a>',\n",
              "   'in_reply_to_status_id': None,\n",
              "   'in_reply_to_status_id_str': None,\n",
              "   'in_reply_to_user_id': None,\n",
              "   'in_reply_to_user_id_str': None,\n",
              "   'in_reply_to_screen_name': None,\n",
              "   'user': {'id': 1379480879211364352,\n",
              "    'id_str': '1379480879211364352',\n",
              "    'name': 'Lloyds Bank British Business Excellence Awards',\n",
              "    'screen_name': 'bbexawards',\n",
              "    'location': '',\n",
              "    'description': 'üèÜ The largest business awards programme in the UK\\n‚≠ê Celebrating resilience, innovation, and creativity in #BritishBusiness\\nüëÄ Get ready for 2022\\n\\n#FTSE #SMEs',\n",
              "    'url': 'https://t.co/nwK25nu6LB',\n",
              "    'entities': {'url': {'urls': [{'url': 'https://t.co/nwK25nu6LB',\n",
              "        'expanded_url': 'https://bit.ly/3dZO5ye',\n",
              "        'display_url': 'bit.ly/3dZO5ye',\n",
              "        'indices': [0, 23]}]},\n",
              "     'description': {'urls': []}},\n",
              "    'protected': False,\n",
              "    'followers_count': 216,\n",
              "    'friends_count': 534,\n",
              "    'listed_count': 1,\n",
              "    'created_at': 'Tue Apr 06 17:07:39 +0000 2021',\n",
              "    'favourites_count': 461,\n",
              "    'utc_offset': None,\n",
              "    'time_zone': None,\n",
              "    'geo_enabled': True,\n",
              "    'verified': False,\n",
              "    'statuses_count': 436,\n",
              "    'lang': None,\n",
              "    'contributors_enabled': False,\n",
              "    'is_translator': False,\n",
              "    'is_translation_enabled': False,\n",
              "    'profile_background_color': 'F5F8FA',\n",
              "    'profile_background_image_url': None,\n",
              "    'profile_background_image_url_https': None,\n",
              "    'profile_background_tile': False,\n",
              "    'profile_image_url': 'http://pbs.twimg.com/profile_images/1379481525687881729/WCaiy6Ev_normal.jpg',\n",
              "    'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1379481525687881729/WCaiy6Ev_normal.jpg',\n",
              "    'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1379480879211364352/1618407899',\n",
              "    'profile_link_color': '1DA1F2',\n",
              "    'profile_sidebar_border_color': 'C0DEED',\n",
              "    'profile_sidebar_fill_color': 'DDEEF6',\n",
              "    'profile_text_color': '333333',\n",
              "    'profile_use_background_image': True,\n",
              "    'has_extended_profile': True,\n",
              "    'default_profile': True,\n",
              "    'default_profile_image': False,\n",
              "    'following': False,\n",
              "    'follow_request_sent': False,\n",
              "    'notifications': False,\n",
              "    'translator_type': 'none',\n",
              "    'withheld_in_countries': []},\n",
              "   'geo': None,\n",
              "   'coordinates': None,\n",
              "   'place': None,\n",
              "   'contributors': None,\n",
              "   'is_quote_status': False,\n",
              "   'retweet_count': 2,\n",
              "   'favorite_count': 2,\n",
              "   'favorited': False,\n",
              "   'retweeted': False,\n",
              "   'possibly_sensitive': False,\n",
              "   'lang': 'en'},\n",
              "  'is_quote_status': False,\n",
              "  'retweet_count': 2,\n",
              "  'favorite_count': 0,\n",
              "  'favorited': False,\n",
              "  'retweeted': False,\n",
              "  'lang': 'en'}]"
            ]
          },
          "execution_count": 242,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "list(tsresp['content']['statuses'])[:2] # first two tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sDdUPf659IMq"
      },
      "source": [
        "We obtain an object with detailed information about the request and the response by Twitter, to obtain the list of tweets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWwj7bEy9IMr",
        "outputId": "241e4d44-0666-4b7e-9a87-76c11104d1b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'created_at': 'Tue May 31 11:35:49 +0000 2022',\n",
              " 'id': 1531600331196583937,\n",
              " 'id_str': '1531600331196583937',\n",
              " 'text': '@Delta I do really apologize for the inconvenience, as much as I love to assist you regarding with your concern but‚Ä¶ https://t.co/7uxcY0QJe2',\n",
              " 'truncated': True,\n",
              " 'metadata': {'iso_language_code': 'en', 'result_type': 'recent'},\n",
              " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              " 'in_reply_to_status_id': 1531040304316416000,\n",
              " 'in_reply_to_status_id_str': '1531040304316416000',\n",
              " 'in_reply_to_user_id': 5920532,\n",
              " 'in_reply_to_user_id_str': '5920532',\n",
              " 'in_reply_to_screen_name': 'Delta',\n",
              " 'user': {'id': 27519218,\n",
              "  'id_str': '27519218',\n",
              "  'name': 'Indamix',\n",
              "  'screen_name': 'marbac',\n",
              "  'location': '',\n",
              "  'description': '',\n",
              "  'url': None,\n",
              "  'entities': {'description': {'urls': []}},\n",
              "  'protected': False,\n",
              "  'followers_count': 28,\n",
              "  'friends_count': 113,\n",
              "  'listed_count': 0,\n",
              "  'created_at': 'Sun Mar 29 22:23:07 +0000 2009',\n",
              "  'favourites_count': 3140,\n",
              "  'utc_offset': None,\n",
              "  'time_zone': None,\n",
              "  'geo_enabled': False,\n",
              "  'verified': False,\n",
              "  'statuses_count': 941,\n",
              "  'lang': None,\n",
              "  'contributors_enabled': False,\n",
              "  'is_translator': False,\n",
              "  'is_translation_enabled': False,\n",
              "  'profile_background_color': '9AE4E8',\n",
              "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "  'profile_background_tile': True,\n",
              "  'profile_image_url': 'http://pbs.twimg.com/profile_images/1413528537634680842/fmFzpEdn_normal.jpg',\n",
              "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1413528537634680842/fmFzpEdn_normal.jpg',\n",
              "  'profile_link_color': '0084B4',\n",
              "  'profile_sidebar_border_color': 'BDDCAD',\n",
              "  'profile_sidebar_fill_color': 'DDFFCC',\n",
              "  'profile_text_color': '333333',\n",
              "  'profile_use_background_image': True,\n",
              "  'has_extended_profile': False,\n",
              "  'default_profile': False,\n",
              "  'default_profile_image': False,\n",
              "  'following': False,\n",
              "  'follow_request_sent': False,\n",
              "  'notifications': False,\n",
              "  'translator_type': 'none',\n",
              "  'withheld_in_countries': []},\n",
              " 'geo': None,\n",
              " 'coordinates': None,\n",
              " 'place': None,\n",
              " 'contributors': None,\n",
              " 'is_quote_status': False,\n",
              " 'retweet_count': 0,\n",
              " 'favorite_count': 0,\n",
              " 'favorited': False,\n",
              " 'retweeted': False,\n",
              " 'lang': 'en'}"
            ]
          },
          "execution_count": 243,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_tweets = tsresp[\"content\"][\"statuses\"]\n",
        "delta_tweets[0] # First tweet data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjUN5pSD9IMs"
      },
      "source": [
        "For each tweet we have an object with many details: among the key ones we have its unique ID, the name of the author and its actual text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncZvBikP9IMt",
        "outputId": "650fa5db-1a1b-4ab0-a736-4abc6c6dba45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1531600331196583937"
            ]
          },
          "execution_count": 244,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_tweets[0][\"id\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "7MjVSGsJ9IMv",
        "outputId": "6aef3007-4871-46e6-ec03-cbe217eed59a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Indamix'"
            ]
          },
          "execution_count": 245,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_tweets[0][\"user\"][\"name\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 58
        },
        "id": "HMTV3-cQ9IMx",
        "outputId": "f022d367-4214-4e37-f040-7c924873b108"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'@Delta I do really apologize for the inconvenience, as much as I love to assist you regarding with your concern but‚Ä¶ https://t.co/7uxcY0QJe2'"
            ]
          },
          "execution_count": 246,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_tweets[0][\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KTfoH9L89IMz"
      },
      "source": [
        "Define a function to repeat the operations given above on any search string and return a list of the contents of each tweet (without metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dIJlfOIX9IMz"
      },
      "outputs": [],
      "source": [
        "def get_recent_tweets(query):\n",
        "    print(\"getting tweets for '{}' ... \".format(query), end=\"\")\n",
        "    tso = TwitterSearchOrder()\n",
        "    tso.set_keywords([query]) # the keywords of our tweets search\n",
        "    tso.set_language(\"en\") # fetch only english tweets\n",
        "    tso.set_include_entities(False) # Entities provide metadata and additional contextual information about content posted on Twitter (e.g. hashtags, urls, user_mentions, symbols). https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/entities\n",
        "    tso.set_count(5) # the number of tweets we want to get. If ommitted it is set to 100 that is also the maximum value\n",
        "    tsresp = ts.search_tweets(tso)\n",
        "    texts = [status[\"text\"] for status in tsresp[\"content\"][\"statuses\"]]\n",
        "    print(\"{} retrieved\".format(len(texts)))\n",
        "    return texts"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDC-Z8Md9IM1"
      },
      "source": [
        "Use then this function to create a dictionary mapping airline names to list of relevant tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeWeR8-h9IM1",
        "outputId": "cdd65868-c732-4984-ef30-4a16f3383c32"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "getting tweets for '@delta' ... 5 retrieved\n",
            "getting tweets for '@americanair' ... 5 retrieved\n",
            "getting tweets for '@jetblue' ... 4 retrieved\n",
            "getting tweets for '@southwestair' ... 5 retrieved\n",
            "getting tweets for '@united' ... 5 retrieved\n"
          ]
        }
      ],
      "source": [
        "current_tweets = {\n",
        "    airline: get_recent_tweets(\"@\" + airline)\n",
        "    for airline in airlines\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WUU2w7RlJFE",
        "outputId": "2aa9a5f2-d270-4cc1-9f10-3dbc50fbb477"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'delta': ['@Delta Marcia(hope I spelled correctly) out of Dallas was awesome this morning helping me with my flight change‚úàÔ∏è‚úàÔ∏è. #Delta',\n",
              "  '@GymSwedeAnto @VirginAtlantic @SAS @Delta @Fly_Norwegian @British_Airways @SouthwestAir @FlyFrontier @Qantas Let‚Äòs‚Ä¶ https://t.co/NkHc2VPis4',\n",
              "  '@LCIDWYS @denise_dewald @Delta I have plenty of evidence. Measured myself',\n",
              "  \"RT @QuirkyGrrrl: @briansbergin @KazutoKiri4 @ocarroll51 @Delta You do know we're still in a pandemic and the reason the flights are cancell‚Ä¶\",\n",
              "  \"RT @ani_ta_twee_ta: Guess @Delta doesn't have much of a plan other than continuing to schedule around COVID staffing issues. They already c‚Ä¶\"],\n",
              " 'americanair': ['@AmericanAir your site won‚Äôt allow us to check in. We‚Äôve been trying since yesterday and keeps saying ‚Äúsomething went wrong‚Äù',\n",
              "  'Kudos to American Airlines flight 429 and all who helped get our students ticketed,  through security, and gate che‚Ä¶ https://t.co/mQxGlud9HI',\n",
              "  'I need a fat ass joint after this terrible trip with @AmericanAir thank god it‚Äôs legal here.',\n",
              "  'Hi @AmericanAir I had a flight scheduled today rebooked (due to American asking for volunteers) for Friday 6/3 and‚Ä¶ https://t.co/PnX88WkbSl',\n",
              "  'RT @flyamritsar: @flyamritsar to many destinations in USAüá∫üá∏ on @qatarairways with seamless convenient 1-stop via #Doha to New York, Philade‚Ä¶'],\n",
              " 'jetblue': ['@JetBlue sitting on a hot runway in JFK while you change a tire? Like seriously tires should be brand new.',\n",
              "  \"RT @RedSox: Nate's first career complete game tops the list of @JetBlue's #FlyestPlays! https://t.co/GL6bLu1RlC\",\n",
              "  'RT @gbibuildingco: CARBON CREDITS available NOW!\\n\\nOver 5 million tons of Certified #CarbonCredits for YOUR #CarbonOffset program. \\n\\nContact‚Ä¶',\n",
              "  'RT @ProfMMurray: Watched this on a @JetBlue flight and LOVED it--my seatmate even leaned over to tell me that the shots of the boeuf bourgu‚Ä¶'],\n",
              " 'southwestair': ['@GymSwedeAnto @VirginAtlantic @SAS @Delta @Fly_Norwegian @British_Airways @SouthwestAir @FlyFrontier @Qantas Let‚Äòs‚Ä¶ https://t.co/NkHc2VPis4',\n",
              "  'RT @SouthwestAir: Wanna mix things up on your next hike? Our variety of heart-pumping destinations are nothing less than epic. Give us a lo‚Ä¶',\n",
              "  'RT @SouthwestAir: @KevinTrudel15 Hit the trails by foot or wheels, then find a spot to set up camp. Kick back and breathe deep. Chances are‚Ä¶',\n",
              "  'RT @SouthwestAir: @KevinTrudel15 Make your escape to this lush, mountain bliss, where you can do everything from jogging to camping‚Äîand mor‚Ä¶',\n",
              "  '@AnnaPAnana_ @tee_new_win @SouthwestAir Seen it in practice and the airlines could argue to protect the passengers‚Ä¶ https://t.co/cL4TRnHQPH'],\n",
              " 'united': ['RT @united: Find your seat and buckle up. This story is gonna be a good one. üßµ \\n \\nBut first, choose your snack for the ride:',\n",
              "  '@united you lost our bags, we have lost 5 hours of our vacation time and now your staff is rude to us because you‚Ä¶ https://t.co/an0FKT0U2K',\n",
              "  'RT @gbibuildingco: CARBON CREDITS available NOW!\\n\\nOver 5 million tons of Certified #CarbonCredits for YOUR #CarbonOffset program. \\n\\nContact‚Ä¶',\n",
              "  '@andromeda_twts @united Good luck - you‚Äôre screwed.',\n",
              "  '@PaperUtd @FabrizioRomano Hopefully they will get him !! Make it happen @United']}"
            ]
          },
          "execution_count": 249,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW7g6aIYleKr",
        "outputId": "aaa878b7-c490-4073-a51c-153c25ab50a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['@Delta Marcia(hope I spelled correctly) out of Dallas was awesome this morning helping me with my flight change‚úàÔ∏è‚úàÔ∏è. #Delta',\n",
              " '@GymSwedeAnto @VirginAtlantic @SAS @Delta @Fly_Norwegian @British_Airways @SouthwestAir @FlyFrontier @Qantas Let‚Äòs‚Ä¶ https://t.co/NkHc2VPis4',\n",
              " '@LCIDWYS @denise_dewald @Delta I have plenty of evidence. Measured myself']"
            ]
          },
          "execution_count": 250,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_tweets[\"delta\"][:3] # first 3 tweets about delta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjfbPhaw9IM4"
      },
      "source": [
        "### Using pre-collected tweets\n",
        "\n",
        "For convenience, we provide a set of precollected tweets about the airline companies as an alternative to latest tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJXE4I_I9IM4"
      },
      "outputs": [],
      "source": [
        "download(\"tweets.zip\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/tweets.zip\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4sEkMrRK9IM6"
      },
      "source": [
        "The ZIP archive contains a `company_name.txt` file for each airline company, each with a list of tweets (one per line): we load them into a dict mapping the name of each company to the list of relevant tweets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQzbR0hz9IM7"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "archive_tweets = {}\n",
        "with ZipFile(\"tweets.zip\") as zipf:\n",
        "    for airline in airlines:\n",
        "        with zipf.open(airline + \".txt\") as f:\n",
        "            archive_tweets[airline] = list(line.decode().strip() for line in f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScC5ge499IM8"
      },
      "source": [
        "You can read for example some tweets about Delta airlines:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rg0Nu9e9IM9",
        "outputId": "d4c53f15-faab-4296-bdd3-368bca0c1282"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings vs Rangers in NY - http://t.co/JXBc5kDXnZ\"RT',\n",
              " '@AneetharPweety am @delta state buh on ma way to benin city now',\n",
              " 'RT @iamdiddy: If you‚Äôre flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lounge at @Delta terminal at JFK. http://t.co/‚Ä¶']"
            ]
          },
          "execution_count": 253,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "archive_tweets[\"delta\"][:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-dWEteC9IM-"
      },
      "source": [
        "In the following we will work on these `archive_tweets`, replace that in the line below with `current_tweets` if you want to use downloaded tweets instead"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qO407nji9IM-"
      },
      "outputs": [],
      "source": [
        "tweets = archive_tweets # current_tweets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "khZAVoZV9INA"
      },
      "source": [
        "To better deal with them later, we represents tweets into a pandas DataFrame with two columns\n",
        "- a `text` column with the text of the tweet\n",
        "- an `airline` column with the airline each tweet refers to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_q-5J0N9INA"
      },
      "outputs": [],
      "source": [
        "tweets = pd.DataFrame(\n",
        "    {\"airline\": airline, \"text\": text}\n",
        "    for airline, tweetlist in tweets.items()\n",
        "    for text in tweetlist\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "BVxwWYH79INC",
        "outputId": "6b816d3c-6ede-49ac-8e38-e85b117bde43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>delta</td>\n",
              "      <td>\"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>delta</td>\n",
              "      <td>@AneetharPweety am @delta state buh on ma way to benin city now</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>delta</td>\n",
              "      <td>RT @iamdiddy: If you‚Äôre flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  airline  \\\n",
              "0   delta   \n",
              "1   delta   \n",
              "2   delta   \n",
              "\n",
              "                                                                                                  text  \n",
              "0  \"@LAKings: Are you the #LAKings biggest fan? Prove it and win a trip on @Delta to see the Kings ...  \n",
              "1                                      @AneetharPweety am @delta state buh on ma way to benin city now  \n",
              "2  RT @iamdiddy: If you‚Äôre flying out of JFK on @Delta you NEED to check out the new @CIROC VIP lou...  "
            ]
          },
          "execution_count": 256,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKrg7s8f9INF"
      },
      "source": [
        "### Estimating sentiment using lists of opinion words\n",
        "\n",
        "Several methods and algorithms have been proposed in literature to estimate the sentiment of a document (or sentence), usually quite complex.\n",
        "\n",
        "To get started, we will use a simple lexicon-based method which assigns a score by counting known positive and negative words in each tweet.\n",
        "\n",
        "Hu and Liu made available for download a list of about 6,800 words labeled as either positive or negative.\n",
        "\n",
        "- **Positive:** love, best, cool, great, good, amazing, ...\n",
        "- **Negative:** hate, worst, sucks, awful, nightmare, ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrgWberF9INF"
      },
      "source": [
        "We write\n",
        "- a function used to process word lists, ignoring lines either empty or starting with \";\" (comments)\n",
        "- another function using the first one to get a set of words contained in a named file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BBxH-BSW9ING"
      },
      "outputs": [],
      "source": [
        "def scan_hu_liu(f):\n",
        "    for line in f:\n",
        "        line = line.decode(errors=\"ignore\").strip() # strip() function removes spaces at the beginning and at the end of the string\n",
        "        if line and not line.startswith(\";\"):\n",
        "            yield line\n",
        "\n",
        "def load_hu_liu(filename):\n",
        "    with open(filename, \"rb\") as f:  # b binary mode\n",
        "        return set(scan_hu_liu(f)) # set(...) is the build function to create a new Python set {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mqbslQd69INI"
      },
      "source": [
        "We then download the two sets (one for positive words and one for negative ones) and use the latter function to load them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAfuoln99INI",
        "outputId": "db9f9c2b-ba75-421d-a824-1687d1dc829f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Positive words\n",
            "{'enchanting', 'polished', 'amaze', 'smilingly', 'vivid', 'humor', 'benefactor', 'enthrall', 'modest', 'liberate', 'prosperous', 'nicest', 'tougher', 'enhanced', 'picturesque', 'fairly', 'ecstatically', 'improve', 'lustrous', 'rich', 'eases', 'redemption', 'sagely', 'embolden', 'invigorating', 'great', 'adoringly', 'marvelled', 'luck', 'energetic', 'mighty', 'humility', 'undisputed', 'skillful', 'invaluablely', 'self-respect', 'compactly', 'accomplish', 'loves', 'stellarly', 'cleanest', 'straighten', 'thriving', 'well', 'delectable', 'sensation', 'calming', 'stimulative', 'preferes', 'groundbreaking', 'spellbinding', 'pleasurable', 'unfettered', 'equitable', 'fastest', 'cohere', 'humourous', 'chic', 'diplomatic', 'mastery', 'champion', 'excited', 'rejoicing', 'matchless', 'bonuses', 'flawlessly', 'fondness', 'remedy', 'hospitable', 'outstanding', 'beckoned', 'adore', 'perseverance', 'rapture', 'simplifies', 'clearly', 'overtake', 'upbeat', 'fruitful', 'dominates', 'gooood', 'securely', 'terrific', 'fashionable', 'monumentally', 'obsessions', 'finest', 'divine', 'counter-attacks', 'flatter', 'liking', 'thumb-up', 'conveniently', 'warm', 'entertain', 'eloquent', 'blameless', 'nice', 'thinner', 'silent', 'gratifies', 'supremacy', 'convenient', 'enviable', 'beneficially', 'glorify', 'cool', 'loyalty', 'enrapture', 'better', 'resound', 'astounded', 'enliven', 'record-setting', 'attractive', 'encourage', 'patriot', 'dignified', 'impress', 'nifty', 'charismatic', 'recommendation', 'survival', 'serene', 'quicker', 'brilliantly', 'glowing', 'awsome', 'paradise', 'first-rate', 'successes', 'unrestricted', 'cherish', 'cuteness', 'ebullient', 'trustworthy', 'chaste', 'smart', 'vouchsafe', 'skilled', 'fluent', 'marvel', 'evenly', 'rapt', 'admirable', 'kindly', 'proving', 'healthful', 'lighter', 'unabashedly', 'sensations', 'posh', 'rock-stars', 'well-bred', 'considerate', 'thank', 'commodious', 'stylish', 'won', 'comfortable', 'commend', 'clear-cut', 'overjoyed', 'freedom', 'phenomenal', 'examplary', 'well-established', 'generously', 'thrilling', 'freed', 'gracefully', 'handy', 'rectify', 'undisputably', 'flutter', 'aspirations', 'playfully', 'worth', 'lean', 'engrossing', 'sophisticated', 'heaven', 'mesmerizing', 'wisdom', 'benevolent', 'light-hearted', 'liberation', 'passion', 'adulation', 'gratefully', 'intriguingly', 'illumine', 'grace', 'sufficed', 'liberty', 'perfection', 'convienient', 'peacekeepers', 'jubilation', 'charm', 'jubiliant', 'revitalize', 'elate', 'enjoyably', 'euphoric', 'unfazed', 'aspire', 'proud', 'honor', 'confidence', 'peerless', 'creative', 'enhancement', 'stupendously', 'gratify', 'survivor', 'abound', 'rightful', 'admire', 'swank', 'wieldy', 'low-price', 'appreciable', 'futuristic', 'fancy', 'lawfully', 'zest', 'well-backlit', 'chivalry', 'hail', 'virtue', 'worthiness', 'deservedly', 'nicely', 'admirer', 'well-rounded', 'compatible', 'properly', 'thrive', 'victory', 'glad', 'reverent', 'colorful', 'endorses', 'top-notch', 'strong', 'advocates', 'tops', 'cheery', 'hotcakes', 'loyal', 'pamperedness', 'momentous', 'respite', 'thrifty', 'led', 'impeccable', 'lively', 'trump', 'well-wishers', 'glitter', 'reasonable', 'risk-free', 'heartwarming', 'succeeded', 'trophy', 'infallibility', 'gentle', 'durable', 'visionary', 'graciousness', 'humble', 'amusingly', 'wonderful', 'classic', 'stirringly', 'upheld', 'celebratory', 'humour', 'seasoned', 'hopeful', 'multi-purpose', 'effusion', 'well-informed', 'monumental', 'irreplaceable', 'dependable', 'rightly', 'well-mannered', 'profoundly', 'genius', 'appreciates', 'radiance', 'elite', 'ecstasy', 'triumphant', 'fragrant', 'yay', 'idealize', 'slammin', 'portable', 'handily', 'amiabily', 'assuredly', 'confident', 'prudent', 'ardent', 'swankier', 'praising', 'righteous', 'enthral', 'cashback', 'pleasurably', 'smiling', 'benifits', 'aspiration', 'lionhearted', 'complements', 'viewable', 'cashbacks', 'worthy', 'gorgeously', 'awestruck', 'exultingly', 'unequivocally', 'justly', 'jaw-droping', 'succeeding', 'intricate', 'fans', 'advantageously', 'assure', 'supportive', 'euphoria', 'quieter', 'enviably', 'soundness', 'tempting', 'pleases', 'sane', 'daring', 'richer', 'venerate', 'fulfillment', 'goodwill', 'thrift', 'sexy', 'progress', 'poetic', 'fertile', 'laud', 'generous', 'uphold', 'supported', 'whooa', 'distinction', 'stunned', 'well-balanced', 'effortlessly', 'brilliance', 'unrivaled', 'bloom', 'optimism', 'heroize', 'polite', 'impeccably', 'faster', 'effective', 'charisma', 'efficiently', 'grin', 'foolproof', 'purposeful', 'excellence', 'fav', 'sparkling', 'catchy', 'enhances', 'gentlest', 'inviolable', 'recommendations', 'conciliatory', 'well-made', 'prosper', 'dawn', 'affordably', 'ingeniously', 'erudite', 'refined', 'courageousness', 'evaluative', 'irresistibly', 'superb', 'supporting', 'ingenious', 'immaculately', 'upscale', 'fanfare', 'soft', 'righteously', 'brainy', 'civility', 'fascinate', 'entrust', 'welcome', 'readily', 'undamaged', 'guarantee', 'economical', 'luxuriant', 'jolly', 'positive', 'togetherness', 'worked', 'tranquility', 'rightfully', 'supurbly', 'efficacious', 'profound', 'restructured', 'golden', 'celebrate', 'flourish', 'headway', 'affability', 'protection', 'paramount', 'rewardingly', 'exhilaratingly', 'modesty', 'poised', 'decent', 'extol', 'staunch', 'saint', 'fresher', 'diligently', 'foremost', 'respectful', 'felicitate', 'wows', 'luckier', 'balanced', 'affirmative', 'flatteringly', 'illuminating', 'valiantly', 'pamperedly', 'supreme', 'attraction', 'surpass', 'gracious', 'pluses', 'peps', 'upliftment', 'user-replaceable', 'congratulations', 'supurb', 'glimmering', 'excelled', 'feasible', 'gladly', 'raptureously', 'fearlessly', 'trust', 'courteous', 'unbiased', 'awarded', 'endorsed', 'keenness', 'worth-while', 'gleeful', 'spellbindingly', 'illuminate', 'exaltedly', 'inventive', 'profuse', 'beautifully', 'believeable', 'cozy', 'surreal', 'winnable', 'ilu', 'compact', 'thrills', 'self-satisfaction', 'amenable', 'heros', 'joyful', 'wonder', 'happily', 'sincerely', 'gladden', 'secure', 'intriguing', 'marvellous', 'fancier', 'mercifully', 'upgraded', 'applaud', 'wellbeing', 'infallible', 'levity', 'wisely', 'advantageous', 'hallmark', 'tenderly', 'encouragingly', 'slick', 'magic', 'oasis', 'good', 'surmount', 'danken', 'impressiveness', 'favorite', 'perfectly', 'savings', 'efficient', 'positives', 'unparalleled', 'prodigious', 'alluringly', 'steadfastness', 'memorable', 'graciously', 'interesting', 'favour', 'awesome', 'revive', 'constructive', 'phenomenally', 'attentive', 'harmoniously', 'enlighten', 'splendidly', 'valuable', 'entrancing', 'satisified', 'buoyant', 'prefers', 'angelic', 'patiently', 'god-send', 'blissful', 'prize', 'impressive', 'wise', 'wonders', 'warmly', 'courtly', 'capably', 'optimistic', 'standout', 'contrasty', 'luster', 'individualized', 'ease', 'mightily', 'comfort', 'significant', 'tantalizing', 'support', 'intelligible', 'stimulates', 'articulate', 'fecilitous', 'agilely', 'sustainable', 'tantalize', 'wealthy', 'decency', 'blithe', 'illustrious', 'simplifying', 'feisty', 'desirous', 'amply', 'achievement', 'amiability', 'promising', 'prestige', 'nourishment', 'exceptionally', 'resourcefulness', 'agility', 'excitingly', 'solidarity', 'adored', 'super', 'enjoyable', 'prosperity', 'tickle', 'revelation', 'invulnerable', 'majestic', 'exceeded', 'rock-star', 'autonomous', 'skillfully', 'destiny', 'attune', 'astonished', 'amazes', 'divinely', 'steady', 'problem-solver', 'benevolence', 'replaceable', 'simplified', 'hardier', 'industrious', 'peace', 'mesmerized', 'effusively', 'vibrant', 'maturity', 'resourceful', 'approve', 'imaculate', 'refinement', 'assurance', 'orderly', 'alluring', 'privileged', 'titillate', 'politeness', 'well-positioned', 'amazingly', 'infallibly', 'incredible', 'excel', 'accomodative', 'top-quality', 'courage', 'pretty', 'renewed', 'amusing', 'prettily', 'fortune', 'invaluable', 'accolade', 'prudently', 'terrifically', 'timely', 'soulful', 'gratifying', 'congenial', 'revolutionized', 'straightforward', 'advantages', 'superior', 'amenity', 'soundly', 'amicably', 'hot', 'peaceable', 'right', 'faith', 'mercy', 'famously', 'dependably', 'proactive', 'faultless', 'adorer', 'excellently', 'instantly', 'lyrical', 'revival', 'beneficial', 'unquestionably', 'beutifully', 'capable', 'gratification', 'sumptuously', 'better-than-expected', 'roomier', 'well-behaved', 'redeeming', 'heartening', 'endorsing', 'enlightenment', 'valiant', 'hale', 'noble', 'impassioned', 'pleasant', 'empathize', 'glamorous', 'exuberant', 'attractively', 'fervor', 'marvels', 'exaltingly', 'exultation', 'flexible', 'edify', 'bountiful', 'thankful', 'reliable', 'romanticize', 'empathy', 'softer', 'pre-eminent', 'elatedly', 'incredibly', 'enviously', 'appealing', 'likes', 'enterprising', 'acclaimed', 'coherent', 'eagerness', 'inestimably', 'miraculous', 'exellent', 'overtakes', 'smitten', 'feature-rich', 'speedy', 'meritorious', 'breakthrough', 'acumen', 'benefit', 'ready', 'work', 'supple', 'sensibly', 'guidance', 'twinkly', 'well-run', 'trumpet', 'affably', 'enough', 'reconciliation', 'complemented', 'overtaking', 'sturdy', 'rational', 'convenience', 'jaw-dropping', 'effusiveness', 'overture', 'well-known', 'victorious', 'tidy', 'respect', 'precious', 'gusto', 'abounds', 'privilege', 'brainiest', 'jubilant', 'exhilarating', 'fine-looking', 'gratifyingly', 'noteworthy', 'envious', 'sufficiently', 'feasibly', 'enrapt', 'self-sufficiency', 'credible', 'ebulliently', 'congratulate', 'bargain', 'keenly', 'substantive', 'encouragement', 'productively', 'obsession', 'inspire', 'woo', 'promoter', 'greatness', 'dignify', 'smooth', 'free', 'indulgence', 'sparkle', 'freedoms', 'reachable', 'reputable', 'impartiality', 'counter-attack', 'masterpiece', 'restructure', 'warmer', 'entertains', 'enthusiasm', 'sincerity', 'compliant', 'piety', 'reverently', 'bravo', 'stainless', 'unassailable', 'affluent', 'solid', 'patriotic', 'enrichment', 'talents', 'principled', 'originality', 'rejoicingly', 'accomplishments', 'rockstar', 'fabulously', 'rectification', 'eventful', 'ambitious', 'chivalrous', 'stunning', 'encouraging', 'exultant', 'heartfelt', 'facilitate', 'sagacity', 'amicable', 'thoughtfully', 'enticed', 'awesomeness', 'cure', 'eyecatch', 'shimmering', 'available', 'flattering', 'dazzled', 'audibly', 'exceeds', 'accolades', 'appropriate', 'protect', 'supporter', 'loving', 'plusses', 'lucid', 'entertaining', 'sturdier', 'clears', 'streamlined', 'gaily', 'lovable', 'heroically', 'triumphantly', 'first-in-class', 'excitedness', 'leading', 'genuine', 'enticing', 'fortunately', 'invincibility', 'astound', 'refresh', 'fast-growing', 'unity', 'punctual', 'dumbfounding', 'happier', 'exuberantly', 'enhance', 'reform', 'rockstars', 'hero', 'hooray', 'brilliant', 'responsive', 'enjoy', 'luxurious', 'youthful', 'accomplished', 'idol', 'charitable', 'cute', 'award', 'proper', 'pleasure', 'danke', 'panoramic', 'irresistible', 'subsidize', 'auspicious', 'well-received', 'hallowed', 'simpler', 'enticingly', 'wowed', 'fair', 'leads', 'reformed', 'understandable', 'superiority', 'peppy', 'resolute', 'greatest', 'happy', 'harmless', 'painless', 'logical', 'laudable', 'geekier', 'ultra-crisp', 'striving', 'suffice', 'world-famous', 'soothingly', 'dexterously', 'honored', 'law-abiding', 'cheerful', 'problem-free', 'magnificently', 'delicacy', 'harmonize', 'dedicated', 'instructive', 'rejuvenated', 'pep', 'brighten', 'dextrous', 'endear', 'fascinatingly', 'intuitive', 'masterful', 'ingenuous', 'stability', 'swankiest', 'innocuous', 'steadfastly', 'simplest', 'talented', 'elan', 'pride', 'thrillingly', 'beneficiary', 'defeating', 'euphorically', 'apotheosis', 'merciful', 'merriness', 'passionately', 'honorable', 'ennoble', 'sweetly', 'marveled', 'unconditional', 'galore', 'altruistic', 'joyously', 'pain-free', 'believable', 'glimmer', 'virtuously', 'delighted', 'satisfying', 'virtuous', 'successfully', 'like', 'gutsy', 'openness', 'vigilance', 'modern', 'liked', 'rejoice', 'zippy', 'enjoyment', 'temptingly', 'staunchly', 'brand-new', 'precisely', 'merry', 'appreciatively', 'traction', 'inestimable', 'unselfish', 'continuity', 'exquisitely', 'integral', 'precise', 'detachable', 'uplifting', 'cheapest', 'correctly', 'meaningful', 'outstrip', 'sensitive', 'elegance', 'preferring', 'spiritual', 'long-lasting', 'flexibility', 'outperform', 'supports', 'sustainability', 'commendably', 'luxury', 'beneficent', 'neat', 'dazzling', 'dominated', 'helped', 'stabilize', 'consistently', 'brave', 'deserving', 'well-intentioned', 'receptive', 'faithfully', 'pleasing', 'ardor', 'romantically', 'usable', 'energy-efficient', 'swift', 'realizable', 'hotcake', 'trouble-free', 'safely', 'breathtakingly', 'honest', 'glory', 'boom', 'solicitous', 'magnanimous', 'reassure', 'affirm', 'relish', 'pamper', 'prospros', 'excellent', 'promises', 'suffices', 'delightfully', 'upliftingly', 'wonderously', 'shiny', 'success', 'hard-working', 'truthfulness', 'comprehensive', 'honoring', 'goodly', 'prominent', 'adaptive', 'proves', 'sweetness', 'first-class', 'truthful', 'mesmerizes', 'merrily', 'easier', 'sumptuousness', 'exceeding', 'laudably', 'heal', 'civilize', 'distinguished', 'sensational', 'stupendous', 'conscientious', 'agreeable', 'excites', 'renown', 'ecstatic', 'praiseworthy', 'famous', 'expansive', 'restored', 'astonishingly', 'wondrous', 'speedily', 'heavenly', 'spacious', 'avid', 'revolutionary', 'undaunted', 'stimulating', 'gladness', 'god-given', 'immense', 'exaltation', 'dead-cheap', 'verifiable', 'miracle', 'joy', 'adaptable', 'works', 'preeminent', 'electrify', 'ideal', 'agreeably', 'dazzle', 'nimble', 'enjoys', 'saver', 'convience', 'restructuring', 'ardently', 'correct', 'unforgettable', 'miracles', 'fortuitously', 'lover', 'handsomely', 'blessing', 'better-known', 'astonishing', 'masterpieces', 'desirable', 'idolize', 'flashy', 'spontaneous', 'master', 'smartly', 'adjustable', 'glitz', 'winner', 'improves', 'shimmeringly', 'gratified', 'veritable', 'distinctive', 'effusive', 'complementary', 'gainfully', 'comfortably', 'faithfulness', 'uncomplicated', 'well-regarded', 'fresh', 'angel', 'illuminati', 'unbound', 'eased', 'sensible', 'glow', 'accurate', 'cleanliness', 'exceptional', 'meticulously', 'non-violence', 'unabashed', 'clever', 'feat', 'inspirational', 'respectfully', 'excellency', 'remarkably', 'poise', 'improvement', 'glowingly', 'educated', 'lawful', 'willingly', 'awesomely', 'realistic', 'stunningly', 'spotless', 'beloved', 'peacefully', 'glisten', 'fun', 'manageable', 'courageous', 'humorously', 'opulent', 'classy', 'unreal', 'hallmarks', 'steadfast', 'best-known', 'gaining', 'grateful', 'promptly', 'tranquil', 'playful', 'advocate', 'tender', 'bonus', 'cushy', 'love', 'merriment', 'bullish', 'affection', 'jovial', 'statuesque', 'snazzy', 'permissible', 'carefree', 'smile', 'low-priced', 'quaint', 'gained', 'endorse', 'suitable', 'serenity', 'powerfully', 'dumbfounded', 'acclamation', 'reasoned', 'deginified', 'regard', 'fiery', 'lower-priced', 'tremendously', 'magical', 'safe', 'treasure', 'cleaner', 'magnificent', 'innovation', 'effectual', 'dreamland', 'clear', 'accessible', 'proficient', 'fame', 'revere', 'refreshed', 'dote', 'fortunate', 'consummate', 'champ', 'exceed', 'defeat', 'reputation', 'irreproachable', 'savvy', 'inviolate', 'handsome', 'crisper', 'cooperatively', 'conciliate', 'gorgeous', 'radiant', 'awe', 'upgradeable', 'sweetheart', 'assurances', 'foresight', 'vibrantly', 'time-honored', 'trusting', 'pepping', 'exuberance', 'spirited', 'fascination', 'mesmerizingly', 'well-managed', 'calmness', 'effectiveness', 'reclaim', 'steadiness', 'courageously', 'loved', 'valor', 'relaxed', 'high-spirited', 'impressively', 'impartially', 'pardon', 'enjoyed', 'enraptured', 'ethical', 'likable', 'commitment', 'calm', 'contentment', 'famed', 'triumph', 'adequate', 'delicate', 'best', 'regal', 'examplar', 'invincible', 'dauntless', 'hands-down', 'state-of-the-art', 'trusted', 'unencumbered', 'reforms', 'nurturing', 'worthwhile', 'intimacy', 'steadiest', 'hilarious', 'goodness', 'persevere', 'renaissance', 'avidly', 'blockbuster', 'thrilled', 'amicability', 'subsidizes', 'enjoying', 'ftw', 'beautify', 'finely', 'outdo', 'nicer', 'enrich', 'wowing', 'whoa', 'hardy', 'advantage', 'advocated', 'insightful', 'appeal', 'easiest', 'ameliorate', 'convient', 'positively', 'impresses', 'succeeds', 'futurestic', 'masters', 'cherished', 'excelent', 'sharpest', 'best-performing', 'prodigiously', 'comfy', 'prestigious', 'outshone', 'admiration', 'talent', 'uplift', 'freshest', 'favor', 'zenith', 'peach', 'loveliness', 'affectionate', 'enthralled', 'energize', 'relief', 'eager', 'favorable', 'nobly', 'flawless', 'satisfied', 'tantalizingly', 'tempt', 'genial', 'glorious', 'marvelous', 'romantic', 'kindliness', 'pampers', 'empowerment', 'lovably', 'fervid', 'warmhearted', 'felicity', 'inspiring', 'unbeatable', 'proficiently', 'skill', 'exquisite', 'thoughtfulness', 'defeats', 'heartily', 'robust', 'sharper', 'painlessly', 'sprightly', 'integrated', 'gains', 'entice', 'renowned', 'outshine', 'palatial', 'winners', 'cleverly', 'excellant', 'priceless', 'strikingly', 'booming', 'gem', 'goood', 'smarter', 'doubtless', 'glee', 'jollify', 'spellbind', 'celebration', 'accommodative', 'prodigy', 'geeky', 'ingenuously', 'bliss', 'coolest', 'stylized', 'selective', 'appreciative', 'handier', 'wow', 'patience', 'whoooa', 'morality', 'miraculousness', 'transparent', 'formidable', 'enviousness', 'gems', 'hottest', 'harmonious', 'generosity', 'glistening', 'prefer', 'elegantly', 'concise', 'delight', 'plush', 'adventuresome', 'top', 'sufficient', 'prompt', 'rapturous', 'refund', 'eagerly', 'helping', 'fancinating', 'rewarding', 'revives', 'afford', 'scenic', 'prolific', 'trusty', 'personages', 'brighter', 'cornerstone', 'inexpensive', 'revel', 'friendliness', 'legendary', 'achievable', 'brotherly', 'keen', 'happiness', 'staunchness', 'advanced', 'fastest-growing', 'lavishly', 'excels', 'notably', 'everlasting', 'ecstasies', 'delightful', 'godsend', 'profusion', 'impressed', 'excitedly', 'innovative', 'enthusiastic', 'complimentary', 'captivate', 'exemplary', 'brilliances', 'dirt-cheap', 'authoritative', 'qualified', 'abundant', 'revolutionizes', 'gaiety', 'optimal', 'cherub', 'outperforms', 'ambitiously', 'excitement', 'effectively', 'indebted', 'ergonomical', 'adorable', 'defender', 'fairness', 'outdone', 'tenacity', 'solace', 'undisputable', 'tenacious', 'accessable', 'enchant', 'frolic', 'extraordinarily', 'easiness', 'productive', 'superbly', 'trustingly', 'warmth', 'extraordinary', 'readable', 'win', 'aver', 'indulgent', 'bolster', 'approval', 'maneuverable', 'eminence', 'novelty', 'eyecatching', 'assuring', 'fast', 'pampered', 'admiring', 'intelligent', 'healthy', 'issue-free', 'reverence', 'improving', 'overtook', 'gratitude', 'important', 'benefits', 'affordable', 'favored', 'stately', 'gush', 'elation', 'cure-all', 'fidelity', 'exhilarate', 'devout', 'gain', 'acclaim', 'ideally', 'exceled', 'ebullience', 'successful', 'friendly', 'cheaper', 'miraculously', 'endearing', 'luckiest', 'enthusiast', 'finer', 'evocative', 'heroic', 'proven', 'ovation', 'user-friendly', 'strongest', 'admiringly', 'cajole', 'deference', 'excallent', 'outstandingly', 'triumphal', 'compassionate', 'eulogize', 'neatly', 'openly', 'reward', 'variety', 'lucidly', 'rapid', 'comely', 'swanky', 'jubilate', 'diversified', 'earnestly', 'eloquently', 'sweeping', 'smoother', 'mesmerize', 'tingle', 'darling', 'fervidly', 'majesty', 'passionate', 'earnestness', 'dominate', 'preferable', 'extoll', 'reconcile', 'high-quality', 'exalted', 'poignant', 'reaffirm', 'snappy', 'mature', 'stellar', 'kid-friendly', 'dexterous', 'adventurous', 'idolized', 'sociable', 'exult', 'saintliness', 'exalting', 'lovely', 'preferably', 'daringly', 'rightness', 'patient', 'responsibly', 'hug', 'astoundingly', 'audible', 'amiable', 'refunded', 'sleek', 'enthusiastically', 'thoughtful', 'luckiness', 'reforming', 'energy-saving', 'merit', 'willing', 'honesty', 'expeditiously', 'convincingly', 'masterfully', 'pleasingly', 'unmatched', 'leverage', 'toll-free', 'jubilantly', 'credence', 'convincing', 'lucrative', 'bravery', 'pleasantly', 'resounding', 'breathtaking', 'harmony', 'affluence', 'err-free', 'gumption', 'easy', 'powerful', 'luxuriously', 'subsidizing', 'tenaciously', 'recovery', 'popular', 'dashing', 'satisfy', 'effortless', 'seamless', 'insightfully', 'unquestionable', 'sensationally', 'progressive', 'gifted', 'magnanimously', 'authentic', 'wins', 'boost', 'beautiful', 'mind-blowing', 'versatility', 'all-around', 'charming', 'poeticize', 'beckon', 'stimulate', 'faithful', 'entranced', 'fortitude', 'favorited', 'fortuitous', 'vigilant', 'enthuse', 'personalized', 'cleanly', 'refreshing', 'resilient', 'cooperative', 'decisive', 'impartial', 'beckons', 'dignity', 'intelligence', 'quiet', 'satisfactory', 'commendable', 'congratulatory', 'useable', 'gallantly', 'affectation', 'agreeableness', 'stronger', 'self-determination', 'holy', 'accomplishment', 'afordable', 'kindness', 'exonerate', 'razor-sharp', 'charmingly', 'deft', 'smoothes', 'agile', 'satisfies', 'trendy', 'cost-effective', 'delightfulness', 'ample', 'abundance', 'judicious', 'a+', 'subsidized', 'elegant', 'righteousness', 'fascinating', 'wonderfully', 'fearless', 'providence', 'versatile', 'defeated', 'satisfactorily', 'self-sufficient', 'humorous', 'inpressed', 'astutely', 'invigorate', 'dynamic', 'contribution', 'resplendent', 'adulate', 'ingenuity', 'savior', 'retractable', 'outperforming', 'pinnacle', 'motivated', 'breathlessness', 'festive', 'noiseless', 'marvelously', 'crisp', 'wholeheartedly', 'amuse', 'eye-catching', 'influential', 'toughest', 'unequivocal', 'joyous', 'gainful', 'suave', 'refine', 'workable', 'tough', 'lifesaver', 'bright', 'promise', 'felicitous', 'exemplar', 'unlimited', 'rejuvenating', 'astonish', 'exhilaration', 'prominence', 'useful', 'breakthroughs', 'engaging', 'meticulous', 'exalt', 'beckoning', 'astounding', 'beauteous', 'thrill', 'witty', 'tolerable', 'easygoing', 'consistent', 'maturely', 'trustworthiness', 'adroit', 'admirably', 'instrumental', 'perfect', 'peaceful', 'humane', 'low-risk', 'interests', 'enchanted', 'compassion', 'recomend', 'striking', 'empower', 'amazing', 'gleefully', 'richness', 'fondly', 'cheer', 'respectable', 'well-being', 'blossom', 'coherence', 'recommended', 'succeed', 'reasonably', 'splendid', 'smartest', 'low-cost', 'affable', 'adoring', 'sublime', 'reaffirmation', 'sharp', 'richly', 'captivating', 'purify', 'kudos', 'accurately', 'cleared', 'firmer', 'exceedingly', 'amity', 'sporty', 'topnotch', 'cost-saving', 'magnificence', 'splendor', 'bless', 'amazement', 'fond', 'wholesome', 'fave', 'grandeur', 'supremely', 'competitive', 'desiring', 'achievements', 'salute', 'guiltless', 'nourish', 'diligent', 'cohesive', 'boundless', 'fashionably', 'covenant', 'smoothly', 'affinity', 'adroitly', 'beautifullly', 'amazed', 'luxuriate', 'bonny', 'plentiful', 'saintly', 'joyfully', 'breeze', 'swiftness', 'rejuvenate', 'righten', 'obtainable', 'achievible', 'godlike', 'reliably', 'lush', 'flourishing', 'propitious', 'smiles', 'capability', 'outsmart', 'backbone', 'remarkable', 'fantastic', 'enchantingly', 'upgradable', 'unwavering', 'willingness', 'brisk', 'salutary', 'prefered', 'suavely', 'premier', 'spectacularly', 'beauty', 'propitiously', 'congratulation', 'revolutionize', 'excite', 'neatest', 'simplify', 'rectifying', 'frugal', 'brightest', 'pleased', 'homage', 'rosy', 'smoothest', 'fine', 'roomy', 'large-capacity', 'pure', 'restful', 'vouch', 'knowledgeable', 'sweet', 'adulatory', 'clean', 'unaffected', 'truthfully', 'appreciated', 'endorsement', 'eminent', 'fervently', 'regally', 'celebrated', 'spectacular', 'clarity', 'gallant', 'rapturously', 'winning', 'succes', 'gloriously', 'imaginative', 'blissfully', 'overtaken', 'soothe', 'stable', 'praise', 'halcyon', 'awards', 'envy', 'remission', 'easing', 'awed', 'improved', 'prowess', 'windfall', 'luminous', 'improvements', 'best-selling', 'comforting', 'stylishly', 'well-educated', 'ecenomical', 'appreciate', 'spellbound', 'zeal', 'fervent', 'solicitously', 'trivially', 'decisiveness', 'titillating', 'redeem', 'sweeten', 'pepped', 'lead', 'relent', 'prudence', 'vivacious', 'marvelousness', 'easy-to-use', 'graceful', 'rapport', 'gold', 'inspiration', 'non-violent', 'pros', 'lucky', 'altruistically', 'earnest', 'complement', 'diligence', 'thumbs-up', 'outwit', 'affirmation', 'remunerate', 'qualify', 'eloquence', 'raptureous', 'intimate', 'clearer', 'dotingly', 'astonishment', 'titillatingly', 'compliment', 'intrigue', 'heroine', 'sumptuous', 'expertly', 'promised', 'fabulous', 'hearten', 'protective', 'delicious', 'exciting', 'shine', 'dead-on', 'lavish', 'fantastically', 'grand', 'idyllic', 'recommend', 'dummy-proof', 'immaculate', 'sincere', 'nourishing', 'recover', 'eye-catch', 'wonderous', 'elated', 'outperformed', 'well-connected', 'helpful', 'fast-paced', 'elevate', 'reassurance', 'navigable'}\n",
            "\n",
            "Negative words\n",
            "{'died', 'addict', 'condemned', 'frustrated', 'perfidious', 'restrict', 'rigid', 'gritty', 'foreboding', 'ruthlessly', 'spew', 'dissidents', 'run-down', 'slothful', 'unjustifiable', 'moan', 'unacceptablely', 'viciousness', 'perversion', 'complain', 'mordant', 'stymied', 'liability', 'gruff', 'farcically', 'miscreants', 'repel', 'wrangle', 'clunky', 'inescapable', 'clamor', 'overplay', 'self-interest', 'franticly', 'uncooperative', 'undissolved', 'stubbornness', 'dissing', 'malaise', 'stark', 'distortion', 'haunt', 'depressed', 'ached', 'drunk', 'bullying', 'debacle', 'farcical-yet-provocative', 'unsecure', 'mudslinger', 'incoherently', 'pig', 'attacks', 'lukewarm', 'sloww', 'dirt', 'ineloquent', 'horrendous', 'insurmountably', 'conspicuously', 'puzzling', 'scandalized', 'filthy', 'slump', 'dull', 'tepid', 'pestilent', 'mistrust', 'fathomless', 'aspersions', 'contrived', 'drowning', 'exterminate', 'disagreement', 'extortion', 'disavow', 'inconsolable', 'anti-white', 'overthrow', 'nonsense', 'pains', 'regret', 'resigned', 'morbidly', 'racy', 'complained', 'dastard', 'swagger', 'bad', 'prosecute', 'sneak', 'discourage', 'disdainful', 'immovable', 'inferior', 'pratfall', 'misconception', 'tiring', 'involuntarily', 'dungeons', 'confounded', 'deviate', 'imposers', 'nauseatingly', 'compulsion', 'enemies', 'irritant', 'subversively', 'groundless', 'feeblely', 'sting', 'fallacies', 'faint', 'unipolar', 'incapable', 'ruin', 'calumnies', 'screwed-up', 'peculiarly', 'taunts', 'unbelievably', 'blockhead', 'malcontented', 'hamper', 'cave', 'indigent', 'decadence', 'brute', 'enflame', 'orphan', 'argumentative', 'perversely', 'polarisation', 'regrettably', 'adulterate', 'strain', 'paralize', 'distraughtly', 'assault', 'fidget', 'deprecate', 'bombastic', 'feint', 'bewilderingly', 'chafe', 'loser', 'devoid', 'subversion', 'tumultuous', 'infamously', 'malice', 'niggles', 'unwillingness', 'fluster', 'gawk', 'obscenity', 'unproves', 'disturbed', 'knock', 'cheater', 'atrophy', 'encroach', 'domineer', 'dishearteningly', 'bland', 'ingratitude', 'unsavory', 'disinclination', 'drawbacks', 'spoiled', 'unsettlingly', 'inequalities', 'radicals', 'distressingly', 'worried', 'fears', 'ghetto', 'lost', 'spoonfed', 'stealing', 'disliking', 'catastrophic', 'temptation', 'disgraced', 'virulent', 'dumping', 'undercutting', 'defamatory', 'refuted', 'difficulties', 'dizzing', 'unsteadily', 'calamity', 'bewildered', 'imprecisely', 'indelicate', 'asinininity', 'laggy', 'appal', 'hell-bent', 'anti-semites', 'bruised', 'imperil', 'neglected', 'pales', 'abolish', 'diabolic', 'hazardous', 'bewitch', 'back-wood', 'smugly', 'snob', 'sloppily', 'unrest', 'vagrant', 'accuses', 'unimportant', 'calumnious', 'fabrication', 'goading', 'indiscreet', 'dissension', 'farce', 'irately', 'slanderously', 'distrustful', 'squash', 'coward', 'lousy', 'jeopardize', 'dissonantly', 'god-awful', 'impeach', 'get-rich', 'unauthentic', 'downturn', 'foolishly', 'frost', 'impatient', 'ironic', 'audaciously', 'bullshit', 'emergency', 'lack', 'rejection', 'rhetoric', 'oddly', 'importunate', 'judder', 'ruined', 'baffling', 'wrinkled', 'lonesome', 'breakup', 'bemoaning', 'hectic', 'hawkish', 'crashing', 'impatiently', 'eyesore', 'hypocritical', 'limitations', 'insolent', 'hateful', 'bumped', 'extraneous', 'oddity', 'rigidity', 'unachievable', 'chill', 'blockage', 'declining', 'abrade', 'dissappointed', 'farfetched', 'impious', 'intractable', 'screwy', 'shatter', 'hideously', 'maledict', 'miserableness', 'derisiveness', 'inhibition', 'wreaked', 'weaker', 'belated', 'long-time', 'caustically', 'inflammed', 'objections', 'peeved', 'emptiness', 'coerce', 'time-consuming', 'unhelpful', 'stiflingly', 'virulence', 'incendiary', 'saggy', 'slowly', 'stagnation', 'lapses', 'contrariness', 'pugnacity', 'jarring', 'turbulent', 'impede', 'peevishly', 'terror', 'ungrateful', 'inimical', 'distastefully', 'scolding', 'obsessiveness', 'inaccuracy', 'absurdness', 'indignant', 'forlorn', 'disparaging', 'irrationalities', 'dump', 'kills', 'harms', 'emphatic', 'odd', 'overbearing', 'improperly', 'castrated', 'predatory', 'regretted', 'destains', 'bulky', 'disquieting', 'crappy', 'falling', 'implausibly', 'poky', 'ramshackle', 'self-coup', 'profane', 'chastisement', 'dissidence', 'perilous', 'pitilessly', 'wobbled', 'evil', 'insanity', 'superficial', 'tyrannically', 'superstition', 'fissures', 'irregular', 'shocking', 'hardship', 'humiliate', 'crabby', 'scourge', 'bloodthirsty', 'inexperience', 'unreliability', 'erratic', 'killer', 'unrelentingly', 'taunting', 'blurs', 'crippled', 'cynical', 'disgusting', 'hegemonism', 'mocks', 'succumb', 'senile', 'distract', 'backaching', 'morbid', 'ill-designed', 'embarrassing', 'mangled', 'crap', 'fatalistically', 'irrelevant', 'blindside', 'disgust', 'vulgar', 'accusations', 'drawback', 'cataclysmal', 'gutless', 'bloated', 'ignore', 'itchy', 'scowl', 'engulf', 'nastiness', 'poorly', 'goofy', 'brutish', 'failures', 'demonize', 'humiliating', 'convoluted', 'extremist', 'insurrection', 'knotted', 'oversize', 'reproach', 'repulsiveness', 'bores', 'disordered', 'shortsighted', 'tragically', 'defiantly', 'irretating', 'skeptically', 'squabble', 'hogs', 'bellicose', 'lurking', 'dissatisfy', 'bashing', 'huckster', 'terribly', 'sermonize', 'dud', 'improbable', 'mudslinging', 'manipulators', 'absurdity', 'misjudgment', 'ugh', 'overrun', 'struck', 'gloom', 'undetermined', 'mystery', 'darkened', 'delays', 'rampant', 'bulkiness', 'selfish', 'boisterous', 'jealousy', 'fastuous', 'disrespectful', 'foulness', 'jeopardy', 'sickly', 'acrimonious', 'downsides', 'reproachful', 'retreat', 'ineptitude', 'matte', 'tentatively', 'irritated', 'misrepresentation', 'maniacal', 'obstinately', 'unappealing', 'sticky', 'hobble', 'bothering', 'madden', 'embarrassment', 'forlornly', 'ambush', 'condemnable', 'sarcasm', 'hypocricy', 'furor', 'deficiency', 'grossly', 'nauseate', 'overturn', 'tedious', 'acrid', 'achey', 'blur', 'entrapment', 'ugly', 'depressions', 'painful', 'bereave', 'debilitating', 'expensive', 'irrelevance', 'polluters', 'commotions', 'corrupts', 'ill-treated', 'impropriety', 'damper', 'archaic', 'lovelorn', 'traumatically', 'wallow', 'contradiction', 'rage', 'struggling', 'listless', 'tentative', 'dizzingly', 'scars', 'hinder', 'dissembler', 'exaggeration', 'sluggish', 'usurper', 'whine', 'disillusioned', 'unprofitable', 'heartless', 'aggressor', 'breach', 'terrible', 'deceitful', 'disconsolation', 'erase', 'horrifys', 'meager', 'brimstone', 'delay', 'gabble', 'protested', 'depress', 'resentment', 'distasteful', 'dwindling', 'pettifog', 'retarded', 'opinionated', 'ravage', 'nosey', 'aggression', 'explosive', 'incessant', 'slanders', 'iniquitous', 'tediously', 'wilt', 'flaunt', 'disdained', 'lagging', 'frustration', 'dirtbag', 'loveless', 'life-threatening', 'smug', 'impossibly', 'inappropriately', 'scrap', 'wripped', 'fumes', 'self-defeating', 'treasonous', 'fastidious', 'misguide', 'indecisively', 'sued', 'aghast', 'plague', 'ostracize', 'mania', 'puny', 'challenging', 'toll', 'blundering', 'embarrassingly', 'malevolent', 'admonish', 'insolently', 'noise', 'traped', 'battered', 'endanger', 'loose', 'gimmicking', 'heavy-handed', 'hard-liner', 'devastatingly', 'antagonist', 'detestably', 'incite', 'inveigle', 'jabber', 'indulge', 'low-rated', 'admonisher', 'frenetically', 'confounding', 'enervate', 'idiot', 'oppositions', 'confrontation', 'catastrophies', 'radicalization', 'fragmented', 'squeals', 'thorny', 'blurring', 'irreversible', 'heartbreaker', 'languor', 'mist', 'rebuke', 'bleak', 'deviously', 'distressing', 'cunts', 'blackmail', 'foully', 'mawkishly', 'bondage', 'losing', 'merciless', 'contamination', 'allergies', 'demon', 'short-lived', 'stuttering', 'fiasco', 'tragic', 'passive', 'fretful', 'ghastly', 'gall', 'denying', 'vilify', 'chore', 'hedonistic', 'less-developed', 'spookiest', 'inconsequential', 'fooled', 'persecute', 'bewail', 'dumbfound', 'fallaciously', 'frown', 'damaging', 'loner', 'rotten', 'ruffle', 'hapless', 'shiver', 'pretence', 'intoxicate', 'failure', 'painfull', 'streaky', 'sensationalize', 'disgraceful', 'presumptuously', 'whiny', 'stereotypically', 'unskilled', 'chintzy', 'vociferously', 'unwillingly', 'disconcert', 'torrent', 'facetiously', 'messing', 'carelessness', 'dangerous', 'rancor', 'byzantine', 'uneasiness', 'egotism', 'unsupportive', 'floundering', 'hasty', 'overdue', 'propaganda', 'loathsome', 'sloow', 'uncollectible', 'insult', 'crack', 'unclear', 'dislikes', 'cheesy', 'squeaky', 'mocked', 'felonious', 'bumpy', 'longingly', 'timidly', 'deplorably', 'dick', 'inconsistence', 'banishment', 'cramping', 'disapointing', 'subjection', 'inglorious', 'recalcitrant', 'sap', 'dogged', 'viciously', 'unforgiving', 'pitiful', 'slower', 'obscenely', 'clumsy', 'petrify', 'horrible', 'propagandize', 'stagnant', 'terrorism', 'break-up', 'ill-usage', 'blistering', 'deceivers', 'fleeing', 'allegation', 'giddy', 'hysterically', 'outrages', 'ferocity', 'recourses', 'ruthless', 'slowed', 'sucky', 'melodramatically', 'pale', 'predicament', 'unwatchable', 'weirdly', 'baseless', 'puzzled', 'mockeries', 'blasphemous', 'oversimplification', 'impermissible', 'flicker', 'disclaim', 'unlucky', 'hater', 'biases', 'despise', 'impasse', 'meddle', 'doubtful', 'stigmatize', 'sidetracked', 'degradation', 'crowded', 'cynicism', 'brainwash', 'fatally', 'ruining', 'acrimoniously', 'addicted', 'fallout', 'insincerely', 'motionless', 'complaint', 'crushing', 'concede', 'lethal', 'subtract', 'unnerve', 'resurgent', 'ho-hum', 'injustices', 'ill-used', 'disapproving', 'slowwww', 'subservient', 'extermination', 'onslaught', 'idle', 'dumb', 'inescapably', 'deceitfulness', 'desecrate', 'clueless', 'strangely', 'hubris', 'quitter', 'breaking', 'dreary', 'discredit', 'nonresponsive', 'tetchy', 'humming', 'vomited', 'dissocial', 'inarticulate', 'implicate', 'clogs', 'election-rigger', 'unfairly', 'self-serving', 'snare', 'overreach', 'chaotic', 'imperfections', 'lewdly', 'overwhelmingly', 'slander', 'destitution', 'dismissively', 'muddle', 'smoldering', 'diametrically', 'restlessness', 'trample', 'inexpiable', 'slow-moving', 'doomsday', 'finagle', 'flaw', 'infection', 'falls', 'flat-out', 'infidels', 'incognizant', 'fictitious', 'sass', 'asperse', 'unspecified', 'cold', 'toughness', 'weak', 'fraudulent', 'nag', 'venomously', 'destructive', 'repugn', 'desperation', 'haphazard', 'gossip', 'barbarity', 'corruptted', 'entanglement', 'nefariously', 'disprove', 'selfishly', 'disinterest', 'worries', 'acerbically', 'scorchingly', 'disappointing', 'payback', 'shabby', 'baffled', 'inextricably', 'stupidly', 'anguish', 'freaking', 'panic', 'scar', 'shrilly', 'alarming', 'burns', 'intolerablely', 'revile', 'retards', 'dread', 'water-down', 'invisible', 'deluded', 'pretend', 'insatiable', 'downheartedly', 'terribleness', 'jeer', 'vomits', 'accusing', 'contend', 'disreputable', 'gnawing', 'wreaks', 'distorts', 'nightmarishly', 'protesting', 'faze', 'rusts', 'spotty', 'unsafe', 'superficially', 'devastates', 'plagiarize', 'savages', 'injury', 'crashed', 'aggrivation', 'puppet', 'blunder', 'lacked', 'spitefulness', 'remorselessness', 'fruitless', 'indolent', 'disbelieve', 'hypocritically', 'ineffectually', 'feign', 'satirical', 'head-aches', 'unseemly', 'impoverish', 'startling', 'wrongful', 'disoobedient', 'grievously', 'infected', 'madly', 'exagerate', 'static', 'helpless', 'mournfully', 'complex', 'blister', 'picket', 'susceptible', 'vengeful', 'hatefulness', 'starve', 'scarcely', 'hating', 'funnily', 'inhospitality', 'beware', 'mystify', 'sick', 'insignificance', 'despotic', 'woe', 'tortured', 'ineffective', 'mess', 'bloody', 'unsuspecting', 'drunkard', 'repulsing', 'timidity', 'sour', 'retreated', 'discontentedly', 'toxic', 'unprove', 'unscrupulous', 'bitingly', 'prevaricate', 'frenzied', 'snappish', 'backwardness', 'detested', 'ultimatums', 'bereft', 'crazy', 'diss', 'blaspheme', 'disfavor', 'infested', 'cruelest', 'invader', 'obstinate', 'epidemic', 'deprived', 'ridiculous', 'rantingly', 'untenable', 'stagnate', 'tangle', 'confrontational', 'junkyard', 'ironical', 'seething', 'plight', 'discontinuity', 'skeptic', 'writhe', 'sag', 'dissuade', 'unwanted', 'aggrieved', 'dusty', 'flirty', 'distraughtness', 'covetous', 'hassles', 'woeful', 'inhuman', 'madder', 'spilling', 'shipwreck', 'mock', 'acerbate', 'unknown', 'mordantly', 'improper', 'foolhardy', 'problematic', 'unfounded', 'glum', 'pervert', 'flair', 'bribery', 'illegally', 'rash', 'moody', 'offensively', 'crisis', 'defunct', 'haughtily', 'untruthful', 'earsplitting', 'moot', 'ambivalent', 'grimace', 'miserly', 'frail', 'hung', 'thoughtlessly', 'condemnation', 'misalign', 'lackeys', 'cheerless', 'dreadfulness', 'incompetently', 'disapproval', 'intimidatingly', 'rival', 'arrogant', 'shrivel', 'steal', 'regressive', 'wrongly', 'perplexity', 'bored', 'monstrous', 'anemic', 'slogging', 'betraying', 'danger', 'irked', 'rebellious', 'nettle', 'chagrin', 'drips', 'fanatical', 'pry', 'scared', 'impudent', 'instigator', 'abysmally', 'nasty', 'hoodium', 'repulsed', 'faltered', 'shamelessly', 'pretense', 'disbeliever', 'hastily', 'incessantly', 'intolerance', 'unthinkable', 'heavyhearted', 'unnerved', 'wrest', 'annoyances', 'cussed', 'slogs', 'lier', 'misgiving', 'betrayer', 'turmoil', 'mistake', 'disquietingly', 'lowly', 'abrasive', 'monotonous', 'unlawful', 'banalize', 'intrusion', 'remorseless', 'indecently', 'smells', 'uninsured', 'insufficient', 'neglect', 'ineptly', 'death', 'redundancy', 'jeering', 'shun', 'smudging', 'crafty', 'smack', 'shrill', 'misreading', 'awfulness', 'irrecoverableness', 'awful', 'delusions', 'goon', 'sneakily', 'picketed', 'galls', 'ill-mannered', 'rumple', 'wicked', 'invalid', 'indeterminable', 'incorrigible', 'swipe', 'soreness', 'bumping', 'tumbles', 'incautious', 'licentious', 'backbiting', 'horrify', 'pleas', 'loathe', 'defiant', 'despondent', 'touts', 'interruptions', 'warped', 'disintegration', 'invasive', 'inessential', 'radically', 'reject', 'controversy', 'snobs', 'defamation', 'inappropriate', 'bothers', 'checkered', 'indignity', 'casualty', 'disintegrates', 'underlings', 'unsteadiness', 'lewdness', 'die', 'unnaturally', 'scratchy', 'decrepitude', 'farcical', 'dejectedly', 'oppression', 'back-logged', 'screw-up', 'overdone', 'discomfititure', 'leer', 'deform', 'corrosions', 'deterioration', 'fastidiously', 'drastically', 'harmed', 'ill-sorted', 'excruciating', 'lunatic', 'negligence', 'oddities', 'slashing', 'unacceptably', 'spoilages', 'waning', 'lose', 'rant', 'sue', 'encroachment', 'refutation', 'unstable', 'oppose', 'worthlessness', 'panicking', 'unusually', 'mischievously', 'rejecting', 'uncontrolled', 'inaccuracies', 'detriment', 'bleakly', 'insufficiency', 'unproductive', 'decadent', 'unhappiness', 'afflict', 'bs', 'dishonesty', 'assult', 'bizarre', 'brusque', 'freezing', 'menial', 'ax', 'overwhelmed', 'polluter', 'suffered', 'unjustifiably', 'unsettle', 'bedlamite', 'wrought', 'dodgey', 'bristle', 'throbs', 'babble', 'overstates', 'uncomfortable', 'raging', 'jumpy', 'erodes', 'overzealous', 'accost', 'tiringly', 'erosion', 'notorious', 'debts', 'asunder', 'disrupt', 'implode', 'inopportune', 'conceit', 'gripes', 'precipitous', 'upseting', 'wrestle', 'brutally', 'disagree', 'drained', 'stodgy', 'deceptively', 'faithless', 'upsetting', 'blurred', 'solemn', 'hysterical', 'overpower', 'slanderous', 'unfortunate', 'effigy', 'shimmy', 'unwieldy', 'frazzle', 'mischief', 'testy', 'felon', 'stumped', 'incompliant', 'semi-retarded', 'chatterbox', 'pimple', 'scoffingly', 'confront', 'strife', 'debt', 'facetious', 'stubbornly', 'harmful', 'sufferers', 'ranting', 'hustler', 'derogatory', 'bull----', 'unusable', 'delusional', 'downside', 'harshly', 'stern', 'divisive', 'inhospitable', 'apprehensions', 'limits', 'snagging', 'fetid', 'divergent', 'inordinately', 'repudiate', 'interference', 'despot', 'disservice', 'deformed', 'paradoxically', 'disgruntle', 'geezer', 'invalidity', 'leaks', 'drop-out', 'disinclined', 'soapy', 'cheap', 'overbalanced', 'hoodwink', 'incredulous', 'infiltrators', 'tease', 'agony', 'rip', 'screech', 'timidness', 'flabbergast', 'haggle', 'phony', 'fever', 'mistakenly', 'polution', 'impractical', 'immoral', 'offending', 'lies', 'sinisterly', 'bruises', 'forgetful', 'cronyism', 'stinks', 'grievance', 'plasticky', 'repugnant', 'shriek', 'repressive', 'paucity', 'distracting', 'blatantly', 'sinfully', 'unfriendly', 'weaknesses', 'bemoan', 'rusty', 'kooky', 'panicky', 'irredeemably', 'ill-natured', 'bull****', 'miser', 'losses', 'killing', 'condescension', 'overblown', 'sceptical', 'dumped', 'cripple', 'wripping', 'set-up', 'terrorize', 'embroil', 'sack', 'illogically', 'illegal', 'narrower', 'steep', 'travesty', 'arrogantly', 'oddest', 'aggressiveness', 'inconstant', 'sore', 'exhaustion', 'dictator', 'headache', 'risks', 'disobey', 'left-leaning', 'overwhelm', 'pollute', 'villianously', 'doom', 'freakishly', 'gangster', 'inexcusably', 'invidiousness', 'tiresome', 'fleer', 'unintelligible', 'hurted', 'aimless', 'rejects', 'involuntary', 'silly', 'stalemate', 'sunken', 'troublemaker', 'avarice', 'indifference', 'falsely', 'stiff', 'longing', 'fusty', 'illusions', 'undermines', 'gruesome', 'mire', 'conflicted', 'dizzy', 'bulkyness', 'absentee', 'loss', 'unnatural', 'vomiting', 'incompatability', 'conceded', 'lure', 'refuting', 'spews', 'heartbreakingly', 'seedy', 'fiend', 'cruel', 'injustice', 'darken', 'reprovingly', 'thug', 'unprepared', 'demoralize', 'rot', 'frustrations', 'headaches', 'creak', 'incomparably', 'shirker', 'object', 'zaps', 'regretfully', 'pandemonium', 'fierce', 'grieving', 'horde', 'preposterous', 'harass', 'infraction', 'craps', 'sugarcoated', 'touchy', 'transgression', 'frantic', 'ingrate', 'lecherous', 'idiotically', 'crummy', 'mawkishness', 'warned', 'insubstantially', 'disputed', 'sags', 'precariously', 'sedentary', 'balk', 'incorrectly', 'scream', 'treachery', 'fatuously', 'annihilate', 'objection', 'egocentric', 'fudge', 'monstrously', 'lying', 'twisted', 'enraging', 'lech', 'loath', 'inoperable', 'outrageous', 'sagging', 'dishonest', 'busybody', 'sham', 'untouched', 'volatility', 'miff', 'stench', 'conservative', 'inextricable', 'paralyzed', 'imbroglio', 'feebleminded', 'languid', 'horrid', 'defects', 'insupportably', 'grumpiest', 'latency', 'vehemently', 'satirize', 'revengefully', 'disregard', 'blunt', 'grumble', 'flagrant', 'symptom', 'paltry', 'unlikely', 'hypocrisy', 'hypocrites', 'exploit', 'isolated', 'loathing', 'secretive', 'shadowy', 'insolence', 'hypocrite', 'foolish', 'strut', 'contemptible', 'lackadaisical', 'arduously', 'fanaticism', 'scum', 'adulterier', 'choleric', 'disrespectfully', 'invidiously', 'overshadow', 'wrath', 'prattle', 'flareup', 'inefficient', 'disgustful', 'maddening', 'refusing', 'uncivilized', 'uncompetitive', 'mistakes', 'desertion', 'cringes', 'devilment', 'dings', 'impoverished', 'perilously', 'tanks', 'ineffectualness', 'nepotism', 'fault', 'invective', 'inadequately', 'travesties', 'snagged', 'snarl', 'subordinate', 'cannibal', 'riled', 'glib', 'siege', 'lie', 'disturbingly', 'foe', 'bum', 'cocky', 'blame', 'burden', 'cruelties', 'contaminates', 'doggedly', 'defiance', 'inconsiderate', 'multi-polarization', 'provocation', 'venomous', 'disrespectable', 'douchebags', 'worrier', 'cons', 'submissive', 'disobedience', 'denunciation', 'obstructing', 'stupidest', 'indefensible', 'coarse', 'incongruously', 'irony', 'appallingly', 'unnecessary', 'ignominiously', 'corrupted', 'deteriorating', 'dirty', 'hollow', 'irate', 'infernal', 'madman', 'desperately', 'bitterly', 'f**k', 'declaim', 'bonkers', 'nauseating', 'monotony', 'boredom', 'fatuity', 'stunt', 'penalty', 'imprecise', 'meltdown', 'crooked', 'disruption', 'fear', 'somber', 'embarrass', 'lag', 'misinformed', 'dangerousness', 'dissatisfies', 'swollen', 'troubling', 'uncaring', 'beastly', 'exasperate', 'occludes', 'suffers', 'swelled', 'sorrowfully', 'glitches', 'menace', 'weakening', 'unfavorable', 'degeneration', 'concerns', 'jaundiced', 'limited', 'inflammation', 'blah', 'rupture', 'smolder', 'discourteous', 'lanky', 'lazy', 'mourn', 'grim', 'superficiality', 'obnoxious', 'instigate', 'leech', 'evildoer', 'smuttiest', 'inequitably', 'smouldering', 'bluring', 'intefere', 'doldrums', 'cannibalize', 'irregularity', 'vengefully', 'stupify', 'fleed', 'fraud', 'innuendo', 'annoyance', 'flees', 'humiliation', 'devil', 'jeers', 'second-class', 'hopelessness', 'deplete', 'annoy', 'pauper', 'tension', 'adulterated', 'mismanage', 'nuisance', 'remorsefully', 'flareups', 'belligerence', 'spoils', 'inexpert', 'impolitely', 'plunder', 'cripples', 'extinguish', 'imbecile', 'retaliate', 'stuck', 'weed', 'indiscriminating', 'battering', 'panders', 'lawless', 'disillusions', 'bastards', 'boggle', 'dying', 'sadly', 'disturbance', 'traitorous', 'scandalously', 'useless', 'daunting', 'sly', 'expunge', 'unsure', 'shortsightedness', 'lagged', 'missed', 'resent', 'agonizingly', 'quibbles', 'calumniate', 'cruelness', 'ineffectively', 'misbehavior', 'repress', 'desititute', 'egomania', 'erode', 'bias', 'unexplained', 'acerbic', 'disturb', 'autocrat', 'enviously', 'inordinate', 'rumbling', 'simplistically', 'implication', 'devastated', 'violators', 'fanciful', 'dissent', 'misinterpret', 'harpy', 'skepticism', 'insulted', 'inexpertly', 'discontinuous', 'incorrect', 'untrustworthy', 'clogged', 'downfallen', 'chide', 'ache', 'hostage', 'upheaval', 'imprecision', 'repression', 'cringed', 'assail', 'squealing', 'abscond', 'embroilment', 'extremism', 'unreasonable', 'mislead', 'ricer', 'inadverent', 'genocide', 'fumble', 'grievances', 'comical', 'obscurity', 'repulsively', 'seriousness', 'beg', 'dissatisfied', 'midget', 'shortcoming', 'sufferer', 'erratically', 'mendacity', 'accuse', 'inconsistency', 'sickness', 'inadvisable', 'noxious', 'infringements', 'gawky', 'hardhearted', 'haze', 'carnage', 'irreconcilable', 'decrepit', 'obscured', 'mawkish', 'forged', 'extort', 'servitude', 'fearsome', 'criminal', 'jutter', 'mediocrity', 'deterrent', 'unlawfully', 'crude', 'horrendously', 'revengeful', 'irritate', 'stranger', 'misbecome', 'penalize', 'struggled', 'desolate', 'distress', 'hard', 'rut', 'inefficacious', 'domineering', 'bloodshed', 'recant', 'disloyalty', 'wariness', 'frigging', 'freaks', 'infuriating', 'uproar', 'evils', 'negatives', 'confessions', 'floored', 'overstatements', 'scolded', 'inconsequent', 'infest', 'drags', 'renounce', 'gimmicked', 'maliciousness', 'second-tier', 'dire', 'subdued', 'rumor', 'anxious', 'zealously', 'inaction', 'recklessly', 'importune', 'smokescreen', 'unavoidably', 'crumple', 'vagueness', 'disgracefully', 'indoctrination', 'illogic', 'prohibitive', 'declines', 'atrocity', 'excuse', 'qualm', 'worse', 'envious', 'garish', 'junk', 'arbitrary', 'complication', 'puzzlement', 'undefined', 'indecisive', 'ruins', 'delinquent', 'glut', 'intransigence', 'skittishly', 'anarchist', 'pernicious', 'gracelessly', 'haughty', 'underpowered', 'tangles', 'dawdle', 'haggard', 'careless', 'heinous', 'nettlesome', 'dejection', 'stuttered', 'sucker', 'screwed', 'condemn', 'malevolently', 'mischievous', 'unnoticed', 'dispirited', 'worst', 'annoyed', 'disown', 'smoulder', 'washed-out', 'smear', 'anxieties', 'depressing', 'heckles', 'chronic', 'fractious', 'faulty', 'infuriatingly', 'slanderer', 'nastily', 'unhealthy', 'displace', 'bump', 'teasingly', 'taunt', 'defame', 'flickers', 'complicated', 'gauche', 'nervousness', 'rattle', 'outbreak', 'fanatic', 'meddlesome', 'anti-social', 'fury', 'unproving', 'ill-favored', 'aweful', 'mistress', 'insubordinate', 'infuriated', 'partisan', 'forswear', 'shrew', 'hatred', 'stifle', 'woebegone', 'conscons', 'interferes', 'oversimplify', 'petty', 'rascals', 'bash', 'awkwardness', 'brittle', 'misinform', 'dark', 'debasement', 'inconvenience', 'ruts', 'audacity', 'doubt', 'skimpy', 'treason', 'vexingly', 'bumps', 'isolate', 'bane', 'grudgingly', 'jam', 'unintelligile', 'simplistic', 'disorder', 'joker', 'adulteration', 'extravagant', 'reprimand', 'inequities', 'subservience', 'tardy', 'unfaithful', 'combust', 'wickedness', 'obtuse', 'scathing', 'overpaid', 'incomprehensible', 'absent-minded', 'contempt', 'helplessness', 'pique', 'illusory', 'deficiencies', 'forfeit', 'frazzled', 'leaking', 'oppress', 'friction', 'fawningly', 'oversight', 'impure', 'vomit', 'glibly', 'misleadingly', 'misses', 'vestiges', 'conspire', 'disaffected', 'alienated', 'runaway', 'vague', 'sidetrack', 'hampered', 'burning', 'anarchy', 'disparage', 'vileness', 'contemptuous', 'ruffian', 'throbbed', 'din', 'drought', 'invidious', 'collude', 'evasive', 'darkness', 'disappointed', 'exagerated', 'forceful', 'graft', 'ignoble', 'perish', 'brutality', 'dismissive', 'despoiler', 'damaged', 'guilt', 'slowest', 'boiling', 'unorthodoxy', 'hestitant', 'furiously', 'spookier', 'mispronounces', 'alarmingly', 'calumny', 'despairingly', 'overlook', 'fainthearted', 'vexation', 'truant', 'whips', 'dent', 'inhumanity', 'sorry', 'troubled', 'deploring', 'lonely', 'butcher', 'brutal', 'prejudice', 'imperious', 'uproot', 'incompetent', 'militancy', 'stridently', 'disadvantages', 'punishable', 'uneven', 'corrosive', 'showdown', 'obscene', 'burn', 'fume', 'calamities', 'dispiriting', 'victimize', 'scoff', 'quandary', 'capitulate', 'thwart', 'complicit', 'fatefully', 'urgent', 'impersonal', 'unobserved', 'denounce', 'reluctance', 'fascist', 'lapse', 'condescendingly', 'misfortune', 'rift', 'immodest', 'meaningless', 'shark', 'stereotypical', 'unwelcome', 'primitive', 'foul', 'hefty', 'aversion', 'fatal', 'sad', 'debatable', 'inadvisably', 'afraid', 'steals', 'fateful', 'despicable', 'discontented', 'brazenly', 'unkind', 'egotistically', 'tainted', 'violation', 'ineffectual', 'killed', 'hellion', 'destroyer', 'wretched', 'tarnish', 'draconian', 'despairing', 'drippy', 'prideful', 'reluctant', 'tetchily', 'forsaken', 'harm', 'spade', 'pessimism', 'angrily', 'suffocate', 'condescend', 'unuseable', 'apocalyptic', 'waste', 'overbearingly', 'displeasure', 'mediocre', 'muddy', 'disgustedly', 'puppets', 'concessions', 'demolisher', 'gimmicks', '2-faced', 'notoriety', 'dissolution', 'breaks', 'anti-proliferation', 'hurt', 'agonies', 'difficult', 'fanatics', 'adamant', 'glitch', 'fool', 'malodorous', 'greasy', 'resentful', 'diappointed', 'overweight', 'betrayals', 'regression', 'reprehensibly', 'war-like', 'isolation', 'childish', 'scrambles', 'disloyal', 'halfhearted', 'stereotype', 'parody', 'disliked', 'undermined', 'break-ups', 'aground', 'fruitlessly', 'languorously', 'exile', 'stooge', 'fickle', 'scarred', 'untimely', 'adverse', 'delirium', 'tricked', 'defy', 'baffle', 'harassment', 'inflammatory', 'prik', 'dissenter', 'immature', 'complaints', 'desperate', 'exhort', 'roadblocks', 'disappointment', 'grudges', 'hazard', 'breakdown', 'bogus', 'inelegant', 'abomination', 'opponent', 'sketchy', 'tarnishes', 'thrash', 'affront', 'mortified', 'deploringly', 'litigious', 'marginal', 'allergy', 'myth', 'allergic', 'frozen', 'betrayal', 'racist', 'disaster', 'browbeat', 'quarrelsome', 'mushy', 'inaccurate', 'rail', 'bedlam', 'expire', 'stringently', 'bemused', 'scorn', 'jealousness', 'spoilled', 'inattentive', 'inaptitude', 'hum', 'discoutinous', 'downhearted', 'shrug', 'slap', 'amputate', 'brazenness', 'freeze', 'sulk', 'thirst', 'twists', 'stringent', 'unwell', 'capricious', 'fatique', 'wreck', 'adversarial', 'decry', 'strangest', 'wimpy', 'demoralizing', 'top-heavy', 'agonize', 'needless', 'hothead', 'imprison', 'craftly', 'lambast', 'stink', 'disagreeable', 'gibber', 'pinch', 'subversive', 'terror-genic', 'dents', 'raping', 'nervous', 'glare', 'intolerable', 'trauma', 'lame-duck', 'shocked', 'betray', 'deplorable', 'ill-fated', 'sillily', 'exagerates', 'spendy', 'inefficiently', 'prickles', 'snarky', 'pretentious', 'deadly', 'dictatorial', 'scoldingly', 'tamper', 'relentless', 'clique', 'sneeringly', 'inconceivably', 'confuse', 'mistrustfully', 'noises', 'desiccated', 'sorrowful', 'retract', 'imperfection', 'culprit', 'despondence', 'miscalculate', 'pertinacity', 'dissatisfaction', 'egotistical', 'cutthroat', 'fascism', 'dismayed', 'limit', 'unresponsive', 'misdirection', 'pricier', 'capriciousness', 'freakish', 'fatalistic', 'suppression', 'presumptuous', 'mockingly', 'inept', 'pricey', 'gross', 'risky', 'lamentable', 'prejudices', 'flicering', 'impugn', 'audacious', 'cancer', 'bomb', 'insecure', 'misread', 'doomed', 'guile', 'bigotries', 'scratched', 'inaccurately', 'warp', 'irresolvable', 'appall', 'underestimate', 'seethe', 'outrageously', 'hassle', 'cruelly', 'discomfit', 'disaccord', 'distrust', 'deter', 'crazily', 'livid', 'worthless', 'skinny', 'ruinous', 'escapade', 'disarm', 'belittle', 'sueing', 'commotion', 'corruption', 'upset', 'damnation', 'mirage', 'critics', 'wild', 'decline', 'revenge', 'scramble', 'punk', 'scarcity', 'incomplete', 'obstructed', 'stumble', 'chunky', 'yawn', 'solicitude', 'villify', 'revolt', 'restless', 'scold', 'lechery', 'skeptical', 'bug', 'remorseful', 'commiserate', 'overrated', 'notoriously', 'cringe', 'sues', 'annoyingly', 'diffidence', 'full-blown', 'restrictive', 'frustrating', 'rue', 'asinine', 'oblique', 'patronize', 'fatty', 'fall', 'lurch', 'overact', 'illness', 'protest', 'ultra-hardline', 'regreted', 'leakage', 'hedge', 'admonition', 'belittling', 'injure', 'egregious', 'peeve', 'apathetically', 'criticized', 'anti-', 'mortification', 'refuse', 'insurmountable', 'imperfectly', 'jerk', 'messed', 'slaughter', 'warning', 'ominous', 'unresolved', 'belabor', 'appalling', 'leaky', 'lifeless', 'overpriced', 'whining', 'worry', 'confused', 'licentiousness', 'heretic', 'die-hard', 'forgetfulness', 'occluded', 'sorely', 'disorient', 'bumpping', 'perfunctory', 'interrupt', 'vociferous', 'idiocy', 'self-destructive', 'undocumented', 'perplexing', 'darker', 'throbbing', 'strike', 'overwhelms', 'forebodingly', 'subjugate', 'degrade', 'impotent', 'dogmatic', 'outrage', 'risk', 'bashed', 'wretchedness', 'shemale', 'pretentiously', 'quarrellously', 'revert', 'inflationary', 'trashed', 'lawbreaker', 'accusingly', 'blurry', 'dismally', 'protests', 'tin-y', 'maniac', 'junky', 'desolately', 'bleakness', 'dented', 'antithetical', 'stun', 'cracks', 'suck', 'unfulfilled', 'gainsayer', 'perversity', 'chaff', 'emphatically', 'messy', 'vent', 'downcast', 'iniquity', 'misapprehend', 'nagging', 'onerously', 'mindless', 'intermittent', 'ill-advised', 'diabolically', 'misbecoming', 'collusion', 'acrimony', 'diatribes', 'indifferent', 'quarrels', 'trivial', 'wobbles', 'defiler', 'plaything', 'worthlessly', 'dubiously', 'idiocies', 'insincere', 'measly', 'mobster', 'corrupting', 'sporadic', 'savaged', 'ridicules', 'misbehave', 'incompetence', 'lumpy', 'dissuasive', 'deplore', 'over-priced', 'detracting', 'pugnacious', 'self-interested', 'buckle', 'unconvincingly', 'unlawfulness', 'cheaply', 'dinky', 'eccentric', 'sloppy', 'woefully', 'ineligible', 'heck', 'troublesome', 'grapple', 'pander', 'nebulously', 'plunderer', 'unviewable', 'hype', 'knife', 'corrode', 'wanton', 'subvert', 'blasted', 'disapprove', 'prate', 'disagrees', 'ferociously', 'hissed', 'boastful', 'lunaticism', 'refusal', 'taint', 'exhausts', 'transgress', 'weaken', 'temper', 'damage', 'lied', 'lackey', 'wasted', 'opportunistic', 'hesitant', 'unsustainable', 'infringe', 'repulse', 'weakness', 'one-sided', 'glower', 'stifling', 'leak', 'snobby', 'vanity', 'immobilized', 'discriminate', 'impending', 'contravene', 'flickering', 'negate', 'numb', 'defensive', 'bravado', 'dubious', 'nitpick', 'obscure', 'cackle', 'meanness', 'perturb', 'rattled', 'violent', 'ding', 'vexing', 'tyranny', 'exploitation', 'drab', 'congested', 'disruptive', 'vibrated', 'heartbreaking', 'beset', 'flabbergasted', 'unproven', 'undecided', 'deprive', 'scuffs', 'uneasily', 'struggles', 'elimination', 'hiliarious', 'acridly', 'impair', 'abruptly', 'intense', 'dishonorable', 'precipitate', 'splatter', 'dripping', 'demonic', 'shallow', 'anti-us', 'pest', 'flimsy', 'harsh', 'squeaks', 'spank', 'messes', 'break', 'catastrophes', 'contention', 'inability', 'accursed', 'askance', 'partisans', 'hacks', 'negativity', 'zombie', 'discrepant', 'non-confidence', 'unimaginably', 'curse', 'misunderstood', 'combative', 'devious', 'intimidation', 'petrified', 'miss', 'hate', 'mercilessly', 'frustrate', 'misfit', 'pain', 'traduce', 'wickedly', 'aggravation', 'rascal', 'breakups', 'thoughtless', 'vainly', 'unreliable', 'mysteriously', 'dead', 'uproarously', 'wrong', 'paranoid', 'traumatic', 'incommensurate', 'emaciated', 'lascivious', 'martyrdom-seeking', 'drains', 'complaining', 'sardonic', 'shoddy', 'intimidate', 'flakey', 'premeditated', 'strictly', 'undersized', 'reactionary', 'disputable', 'trickery', 'craftily', 'delaying', 'joke', 'unbearable', 'disabled', 'frigid', 'unreasonably', 'smutty', 'hegemony', 'unimaginable', 'grisly', 'uproarious', 'bungling', 'scarier', 'delayed', 'delinquency', 'rants', 'inconsistent', 'queer', 'setbacks', 'cravenly', 'disproportionate', 'tricky', 'unnerving', 'pedantic', 'devastation', 'incense', 'disquietude', 'problems', 'leakages', 'disconcertingly', 'miscalculation', 'fuzzy', 'destitute', 'shunned', 'squirm', 'vibrate', 'commonplace', 'enmity', 'devilish', 'harridan', 'hostility', 'lengthy', 'lame', 'inadequate', 'dispirit', 'divisiveness', 'gripe', 'poorest', 'wretchedly', 'misjudge', 'absence', 'snub', 'abusive', 'wary', 'crept', 'imminently', 'disconsolately', 'falsehood', 'quack', 'attack', 'injurious', 'antagonistic', 'grouch', 'smell', 'incomparable', 'pity', 'batty', 'contaminate', 'dissident', 'immoderately', 'hack', 'marginally', 'imprisonment', 'illusion', 'warlike', 'boil', 'disasterous', 'tumbled', 'detests', 'backbite', 'unsteady', 'discourteously', 'hindrance', 'fundamentalism', 'unworthy', 'occluding', 'powerless', 'uncivil', 'gasp', 'juddering', 'bearish', 'weird', 'pittance', 'ludicrous', 'beggarly', 'spoilage', 'trouble', 'obsolete', 'unrealistic', 'flout', 'clamorous', 'filth', 'uncouth', 'antipathy', 'obsess', 'ominously', 'catastrophe', 'inconsequentially', 'dishonorablely', 'cheated', 'disgruntled', 'incompatible', 'rivalry', 'deteriorate', 'deny', 'decrement', 'bullshyt', 'shambles', 'unworkable', 'over-hyped', 'grumpier', 'recessionary', 'criticize', 'flounder', 'heedless', 'fatuous', 'buggy', 'distorted', 'fuck', 'lament', 'ignorance', 'passe', 'tawdry', 'mistaken', 'volatile', 'stuffy', 'dislocated', 'horrifying', 'banal', 'upsets', 'languish', 'virus', 'procrastination', 'taxing', 'immorality', 'misstatement', 'hideousness', 'misuse', 'naughty', 'shock', 'strident', 'thoughtlessness', 'bewilderment', 'unreachable', 'insidious', 'imminence', 'infringement', 'jobless', 'detesting', 'stricken', 'wearisome', 'censure', 'abuse', 'vulnerable', 'indecision', 'insecurity', 'insinuation', 'frictions', 'aggrieve', 'starvation', 'tenuously', 'tarnished', 'virulently', 'massacres', 'infuriate', 'belittled', 'hard-hit', 'savagery', 'undermining', 'impatience', 'venom', 'belligerently', 'lawlessness', 'blameworthy', 'slaughtered', 'gape', 'confusion', 'dispensable', 'eviscerate', 'heresy', 'dim', 'murky', 'pugnaciously', 'overacted', 'despicably', 'indeterminably', 'callous', 'garbage', 'lackluster', 'ailing', 'unpredictable', 'criticizing', 'undependability', 'stress', 'inevitably', 'itch', 'stressful', 'incorrigibly', 'tacky', 'calamitously', 'extravagance', 'heckle', 'rip-off', 'overthrows', 'resignation', 'bugging', 'uproariously', 'inhibit', 'peril', 'irksome', 'unaccustomed', 'dissonance', 'ambiguity', 'deceptive', 'ranted', 'shit', 'irritating', 'blindingly', 'mindlessly', 'undone', 'kill', 'maladjusted', 'apprehensively', 'cataclysm', 'arduous', 'insensitive', 'sinister', 'irrepressible', 'onerous', 'revulsive', 'intransigent', 'impenitent', 'plea', 'absurdly', 'punish', 'hallucinate', 'erroneously', 'ashamed', 'strenuous', 'dishonestly', 'struggle', 'tyrant', 'indoctrinate', 'disappointingly', 'failing', 'wasting', 'jutters', 'limitation', 'sneering', 'stole', 'insociable', 'confession', 'displeased', 'dissed', 'inconsequently', 'obnoxiously', 'bent', 'demoralizingly', 'loneliness', 'hassled', 'coldly', 'failed', 'fake', 'funny', 'degenerately', 'dreadfully', 'aggressive', 'ill-tempered', 'brutalizing', 'jealous', 'heretical', 'misunderstandings', 'nefarious', 'pandering', 'suspicion', 'annihilation', 'hostile', 'discouragingly', 'irascible', 'unaffordable', 'unexpectedly', 'wildly', 'braggart', 'costly', 'fucking', 'violate', 'costlier', 'tantrum', 'droops', 'disrespecting', 'cry', 'insular', 'picky', 'sunder', 'troublingly', 'sacrificed', 'sarcastically', 'grudging', 'insubstantial', 'outburst', 'disadvantageous', 'fib', 'ambiguous', 'ill-defined', 'gaudy', 'lewd', 'obtrusive', 'pompous', 'fuss', 'sabotage', 'testily', 'dilapidated', 'burned', 'arcane', 'depression', 'heathen', 'intimidating', 'chaos', 'self-humiliation', 'despair', 'gloomy', 'decay', 'slog', 'delirious', 'obstacle', 'blab', 'scandalous', 'bowdlerize', 'inconsiderately', 'rabid', 'dehumanize', 'obsessive', 'reluctantly', 'imperiously', 'raked', 'drones', 'hysteric', 'backward', 'hegemonistic', 'refutes', 'incoherence', 'obliterated', 'disinterested', 'impulsively', 'racists', 'appalled', 'damning', 'lethargy', 'inevitable', 'shake', 'fat', 'cliche', 'fat-cats', 'invalidate', 'nave', 'irresponsible', 'quash', 'surrender', 'disintegrated', 'grief', 'disadvantaged', 'issues', 'straining', 'scrambling', 'scuff', 'unacceptable', 'anarchism', 'offend', 'flake', 'fracture', 'languorous', 'melodramatic', 'revulsion', 'unfinished', 'unwisely', 'collapse', 'mists', 'indiscriminately', 'brutalising', 'misaligns', 'hated', 'pervasive', 'harasses', 'imbalance', 'froze', 'laconic', 'stupified', 'decayed', 'adversity', 'choke', 'goad', 'outrageousness', 'enslave', 'deprave', 'debilitate', 'crass', 'dispute', 'needlessly', 'negation', 'unfeeling', 'fleeting', 'overheat', 'poisonously', 'refute', 'splitting', 'oversights', 'unkindly', 'blabber', 'contradict', 'prejudicial', 'sink', 'chastise', 'clash', 'falter', 'pathetic', 'daze', 'disrespect', 'direness', 'imposition', 'inundate', 'mishandle', 'pessimistic', 'recoil', 'stolen', 'touted', 'disconsolate', 'insouciance', 'conceited', 'vicious', 'smelling', 'gaff', 'horrific', 'omission', 'bragger', 'ironically', 'enjoin', 'bashful', 'lambaste', 'blatant', 'inexcusable', 'dissapointed', 'insufficiently', 'abnormal', 'misrepresent', 'harden', 'sardonically', 'split', 'bastard', 'disappoints', 'irredeemable', 'disastrous', 'discordance', 'murderous', 'desert', 'uncomfy', 'parasite', 'tramp', 'offenses', 'rile', 'deaf', 'insultingly', 'irking', 'obstruct', 'poverty', 'overstate', 'louder', 'incoherent', 'anomaly', 'insensitively', 'paranoia', 'denies', 'desultory', 'burdensomely', 'bait', 'dishearten', 'perverts', 'snags', 'outraged', 'disintegrate', 'inexorable', 'over-acted', 'dissonant', 'fist', 'horrified', 'inane', 'skeletons', 'drag', 'sucks', 'crushed', 'perverse', 'disorderly', 'conspiratorial', 'insensitivity', 'refused', 'hatefully', 'torment', 'conflicting', 'substandard', 'spookily', 'scoundrel', 'faults', 'passiveness', 'hangs', 'pout', 'pointless', 'bruise', 'disorganized', 'contaminated', 'tout', 'opposition', 'abysmal', 'falsify', 'unsuccessfully', 'fulminate', 'mislike', 'disagreed', 'vice', 'severe', 'wedge', 'irksomely', 'confined', 'indistinguishable', 'damnable', 'disillusion', 'dismal', 'mad', 'redundant', 'radical', 'incongruous', 'rejected', 'sputter', 'rust', 'discomfort', 'overstated', 'stressfully', 'fictional', 'calumniation', 'reticent', 'odder', 'threat', 'doubtfully', 'troublesomely', 'zapped', 'disconcerting', 'scandel', 'fiction', 'pointlessly', 'dunce', 'scarily', 'furious', 'debility', 'pitiable', 'unilateralism', 'unlamentably', 'hysteria', 'inconsistencies', 'cheapen', 'improbably', 'quibble', 'ulterior', 'bust', 'downbeat', 'shame', 'frets', 'detestable', 'neurotic', 'dripped', 'cumbersome', 'imposing', 'infections', 'fanatically', 'disrespectablity', 'unaccessible', 'conspicuous', 'precarious', 'mundane', 'evade', 'disagreeably', 'spoil', 'forgetfully', 'threaten', 'conflicts', 'bestial', 'interruption', 'disconcerted', 'explode', 'imprudent', 'confess', 'distains', 'slooow', 'critical', 'catastrophically', 'dehumanization', 'brat', 'fractiously', 'despoil', 'gibe', 'lividly', 'swindle', 'banish', 'flaky', 'gravely', 'overdo', 'bereavement', 'blasphemy', 'conspirator', 'frenzy', 'mangles', 'blunders', 'mourner', 'noisy', 'unethical', 'cruelty', 'stupidity', 'fallaciousness', 'apathy', 'inaudible', 'squeak', 'badly', 'blemish', 'perfidity', 'disturbing', 'alarm', 'anxiousness', 'negligent', 'misunderstanding', 'sharply', 'slaves', 'sinking', 'stooges', 'far-fetched', 'provoke', 'sleazy', 'moronic', 'grating', 'insinuate', 'sob', 'demonizes', 'instigators', 'naively', 'harassed', 'ploy', 'scandels', 'traumatized', 'ruthlessness', 'scummy', 'besmirch', 'sugar-coat', 'villains', 'angriness', 'overemphasize', 'abused', 'bitch', 'craven', 'rude', 'devilry', 'last-ditch', 'rumours', 'subjected', 'regrets', 'disappoint', 'scare', 'pan', 'sickening', 'angry', 'disillusionment', 'stump', 'deviousness', 'heckled', 'uneasy', 'abominable', 'ail', 'detracts', 'disable', 'frighteningly', 'irritably', 'pariah', 'fidgety', 'dejected', 'tenderness', 'sucked', 'interfere', 'dreadful', 'slave', 'beguile', 'discord', 'aloof', 'exhaust', 'incivility', 'instable', 'unfunded', 'gruesomely', 'rankle', 'demolish', 'disingenuously', 'bore', 'overwhelming', 'shady', 'brazen', 'mortify', 'uneventful', 'unhappily', 'worriedly', 'doubts', 'concens', 'melancholy', 'odor', 'overawe', 'sloooooooooooooow', 'burdensome', 'feeble', 'uglier', 'autocratic', 'rifts', 'clouding', 'disapointed', 'congestion', 'cramped', 'fret', 'drain', 'wheedle', 'objectionable', 'unwarranted', 'anxiously', 'unconfirmed', 'shameless', 'halfheartedly', 'disgustfully', 'cracked', 'busts', 'menacingly', 'brutalize', 'bulkier', 'disaffect', 'bully', 'flak', 'rocky', 'expel', 'sanctimonious', 'impudence', 'jolt', 'worsening', 'crook', 'wastefulness', 'discontent', 'improbability', 'fatigued', 'trivialize', 'flagging', 'sloooow', 'irrecoverably', 'worrisome', 'jaded', 'selfinterested', 'apathetic', 'steeply', 'insincerity', 'smuttier', 'sty', 'obscures', 'funky', 'cheat', 'detracted', 'ill-treatment', 'suspiciously', 'oblivious', 'tanked', 'oversimplified', 'wrinkle', 'finicky', 'unavailable', 'defrauding', 'unfaithfully', 'discriminatory', 'choppy', 'carp', 'indecency', 'distort', 'donside', 'deceitfully', 'whore', 'befoul', 'apologists', 'scant', 'coercion', 'reprehensible', 'swelling', 'martyrdom', 'racism', 'smut', 'tragedy', 'exacerbate', 'guilty', 'undid', 'dumps', 'berate', 'grotesque', 'idiots', 'regrettable', 'apprehensive', 'lawbreaking', 'rife', 'symptoms', 'trashy', 'forbid', 'unusual', 'nebulous', 'altercation', 'discombobulate', 'enviousness', 'grouse', 'poisonous', 'bicker', 'abyss', 'conspiracies', 'ludicrously', 'relentlessly', 'unsound', 'outmoded', 'kaput', 'tempest', 'beggar', 'clog', 'deject', 'grumpily', 'frustrates', 'hasseling', 'inefficacy', 'unneeded', 'indiscernible', 'inadequacy', 'excoriate', 'pigs', 'sickeningly', 'annoying', 'demise', 'persecution', 'sober', 'unyielding', 'zealot', 'bungler', 'devilishly', 'dupe', 'hostilities', 'damn', 'despised', 'blather', 'shirk', 'sorrow', 'shockingly', 'hardball', 'fat-cat', 'problem', 'ultimatum', 'disquiet', 'impulsive', 'downgrade', 'authoritarian', 'complains', 'hang', 'hurts', 'inteferes', 'dissemble', 'long-winded', 'blind', 'unravel', 'reprehensive', 'torturously', 'revoltingly', 'irksomeness', 'worn', 'abominate', 'assassinate', 'contentious', 'lecher', 'over-balanced', 'tangled', 'rough', 'maddeningly', 'distressed', 'castigate', 'uncompromisingly', 'unmoved', 'wrinkles', 'tumble', 'irrecoverable', 'punch', 'cursed', 'undignified', 'unscrupulously', 'criticism', 'jitters', 'mashed', 'scrambled', 'shaky', 'hurtful', 'coercive', 'suppress', 'unsophisticated', 'cataclysmic', 'tingled', 'laughably', 'discouraging', 'indignation', 'sarcastic', 'stunted', 'syndrome', 'unwilling', 'feckless', 'harrow', 'offensive', 'snag', 'embattled', 'lurid', 'mishap', 'demean', 'maliciously', 'wiles', 'exasperatingly', 'letch', 'derisively', 'draconic', 'reckless', 'antiquated', 'debaucher', 'bigotry', 'miscreant', 'backwood', 'relapse', 'dispiritedly', 'mysterious', 'warily', 'malady', 'stigma', 'disadvantage', 'procrastinate', 'direly', 'throb', 'flimflam', 'defect', 'cramp', 'sin', 'inelegance', 'unwise', 'freak', 'vehement', 'grudge', 'barbarically', 'insufferably', 'raving', 'debauchery', 'apologist', 'beleaguer', 'cranky', 'bothered', 'enfeeble', 'grumpish', 'selfishness', 'assassin', 'errant', 'loot', 'sugar-coated', 'crumbling', 'squander', 'bunk', 'recklessness', 'indiscretion', 'rogue', 'sever', 'startle', 'subpoena', 'smoke', 'cartoonish', 'downturns', 'loses', 'unemployed', 'crippling', 'aborts', 'futilely', 'mendacious', 'expropriation', 'threats', 'drop-outs', 'reprove', 'fabricate', 'peculiar', 'creaking', 'spoon-fed', 'illegitimate', 'dragoon', 'craze', 'excessive', 'monstrosity', 'harboring', 'outcast', 'imprecate', 'creepy', 'accusation', 'deviation', 'miseries', 'slug', 'degrading', 'stab', 'traitor', 'unattractive', 'dungeon', 'tormented', 'expropriate', 'alarmed', 'scathingly', 'divisively', 'ignominious', 'horrifies', 'deluge', 'expulse', 'irreparable', 'aborted', 'pertinaciously', 'prejudge', 'gallingly', 'dishonor', 'contortions', 'confusions', 'exasperating', 'deceit', 'laughable', 'menacing', 'unclean', 'uproarous', 'wane', 'disagreeing', 'madness', 'alienation', 'unusably', 'excuses', 'stampede', 'despotism', 'dirts', 'thankless', 'womanizer', 'caustic', 'flaking', 'inconsolably', 'belligerent', 'lull', 'regress', 'usurp', 'unsupported', 'pillage', 'freezes', 'picketing', 'imperfect', 'provocative', 'prohibitively', 'sinful', 'critic', 'denunciate', 'indecent', 'confound', 'shortage', 'impediment', 'uncertain', 'flare', 'shameful', 'spewing', 'delude', 'hardships', 'nightmarish', 'unconvincing', 'wack', 'bombard', 'preposterously', 'staid', 'demeaning', 'forbidding', 'uncreative', 'bickering', 'pessimistically', 'troubles', 'consternation', 'misery', 'tenuous', 'vibrates', 'slack', 'offender', 'abrupt', 'brashness', 'villainous', 'questionable', 'crumble', 'bleeding', 'dismay', 'perplexed', 'misaligned', 'skittish', 'impolite', 'spurn', 'disses', 'inculcate', 'stormy', 'vindictively', 'stubborn', 'indiscreetly', 'afflictive', 'womanizing', 'despondently', 'remorse', 'unbearablely', 'toil', 'quarrellous', 'fearful', 'inefficiency', 'scarce', 'bombardment', 'miscellaneous', 'sluts', 'displaced', 'blurt', 'contaminating', 'scary', 'superfluous', 'harbors', 'stumbled', 'deadbeat', 'fevers', 'indeterminate', 'disavowal', 'denunciations', 'remorselessly', 'diabolical', 'idiotic', 'cataclysmically', 'concerned', 'impetuous', 'oppressive', 'polemize', 'smallish', 'snobbish', 'curt', 'so-cal', 'underdog', 'wrip', 'excessively', 'dislike', 'scapegoat', 'fallacy', 'compulsive', 'annoys', 'lamentably', 'ridicule', 'ridiculously', 'fatcats', 'scandalize', 'eccentricity', 'undue', 'bankrupt', 'uprising', 'trapped', 'hoax', 'dissatisfactory', 'hardliner', 'laughingstock', 'loathsomely', 'bitchy', 'qualms', 'repugnance', 'impudently', 'futility', 'regretful', 'lapsed', 'lesser-known', 'cloudy', 'disgrace', 'incitement', 'starkly', 'fustigate', 'corrosion', 'scornful', 'malign', 'lurk', 'malicious', 'impaired', 'boycott', 'barbarous', 'impossible', 'prisoner', 'ugliest', 'licentiously', 'growl', 'worsen', 'irragularity', 'beseech', 'bugs', 'grate', 'recession', 'scratches', 'impinge', 'tortures', 'infamous', 'insolvent', 'miserable', 'outsider', 'throttle', 'hideous', 'panick', 'obstructs', 'haunting', 'poor', 'discontinued', 'guiltily', 'scaly', 'spiteful', 'crooks', 'impunity', 'scams', 'violently', 'ailment', 'apprehension', 'distrusting', 'mulish', 'wound', 'disaffirm', 'resistance', 'slut', 'startlingly', 'alienate', 'torture', 'inanely', 'execrate', 'perplex', 'hells', 'amiss', 'omit', 'mistified', 'adamantly', 'undercut', 'fragile', 'deception', 'viper', 'spinster', 'pokey', 'stains', 'dust', 'ugliness', 'contemptuously', 'debaser', 'outbursts', 'errors', 'arrogance', 'handicapped', 'anti-israeli', 'inactive', 'savage', 'feverish', 'unraveled', 'craziness', 'snappishly', 'strange', 'difficulty', 'hotheaded', 'inequality', 'unpopular', 'slogged', 'dropouts', 'weariness', 'pillory', 'swamped', 'renunciation', 'distraction', 'trap', 'stiffness', 'contagious', 'drunken', 'hotbeds', 'inflame', 'enrage', 'tyrannical', 'subpoenas', 'enraged', 'cheating', 'equivocal', 'miserably', 'smudged', 'bullies', 'strained', 'flagrantly', 'incapably', 'superstitious', 'eschew', 'dirtbags', 'unlicensed', 'disarray', 'plot', 'wail', 'exorbitant', 'pickets', 'conflict', 'dearth', 'discountenance', 'irksomenesses', 'worrying', 'malignant', 'rollercoaster', 'famine', 'awkward', 'aggravating', 'anger', 'unruly', 'grouchy', 'dropout', 'illiterate', 'exasperated', 'imprudence', 'erroneous', 'suffer', 'tired', 'despondency', 'smelly', 'barbarously', 'dilemma', 'jealously', 'scam', 'wily', 'unorthodox', 'conspiracy', 'exorbitantly', 'ineloquently', 'dastardly', 'high-priced', 'dissatisfying', 'dazed', 'jittery', 'discouragement', 'gimmicky', 'scorching', 'contradictory', 'bothersome', 'insupportable', 'layoff-happy', 'moribund', 'shamefully', 'undependable', 'threatening', 'broken-hearted', 'deficient', 'unfit', 'stresses', 'disdain', 'smelled', 'droop', 'randomly', 'atrocities', 'discrimination', 'caricature', 'damages', 'malevolence', 'snobish', 'false', 'brainless', 'torturing', 'destabilisation', 'back-woods', 'deceiving', 'berserk', 'issue', 'moron', 'villian', 'loopholes', 'insanely', 'damned', 'lorn', 'bitterness', 'monstrosities', 'suspicions', 'corrupt', 'harangue', 'naive', 'job-killing', 'slowww', 'unuseably', 'ragged', 'unable', 'detest', 'buzzing', 'insensible', 'flighty', 'admonishment', 'vengeance', 'sobering', 'capriciously', 'undermine', 'flaws', 'gutter', 'squabbling', 'unthinkably', 'smudge', 'ignominy', 'inconveniently', 'aching', 'ire', 'limp', 'obliterate', 'disunity', 'egregiously', 'concession', 'watered-down', 'foolishness', 'cowardly', 'indiscriminate', 'insinuating', 'mournful', 'ill-conceived', 'officious', 'grind', 'prickle', 'sneer', 'audiciously', 'antagonize', 'twist', 'denial', 'upbraid', 'bother', 'insults', 'dilly-dally', 'bleed', 'besiege', 'abort', 'diatribe', 'revoke', 'unsettled', 'treacherously', 'straggle', 'skulk', 'rhapsodize', 'perturbed', 'slur', 'fibber', 'thumb-down', 'blow', 'indecorum', 'vindictive', 'flawed', 'discompose', 'insulting', 'offensiveness', 'spoon-feed', 'molest', 'exhausted', 'cliched', 'judders', 'unforeseen', 'hooligan', 'concern', 'occlude', 'demonizing', 'flee', 'unease', 'damnably', 'defile', 'enemy', 'topple', 'weary', 'aspersion', 'sourly', 'vibration', 'wasteful', 'nemesis', 'shrouded', 'cuss', 'mocking', 'vindictiveness', 'undercuts', 'impertinent', 'mispronounce', 'dismayingly', 'famished', 'pertinacious', 'frustratingly', 'sweaty', 'anti-american', 'stumps', 'curses', 'dissappointing', 'fell', 'brashly', 'stingy', 'traitorously', 'gloatingly', 'calamitous', 'insignificant', 'zealous', 'fiendish', 'disingenuous', 'jagged', 'unpleasantries', 'plotters', 'fraught', 'rebuff', 'refuses', 'underpaid', 'sh*t', 'cunt', 'fugitive', 'obsessively', 'disgusted', 'flirt', 'smudges', 'untested', 'hazy', 'drastic', 'downhill', 'mistrustful', 'spook', 'vain', 'restricted', 'blinding', 'unqualified', 'gullible', 'smother', 'biased', 'unjustly', 'abominably', 'cash-strapped', 'unnervingly', 'displeasing', 'dragged', 'offence', 'audaciousness', 'prison', 'relentlessness', 'avenge', 'bitter', 'awfully', 'denigrate', 'posturing', 'blotchy', 'lugubrious', 'insignificantly', 'fearfully', 'spite', 'stupor', 'dissention', 'sullen', 'brash', 'derisive', 'unproved', 'creaks', 'disapointment', 'deign', 'culpable', 'fright', 'hairloss', 'irreformable', 'manipulation', 'atrocious', 'dauntingly', 'revolting', 'self-criticism', 'spooky', 'spurious', 'over-awe', 'murder', 'pitifully', 'thicker', 'avariciously', 'killjoy', 'crush', 'tank', 'thumbs-down', 'inexperienced', 'overzealously', 'agonizing', 'ironies', 'avaricious', 'disallow', 'lacking', 'loud', 'unbelievable', 'injudicious', 'misbegotten', 'crashes', 'hurting', 'oppressors', 'crime', 'friggin', 'overzelous', 'hardened', 'hothouse', 'instability', 'kook', 'morons', 'eruptions', 'destroy', 'immorally', 'murderer', 'maltreatment', 'pitiless', 'counterproductive', 'procrastinates', 'unpleasant', 'neurotically', 'hoard', 'quarrel', 'depressingly', 'mar', 'repugnantly', 'depravedly', 'forsake', 'stinging', 'debauch', 'unfortunately', 'irrationals', 'murderously', 'embroiled', 'salacious', 'cloud', 'haste', 'irrational', 'phobic', 'cancerous', 'suicidal', 'losers', 'violator', 'd*mn', 'irrationality', 'entrap', 'scariest', 'suffering', 'averse', 'rhetorical', 'wounds', 'apocalypse', 'nauseates', 'monster', 'inhumane', 'overloaded', 'upsettingly', 'scandal', 'insane', 'displease', 'boring', 'intrusive', 'infidel', 'deride', 'avalanche', 'rigidness', 'dubitable', 'astray', 'butchery', 'frightfully', 'frightful', 'gaffe', 'mortifying', 'hopeless', 'paradoxical', 'unsatisfactory', 'impedance', 'irreplacible', 'acridness', 'concen', 'villainously', 'outlaw', 'proprietary', 'evasion', 'rape', 'punitive', 'irresponsibly', 'wretch', 'devastate', 'entangle', 'hallucination', 'peevish', 'slumpping', 'anarchistic', 'liars', 'spewed', 'inconceivable', 'fallacious', 'begging', 'criticisms', 'flakieness', 'fussy', 'incredulously', 'graceless', 'hiss', 'nervously', 'confusing', 'inequitable', 'stain', 'deceiver', 'effrontery', 'controversial', 'derision', 'fails', 'affliction', 'irrationally', 'stammer', 'trick', 'strangle', 'contort', 'error', 'knave', 'greed', 'maladjustment', 'illogical', 'restriction', 'slow', 'extravagantly', 'irks', 'hard-line', 'glaringly', 'illicit', 'bid-rigging', 'phobia', 'perverted', 'exclusion', 'anomalous', 'betrays', 'bruising', 'inimically', 'emasculate', 'ordeal', 'debase', 'torturous', 'itching', 'rubbish', 'fatcat', 'infiltrator', 'stumbles', 'paupers', 'profanity', 'haters', 'frenetic', 'stale', 'suspect', 'daunt', 'shamelessness', 'traumatize', 'unexpected', 'creeps', 'douchebag', 'fail', 'irk', 'weep', 'distaste', 'distraught', 'devastating', 'demonized', 'massacre', 'poorer', 'coupists', 'overkill', 'broke', 'allege', 'frightening', 'detrimental', 'downer', 'goof', 'inexorably', 'calumniously', 'oppressively', 'ineffectiveness', 'retard', 'straggler', 'nightmare', 'nitpicking', 'anxiety', 'degradingly', 'inflict', 'poison', 'layoff', 'chasten', 'defective', 'dimmer', 'exhorbitant', 'shroud', 'stew', 'broken', 'suspicious', 'forbidden', 'figurehead', 'hissing', 'prick', 'repudiation', 'ripped', 'counter-productive', 'estranged', 'musty', 'crueler', 'tortuous', 'immoderate', 'jerky', 'disgustingly', 'irritable', 'irritations', 'niggle', 'suicide', 'manic', 'mockery', 'unspeakablely', 'absurd', 'humid', 'sunk', 'disregardful', 'rampage', 'dullard', 'exaggerate', 'inadverently', 'mope', 'unjustified', 'sadness', 'ripoff', 'crash', 'disparagingly', 'misleading', 'muscle-flexing', 'oppressiveness', 'two-faced', 'havoc', 'irritation', 'needy', 'ghosting', 'taboo', 'greedy', 'reprehension', 'tarnishing', 'overpayed', 'contrive', 'lethargic', 'galling', 'obese', 'sully', 'scratch', 'creeping', 'wayward', 'vile', 'smash', 'adversary', 'backwoods', 'smelt', 'uncomfortably', 'denied', 'partiality', 'lags', 'haywire', 'impurity', 'condescending', 'downfall', 'pathetically', 'wince', 'futile', 'senseless', 'sneaky', 'barren', 'botch', 'jitter', 'overtaxed', 'bewildering', 'disoriented', 'protracted', 'animosity', 'hardheaded', 'backaches', 'barbaric', 'allegations', 'irrecoverablenesses', 'laid-off', 'grainy', 'mispronounced', 'crowdedness', 'preoccupy', 'whores', 'worryingly', 'mangling', 'unhappy', 'shortchange', 'hopelessly', 'stingingly', 'rremediable', 'hell', 'unrelenting', 'sub-par', 'lemon', 'irresolute', 'creep', 'hysterics', 'disastrously', '2-faces', 'implausible', 'infirm', 'exorbitantance', 'immaterial', 'un-viewable', 'ungovernable', 'doddering', 'threesome', 'aggravate', 'inflexible', 'dope', 'malcontent', 'stupid', 'noisier', 'undesirable', 'peeled', 'disrespectfulness', 'impose', 'blandish', 'slumping', 'wobble', 'irretrievable', 'desolation', 'intrude', 'dense', 'sicken', 'nonexistent', 'sagged', 'slime', 'retaliatory', 'uncompromising', 'unleash', 'infamy', 'subjugation', 'unsettling', 'raped', 'bleeds', 'brutalities', 'cheats', 'crumpled', 'delusion', 'shamefulness', 'standstill', 'disheartening', 'austere', 'backache', 'panicked', 'bullyingly', 'incompatibility', 'reviled', 'rumors', 'little-known', 'treacherous', 'inflated', 'timid', 'vex', 'motley', 'antagonism', 'bewilder', 'discordant', 'leery', 'trash', 'wreak', 'grumpy', 'severity', 'misguidance', 'detract', 'senselessly', 'fallen', 'zap', 'frantically', 'aches', 'depraved', 'harried', 'accidental', 'unsuccessful', 'inexplainable', 'grieve', 'implacable', 'bungle', 'misconceptions', 'ambivalence', 'extremists', 'negative', 'draining', 'tattered', 'misguided', 'barbarian', 'misgivings', 'tingling', 'fried', 'crumples', 'stall', 'tense', 'prohibit', 'deadweight', 'unreadable', 'squeal', 'capsize', 'hates', 'liable', 'setback', 'shortcomings', 'overstatement', 'grievous', 'admonishingly', 'disrepute', 'plebeian', 'exasperation', 'impolitic', 'painfully', 'disvalue', 'uninformed', 'shimmer', 'flairs', 'mangle', 'credulous', 'vengefulness', 'lone', 'scornfully', 'inferiority', 'utterly', 'macabre', 'hardliners', 'repulsive', 'confuses', 'chatter', 'incomprehension', 'addicts', 'gibberish', 'loophole', 'unequal', 'strict', 'insidiously', 'liar', 'disbelief', 'stalls', 'disapprobation', 'destruction', 'jeeringly', 'indignantly', 'abuses', 'biting', 'detraction', 'imperialist', 'imaginary', 'deceive', 'unspeakable', 'douchbag', 'frighten', 'vibrating', 'impetuously', 'temerity', 'molestation', 'flares', 'outcry', 'sadden', 'spitefully', 'taut', 'dragging', 'two-faces', 'cautionary', 'helplessly', 'totalitarian', 'scandals', 'err', 'shortness', 'disobedient', 'retardedness', 'bafflement', 'inundated', 'unjust', 'ill-formed', 'inclement', 'dissolute', 'gainsay', 'gimmick', 'chilly', 'ignorant', 'manipulative', 'stutters', 'untrue', 'uneconomical', 'dismaying', 'villianous', 'belie', 'whimper', 'insufferable', 'tauntingly', 'impiety', 'cuplrit', 'excruciatingly', 'unconstitutional', 'manipulate', 'fatigue', 'condemns', 'deadlock', 'disappointments', 'expired', 'spiritless', 'desiccate', 'dismalness', 'obstruction', 'overbalance', 'asininely', 'sloth', 'rattles', 'disdainfully', 'dies', 'addicting', 'defamations', 'degenerate', 'over-valuation', 'stutter', 'unfamiliar', 'unlamentable', 'impossiblity', 'brood', 'repetitive', 'inapt', 'misunderstand', 'anti-occupation', 'loathly', 'complacent', 'lacks'}\n"
          ]
        }
      ],
      "source": [
        "download(\"positive-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/positive-words.txt\")\n",
        "download(\"negative-words.txt\", \"https://raw.githubusercontent.com/unibodatascience/BBS-TextMining/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/negative-words.txt\")\n",
        "\n",
        "hu_liu_pos = load_hu_liu(\"positive-words.txt\")\n",
        "print('Positive words')\n",
        "print(hu_liu_pos)\n",
        "\n",
        "print()\n",
        "\n",
        "hu_liu_neg = load_hu_liu(\"negative-words.txt\")\n",
        "print('Negative words')\n",
        "print(hu_liu_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzWuXxEq9INJ"
      },
      "source": [
        "The words in the list are general, but we can add some domain-specific word (\"`|`\" is the \"set union\" operator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XHAevZFs9INK"
      },
      "outputs": [],
      "source": [
        "airline_pos_words = hu_liu_pos | {\"upgrade\"}\n",
        "airline_neg_words = hu_liu_neg | {\"wtf\", \"wait\", \"waiting\", \"epicfail\", \"mechanical\"} # wtf what the fu.k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w7GIElE9INL"
      },
      "source": [
        "_Performance note:_ we use sets here (denoted with braces: `{...}`) rather than lists (with square brackets: `[...]`) to make lookup faster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oy45mfQ79INL",
        "outputId": "8508667e-b7d7-47c3-e101-87282221d700"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "64.2 ns ¬± 7.24 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 1000000 \n",
        "# -n represents the number of loops, i.e. the number of times the code will be executed\n",
        "# 5 is the test repeat count; the tests are repeated several times. The fastest time of those 5 is then taken.\n",
        "\n",
        "\"e\" in [\"a\", \"b\", \"c\", \"d\", \"e\"]   # list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADOFvNSD9INN",
        "outputId": "0d02edd5-85de-4694-ed83-280cca1df239"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.6 ns ¬± 2.7 ns per loop (mean ¬± std. dev. of 7 runs, 1,000,000 loops each)\n"
          ]
        }
      ],
      "source": [
        "%%timeit -n 1000000\n",
        "\"e\" in {\"a\", \"b\", \"c\", \"d\", \"e\"}   # set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h8XH_H6d9INP"
      },
      "source": [
        "### Text tokenization\n",
        "\n",
        "We have to decompose tweets into the single words they contain in order to search for the opinion words within it\n",
        "\n",
        "A _tokenization_ algorithm splits a text string into a sequence of _tokens_ each representing a single word (or other entities such as numbers and punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mSDplc_P9INP"
      },
      "source": [
        "A simple tokenization algorithm can consist in removing all characters different from letters and spaces from text, than splitting text in words using spaces as boundaries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJORMSRs9INP"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "# Considering \"This isn't a test, or is it?\" sentence as text\n",
        "# re.sub(\"[^A-Za-z ]\", \"\", text) will transform it as 'This isnt a test or is it'. \n",
        "# In general, it removes (that is equivalent to: substitute with \"\") every character that is not a upperase/lowercase letter or space\n",
        "def my_tokenizer(text):\n",
        "    # split(\" \") is used to split the sentence in a list of strings using the space \" \" as separator\n",
        "    return re.sub(\"[^A-Za-z ]\", \"\", text).split(\" \") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw9xbtIU9INQ"
      },
      "source": [
        "An example usage is..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3W6juY_S9INR",
        "outputId": "c8b8660d-f38f-40d3-d602-d30dcac98c7f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This', 'isnt', 'a', 'test', 'or', 'is', 'it']"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_tokenizer(\"This isn't a test, or is it?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFoRFRJM9INS"
      },
      "source": [
        "NLTK provides a finer tokenization algorithm, based on a knowledge model of the English language: in order to make it work, we have first to download the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnBPTc5E9INT",
        "outputId": "6a69750b-603a-47ad-9272-d4997b1a9c2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/gianluca/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 265,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"punkt\") # PunktSentenceTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pS5JsR0E9INU"
      },
      "source": [
        "We can then use the `word_tokenize` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su1bApvb9INU",
        "outputId": "82b041e5-67f9-42bf-88b3-a3c18510ca9e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.word_tokenize(\"This isn't a test, or is it?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftuN515Y9INW"
      },
      "source": [
        "Other than keeping punctuation marks as separate tokens, NLTK was able to correctly split \"isn't\" into its two component words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trAmVK-69INX"
      },
      "source": [
        "### Sentiment scoring\n",
        "\n",
        "We define a function to compute the \"sentiment score\" of some text, computed as the difference between counts of positive and negative opinion words contained in it. Notice we have to convert all words in lowercase to be sure to find them in the lists."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "walyIml89INX"
      },
      "outputs": [],
      "source": [
        "def sentiment_score(text, pos_words, neg_words):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    # count 1 for each word present in the positive words list\n",
        "    pos_matches = sum(1 for word in words if word.lower() in pos_words)\n",
        "    # same count with the negative words list\n",
        "    neg_matches = sum(1 for word in words if word.lower() in neg_words)\n",
        "    # return the difference between the two counts\n",
        "    return pos_matches - neg_matches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEiDe6fv9INZ"
      },
      "source": [
        "This functions accept the lists of positive and negative words as input, we can wrap it in a version specific for the \"airline\" opinion words lists"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njkdCZha9INZ"
      },
      "outputs": [],
      "source": [
        "def airline_sentiment_score(text):\n",
        "    return sentiment_score(text, airline_pos_words, airline_neg_words)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwKz63o99INb"
      },
      "source": [
        "Example: a sentence with one positive word..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KsCtI9SU9INb",
        "outputId": "92b49cdb-81ef-4124-ae37-861b765b043c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 269,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "airline_sentiment_score(\"This is an awesome test!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aQ1fUrK9INd"
      },
      "source": [
        "Let's consider a small set of sample sentences to evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DvZj3Qg59INd"
      },
      "outputs": [],
      "source": [
        "sample = [\n",
        "    \"You're awesome and I love you\",\n",
        "    \"I hate and hate and hate. So angry. Die!\",\n",
        "    \"Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVxGd4jj9INf"
      },
      "source": [
        "We can use `map` to apply the scoring function to each of the samples and get the sequence of corresponding scores wrapped in a list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hzGXMsQ9INf"
      },
      "outputs": [],
      "source": [
        "sample_scores = list(map(airline_sentiment_score, sample))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wJ5dPnud9INh",
        "outputId": "f4b79f53-d6fb-416f-f64e-be80a7276024"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[2, -5, 4]"
            ]
          },
          "execution_count": 272,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I306cBAA9INj"
      },
      "source": [
        "Using a pandas DataFrame, we can get a table of sample sentences matched with scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "kWoqjh6f9INk",
        "outputId": "19bf9f93-12fb-411e-8744-feb732f34a04"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>You're awesome and I love you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-5</td>\n",
              "      <td>I hate and hate and hate. So angry. Die!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   score  \\\n",
              "0      2   \n",
              "1     -5   \n",
              "2      4   \n",
              "\n",
              "                                                                                     text  \n",
              "0                                                           You're awesome and I love you  \n",
              "1                                                I hate and hate and hate. So angry. Die!  \n",
              "2  Impressed and amazed: you are peerless in your achievement of unparalleled mediocrity.  "
            ]
          },
          "execution_count": 273,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({\"score\": sample_scores, \"text\": sample})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4iDxy-y9INl"
      },
      "source": [
        "As we can see, the scoring function correctly evaluates straightforward sentences, although it fails to detect more elaborate text (e.g. using sarcasm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAPiIBPC9INl"
      },
      "source": [
        "Let's apply the scoring functions to all tweets for one of the companies, e.g. Delta. We wrap scores in a pandas Series so we can use its functionalities."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UHfh_kQf9INm"
      },
      "outputs": [],
      "source": [
        "delta_scores = pd.Series(map(airline_sentiment_score, tweets[\"text\"][tweets[\"airline\"] == \"delta\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XANhbzGVgva_",
        "outputId": "1700a31e-ef67-46be-e0b9-29d017872420"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       1\n",
              "1       0\n",
              "2       0\n",
              "3      -1\n",
              "4       0\n",
              "       ..\n",
              "1140   -1\n",
              "1141   -1\n",
              "1142    0\n",
              "1143    0\n",
              "1144    0\n",
              "Length: 1145, dtype: int64"
            ]
          },
          "execution_count": 275,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTqV-3Y19INn"
      },
      "source": [
        "We can get for example the mean score of tweets..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SX8uoX49INo",
        "outputId": "bba17036-0711-4582-c055-bb3875a8b425"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.23231441048034934"
            ]
          },
          "execution_count": 276,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "delta_scores.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAM9PgZ9INp"
      },
      "source": [
        "...and even plot an histogram of the distribution of scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "IdnDfrX49INq",
        "outputId": "54a52d07-1ffd-4adf-b0ff-2b33e608082b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:ylabel='Frequency'>"
            ]
          },
          "execution_count": 277,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "delta_scores.plot.hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0TSBjii9INr"
      },
      "source": [
        "Let's now work with the whole collection of tweets related to all airlines\n",
        "\n",
        "We compute sentiment scores for each tweet by applying the `airline_sentiment_score` function to the `text` columns; scores are saved in a `score` column added to a copy of the `tweets` DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-DsQ0Pd39INr"
      },
      "outputs": [],
      "source": [
        "tweets_with_scores = tweets.copy() # to leave unchanged the tweets DataFramce\n",
        "tweets_with_scores[\"score\"] = tweets_with_scores[\"text\"].apply(airline_sentiment_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOG2mmQe9INs"
      },
      "source": [
        "Let's see some random rows from it..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "O6sqT54S9INt",
        "outputId": "bc59d530-0f7b-49fe-9015-ec271277f4af"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>airline</th>\n",
              "      <th>text</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3682</th>\n",
              "      <td>united</td>\n",
              "      <td>RT @united: Tweet the amount of extra legroom in Economy Plus w/ #flyerfriendly for a chance to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1819</th>\n",
              "      <td>americanair</td>\n",
              "      <td>RT @FOXSportsLive: Best Customer Service of the day goes to @AmericanAir</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1021</th>\n",
              "      <td>delta</td>\n",
              "      <td>About to board an @Delta flight to Houston for #NRPACongress, stop by the @wtiworld booth number...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3984</th>\n",
              "      <td>united</td>\n",
              "      <td>United People of Pakistan</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>delta</td>\n",
              "      <td>Never experienced such distaste before a @delta flight!The lady knew she was wrong and didn't ma...</td>\n",
              "      <td>-2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          airline  \\\n",
              "3682       united   \n",
              "1819  americanair   \n",
              "1021        delta   \n",
              "3984       united   \n",
              "951         delta   \n",
              "\n",
              "                                                                                                     text  \\\n",
              "3682  RT @united: Tweet the amount of extra legroom in Economy Plus w/ #flyerfriendly for a chance to ...   \n",
              "1819                             RT @FOXSportsLive: Best Customer Service of the day goes to @AmericanAir   \n",
              "1021  About to board an @Delta flight to Houston for #NRPACongress, stop by the @wtiworld booth number...   \n",
              "3984                                                                            United People of Pakistan   \n",
              "951   Never experienced such distaste before a @delta flight!The lady knew she was wrong and didn't ma...   \n",
              "\n",
              "      score  \n",
              "3682      1  \n",
              "1819      1  \n",
              "1021      0  \n",
              "3984      0  \n",
              "951      -2  "
            ]
          },
          "execution_count": 279,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tweets_with_scores.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id6S53XS9INu"
      },
      "source": [
        "### Summarizing sentiment for each company\n",
        "\n",
        "Let‚Äôs focus our analysis only on very negative (score <= 2) and very positive (score >= 2) tweets, adding columns which identify them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNKPLeHv9INu"
      },
      "outputs": [],
      "source": [
        "tweets_with_scores[\"very_pos\"] = tweets_with_scores[\"score\"] >= 2\n",
        "tweets_with_scores[\"very_neg\"] = tweets_with_scores[\"score\"] <= -2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUiKdp6G9INx"
      },
      "source": [
        "We group the frame by companies, keeping just the columns indicating very positive or negative tweets and counting the number of them for each group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLlyCc2u9INx"
      },
      "outputs": [],
      "source": [
        "twitter_score = tweets_with_scores.groupby(\"airline\")[[\"very_pos\", \"very_neg\"]].sum().sort_index()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RsmBFK-U9INz"
      },
      "source": [
        "Let's view the obtained grouped table..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "KEzM87Un9IN0",
        "outputId": "2423a120-0cbc-4a1f-ccdd-2b64a2bc17cf"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>very_pos</th>\n",
              "      <th>very_neg</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>116</td>\n",
              "      <td>56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>122</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>117</td>\n",
              "      <td>101</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              very_pos  very_neg\n",
              "airline                         \n",
              "americanair        118        31\n",
              "delta              116        56\n",
              "jetblue             10         2\n",
              "southwestair       122        34\n",
              "united             117       101"
            ]
          },
          "execution_count": 282,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "In3HBOxx9IN2"
      },
      "source": [
        "`airline` is now the _index_ of the frame: values of the index identify each row (much like a primary key in a database)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQLL_qnb9IN2"
      },
      "source": [
        "For every company, we compute the sum of very positive and very negative tweets..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c8cE82zg9IN2"
      },
      "outputs": [],
      "source": [
        "twitter_score[\"all_count\"] = twitter_score.very_pos + twitter_score.very_neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFcIG4YN9IN4"
      },
      "source": [
        "...then we compute a \"global sentiment score\" as the percentage between the count of positive tweets and the total count of tweets above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UwlgKs19IN5"
      },
      "outputs": [],
      "source": [
        "twitter_score[\"score\"] = 100 * twitter_score.very_pos / twitter_score.all_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNz_-VSt9IN7"
      },
      "source": [
        "Let's now list the companies ranked by their score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "KlEyMUuX9IN7",
        "outputId": "2ae25095-1874-4d76-e273-e93aa124fa73"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>very_pos</th>\n",
              "      <th>very_neg</th>\n",
              "      <th>all_count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>10</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>83.333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>118</td>\n",
              "      <td>31</td>\n",
              "      <td>149</td>\n",
              "      <td>79.195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>122</td>\n",
              "      <td>34</td>\n",
              "      <td>156</td>\n",
              "      <td>78.205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>116</td>\n",
              "      <td>56</td>\n",
              "      <td>172</td>\n",
              "      <td>67.442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>117</td>\n",
              "      <td>101</td>\n",
              "      <td>218</td>\n",
              "      <td>53.670</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              very_pos  very_neg  all_count   score\n",
              "airline                                            \n",
              "jetblue             10         2         12  83.333\n",
              "americanair        118        31        149  79.195\n",
              "southwestair       122        34        156  78.205\n",
              "delta              116        56        172  67.442\n",
              "united             117       101        218  53.670"
            ]
          },
          "execution_count": 285,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "twitter_score.sort_values(\"score\", ascending=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pav5BKXF9IN8"
      },
      "source": [
        "To simplify subsequent tests, we create a function which, given a series of scores for tweets, executes the steps above to extract summary scores for each airline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNj8OLsF9IN8"
      },
      "outputs": [],
      "source": [
        "def get_summary_scores(tweet_scores):\n",
        "    very_pos_tweets = tweet_scores >= 2\n",
        "    very_neg_tweets = tweet_scores <= -2\n",
        "    very_pos = very_pos_tweets.groupby(tweets[\"airline\"]).sum()\n",
        "    very_neg = very_neg_tweets.groupby(tweets[\"airline\"]).sum()\n",
        "    total = very_pos + very_neg\n",
        "    return 100 * (very_pos / total)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Img7WOX9IN-"
      },
      "source": [
        "### Comparing results with known customer satisfaction\n",
        "\n",
        "We can extract known information about the general satisfaction of airline companies from the ACSI (_American Customer Satisfaction Index_) website\n",
        "\n",
        "A table of the satisfaction index by year about airline companies is available at\n",
        "\n",
        "https://web.archive.org/web/20200203093734/https://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\n",
        "\n",
        "<!-- http://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines -->\n",
        "\n",
        "We can import such data and use it to validate the satisfaction score extracted from Twitter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWYVF1x09IN-"
      },
      "source": [
        "pandas provides the `read_html` function to get DataFrames by scraping tables from a Web page (the `lxml` and `BeautifulSoup4` packages must be installed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzQcr8ci9IN-"
      },
      "outputs": [],
      "source": [
        "import ssl\n",
        "# it overrides the default function for context creation with the function to create an unverified context\n",
        "# namely to disable certificate verification\n",
        "ssl._create_default_https_context = ssl._create_unverified_context\n",
        "\n",
        "acsi_table = pd.read_html(\n",
        "    \"https://web.archive.org/web/20200203093734/https://www.theacsi.org/index.php?option=com_content&view=article&id=147&catid=&Itemid=212&i=Airlines\",\n",
        "    header=0, index_col=0)[1]\n",
        "\n",
        "# use the local copy of ACSI table just in case of network troubles\n",
        "# acsi_table = pd.read_html(\"https://www.dropbox.com/s/xgkqtcd9bu6jres/acsi_arlines.html?raw=1\",\n",
        "#    header=0, index_col=0)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 403
        },
        "id": "_-CPi6_M9IOA",
        "outputId": "9e723f7b-383a-478b-9ba1-d41a24e47d43"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>PreviousYear%Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>77.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Southwest</th>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>-1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JetBlue</th>\n",
              "      <td>80.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>71.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Airlines</th>\n",
              "      <td>72.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American</th>\n",
              "      <td>72.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>-1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Others</th>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Allegiant</th>\n",
              "      <td>65.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-4.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United</th>\n",
              "      <td>68.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frontier</th>\n",
              "      <td>66.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              16    17    18    19  PreviousYear%Change\n",
              "Alaska      77.0  78.0  79.0  80.0                  1.3\n",
              "Southwest   80.0  80.0  80.0  79.0                 -1.3\n",
              "JetBlue     80.0  82.0  79.0  79.0                  0.0\n",
              "Delta       71.0  76.0  74.0  75.0                  1.4\n",
              "Airlines    72.0  75.0  73.0  74.0                  1.4\n",
              "American    72.0  76.0  74.0  73.0                 -1.4\n",
              "All Others  74.0  74.0  73.0  71.0                 -2.7\n",
              "Allegiant   65.0  71.0  74.0  71.0                 -4.1\n",
              "United      68.0  70.0  67.0  70.0                  4.5\n",
              "Frontier    66.0  63.0  62.0  64.0                  3.2"
            ]
          },
          "execution_count": 288,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_table.iloc[:10,-5:] # display the first ten rows and the last five columuns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz8CFcpZlqaJ",
        "outputId": "7bbfcc34-3e45-40b6-bd31-5b208495e97d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(14, 27)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>PreviousYear%Change</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Alaska</th>\n",
              "      <td>NM</td>\n",
              "      <td>NM</td>\n",
              "      <td>75</td>\n",
              "      <td>77.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Southwest</th>\n",
              "      <td>81</td>\n",
              "      <td>78</td>\n",
              "      <td>78</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>-1.3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>JetBlue</th>\n",
              "      <td>83</td>\n",
              "      <td>79</td>\n",
              "      <td>81</td>\n",
              "      <td>80.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Delta</th>\n",
              "      <td>68</td>\n",
              "      <td>71</td>\n",
              "      <td>71</td>\n",
              "      <td>71.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Airlines</th>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>69</td>\n",
              "      <td>72.0</td>\n",
              "      <td>75.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>American</th>\n",
              "      <td>65</td>\n",
              "      <td>66</td>\n",
              "      <td>66</td>\n",
              "      <td>72.0</td>\n",
              "      <td>76.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>-1.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>All Others</th>\n",
              "      <td>72</td>\n",
              "      <td>70</td>\n",
              "      <td>73</td>\n",
              "      <td>74.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>73.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-2.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Allegiant</th>\n",
              "      <td>NM</td>\n",
              "      <td>NM</td>\n",
              "      <td>65</td>\n",
              "      <td>65.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>74.0</td>\n",
              "      <td>71.0</td>\n",
              "      <td>-4.1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>United</th>\n",
              "      <td>62</td>\n",
              "      <td>60</td>\n",
              "      <td>60</td>\n",
              "      <td>68.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>67.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Frontier</th>\n",
              "      <td>NM</td>\n",
              "      <td>NM</td>\n",
              "      <td>58</td>\n",
              "      <td>66.0</td>\n",
              "      <td>63.0</td>\n",
              "      <td>62.0</td>\n",
              "      <td>64.0</td>\n",
              "      <td>3.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            13  14  15    16    17    18    19  PreviousYear%Change\n",
              "Alaska      NM  NM  75  77.0  78.0  79.0  80.0                  1.3\n",
              "Southwest   81  78  78  80.0  80.0  80.0  79.0                 -1.3\n",
              "JetBlue     83  79  81  80.0  82.0  79.0  79.0                  0.0\n",
              "Delta       68  71  71  71.0  76.0  74.0  75.0                  1.4\n",
              "Airlines    69  69  69  72.0  75.0  73.0  74.0                  1.4\n",
              "American    65  66  66  72.0  76.0  74.0  73.0                 -1.4\n",
              "All Others  72  70  73  74.0  74.0  73.0  71.0                 -2.7\n",
              "Allegiant   NM  NM  65  65.0  71.0  74.0  71.0                 -4.1\n",
              "United      62  60  60  68.0  70.0  67.0  70.0                  4.5\n",
              "Frontier    NM  NM  58  66.0  63.0  62.0  64.0                  3.2"
            ]
          },
          "execution_count": 329,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(acsi_table.shape) # 14 rows, 27 columns \n",
        "acsi_table.iloc[:10,-8:] # display the last 7 years since 2013"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4mE8sbW9IOB"
      },
      "source": [
        "We select the column \"13\" for the year when tweets were extracted (use \"21\" in case you are analyzing current tweets) and the rows related to analyzed companies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jJfNKq39IOB"
      },
      "outputs": [],
      "source": [
        "airline_names = [\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        "acsi_score = acsi_table.loc[airline_names, \"13\"].astype(float).sort_index() # loc() function let us select only certain columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkg7Ug9C9IOE",
        "outputId": "3f825dc4-bb4f-45cf-83ca-b272137438db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "American     65.0\n",
              "Delta        68.0\n",
              "JetBlue      83.0\n",
              "Southwest    81.0\n",
              "United       62.0\n",
              "Name: 13, dtype: float64"
            ]
          },
          "execution_count": 326,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5F0584r9IOF"
      },
      "source": [
        "In case you miss the required libraries, here are two alternative instructions to create the ACSI scores series without using the `read_html` function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wroivXas9IOF"
      },
      "outputs": [],
      "source": [
        "# 2021 (current_tweets)\n",
        "acsi_score = pd.Series(\n",
        "          [      79.0 ,     77.0 ,      75.0 ,   79.0 ,    75.0 ],\n",
        "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        ").sort_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpIwLxb39IOG",
        "outputId": "ca9a6787-ad59-47af-b71a-301fb34dbaf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "American     65.0\n",
              "Delta        68.0\n",
              "JetBlue      83.0\n",
              "Southwest    81.0\n",
              "United       62.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 331,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 2013 (archive_tweets)\n",
        "acsi_score = pd.Series(\n",
        "          [      81.0 ,     83.0 ,      65.0 ,   68.0 ,    62.0 ],\n",
        "    index=[\"Southwest\", \"JetBlue\", \"American\", \"Delta\", \"United\"]\n",
        ").sort_index()\n",
        "\n",
        "acsi_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOIy6Cvd9IOH"
      },
      "source": [
        "We extracted a single column of the table along with the index containing company names: we change ACSI airline names in order to match the index from `twitter_scores` "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B_8edSA9IOH"
      },
      "outputs": [],
      "source": [
        "acsi_score.index = (acsi_score.index\n",
        "                    .str.lower()\n",
        "                    .str.replace(\"american\", \"americanair\")\n",
        "                    .str.replace(\"southwest\", \"southwestair\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rJTUitHH9IOI",
        "outputId": "5a76ace3-1b95-48b8-8471-bee611ab97bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "americanair     65.0\n",
              "delta           68.0\n",
              "jetblue         83.0\n",
              "southwestair    81.0\n",
              "united          62.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 333,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acsi_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDcu3Kfx9IOJ"
      },
      "source": [
        "We have now the `acsi_score` series and the `score` column of the `twitter_score` frame indexed with the same labels, but in different order: we can merge them into a new frame to align the series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "hhtsXGno9IOJ",
        "outputId": "c70bf993-aea0-49dc-95d5-a12c715057ad"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>twitter</th>\n",
              "      <th>acsi</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>americanair</th>\n",
              "      <td>79.195</td>\n",
              "      <td>65.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>delta</th>\n",
              "      <td>67.442</td>\n",
              "      <td>68.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>jetblue</th>\n",
              "      <td>83.333</td>\n",
              "      <td>83.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>southwestair</th>\n",
              "      <td>78.205</td>\n",
              "      <td>81.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>united</th>\n",
              "      <td>53.670</td>\n",
              "      <td>62.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              twitter  acsi\n",
              "americanair    79.195  65.0\n",
              "delta          67.442  68.0\n",
              "jetblue        83.333  83.0\n",
              "southwestair   78.205  81.0\n",
              "united         53.670  62.0"
            ]
          },
          "execution_count": 334,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame({\"twitter\": twitter_score[\"score\"], \"acsi\": acsi_score})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZhczxte9IOK"
      },
      "source": [
        "We can now evaluate the degree of agreement between the two scores: we may do it graphically using a _scatter plot_..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "pFLxT67U9IOK",
        "outputId": "38f4fc36-dd0f-4fc5-e099-36c559f795ac"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# plt.scatter() function is used to plot points. 's' parameters can be use to set the point dimension\n",
        "plt.scatter(twitter_score[\"score\"], acsi_score, s=50) \n",
        "\n",
        "# plot a x=y segment. First two parameters represents the coordinates of the segment, \n",
        "# while the third one let us draw red dashes\n",
        "plt.plot([50, 100], [50, 100], \"r--\")  \n",
        "plt.xlabel(\"Twitter score\")\n",
        "plt.ylabel(\"ACSI score\");"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DL-_tWRJ9IOL"
      },
      "source": [
        "Each point indicates the scores of a company, the dashed line indicates where scores match: the most the points are close to the line, the most the scores agree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJ8Q-miJ9IOM"
      },
      "source": [
        "To properly verify the agreement of the two scores, we measure the _Pearson's correlation coefficient_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7fLMeuQd9IOM",
        "outputId": "73398d95-86ae-4650-97f6-a24924f0e5ac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.7231598735081548, 0.16740383740447334)"
            ]
          },
          "execution_count": 336,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from scipy.stats import pearsonr\n",
        "pearson_coeff, pvalue = pearsonr(twitter_score[\"score\"], acsi_score)\n",
        "pearson_coeff, pvalue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igRoHtv-9ION"
      },
      "source": [
        "The first value is the Pearson's coefficient, while the second value is the associated p-value, i.e. the probability that the correlation between the two series was obtained by chance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1wEVYlPl1Wh"
      },
      "source": [
        "To decide if the two ACSI distributions and ours are equivalent it is necessary\n",
        "1. set a confidence level, for example $0.80$\n",
        "2. check if $pvalue < (1-0.80) = 0.20$; \n",
        "\n",
        "\n",
        "In this case pvalue is $< 0.20$ so we decide that the difference between the two distributions is the result of chance, i.e. the difference is not statistically significant, in other words they are equivalent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ps1-Zgh-lkMw",
        "outputId": "415ffca8-749e-4749-ab1b-585eee106997"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Our distribution and ACSI one are equivalent!\n"
          ]
        }
      ],
      "source": [
        "confidence_level = 0.80\n",
        "alpha = (1 - confidence_level)\n",
        "\n",
        "if pvalue < alpha:\n",
        "  print(\"Our distribution and ACSI one are equivalent!\")\n",
        "else:\n",
        "  print(\"Our distribution and ACSI one are different!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_x0CVCda9ION"
      },
      "source": [
        "### Exercise 1: interpreting negations\n",
        "\n",
        "In the `sentiment_score` function, when we look for positive or negative words, we do not consider whether they are negated\n",
        "\n",
        "**A)** The `sentiment_score_neg` function below implements the same logic of `sentiment_score` so that it can be more easily changed: modify it in order to count any positive word immediately preceded by \"not\" (case-insensitive) as negative and vice versa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_ebKPt09IOP"
      },
      "outputs": [],
      "source": [
        "def sentiment_score_neg(text, pos_words, neg_words):\n",
        "    words = nltk.word_tokenize(text)\n",
        "    score = 0\n",
        "    for i in range(len(words)):\n",
        "        word_score = 0\n",
        "        if words[i] in pos_words:\n",
        "            word_score = 1\n",
        "        elif words[i] in neg_words:\n",
        "            word_score = -1\n",
        "        score += word_score\n",
        "    return score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eozF1o_R9IOQ"
      },
      "source": [
        "**B)** Create a series `tweet_scores_neg` (using the `sentiment_score_neg` function developed in the previous point) with scores of tweets in `tweets[\"text\"]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GYBWW05y9IOQ"
      },
      "source": [
        "**C)** Compute the mean absolute difference between this previous score and the new score of each tweet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8wVHZ-R9IOQ"
      },
      "source": [
        "**D)** Use the `get_summary_scores` defined above to get a series `twitter_score_neg` with summary scores for each airline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g9sRf63e9IOQ"
      },
      "source": [
        "**E)** Verify the correlation between the new Twitter score and the ACSI score using a scatter plot and Pearson's coefficient as above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yygvv94X9IOQ"
      },
      "source": [
        "## Activity 2: Sentiment Analysis at sentence and feature level\n",
        "\n",
        "We reuse techniques seen above to perform sentiment analysis at sentence and feature level on reviews of hotels\n",
        "\n",
        "TripAdvisor used to provide a summary of hotel ratings against 6 different features: **Location, Sleep Quality, Rooms, Service, Value, Cleanliness**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZwNfCgBU9IOR"
      },
      "source": [
        "### Activity plan\n",
        "\n",
        "1. Define lists of opinion and feature words\n",
        "  - for opinion words, we reuse the lists of Hu and Liu from above\n",
        "2. Break reviews into sentences\n",
        "3. Detect sentences dealing with a specific feature and score its sentiment\n",
        "4. Summarize evaluation of each hotel and each feature\n",
        "5. Compare features of each hotel\n",
        "6. Compare results with scores on TripAdvisor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf0Kw1v49IOR"
      },
      "source": [
        "### Loading reviews\n",
        "\n",
        "We provide a ZIP file with reviews of 6 different Hotels in Chicago, in a format similar to that of airline tweets used above (one file per hotel, one review per line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kOhA6CRF9IOR"
      },
      "outputs": [],
      "source": [
        "download(\"hotel-reviews.zip\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/hotel-reviews.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WMYKO7r39IOT",
        "outputId": "c33f0985-0b0e-4a9f-8442-a6dc32ccb0e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "usa_illinois_chicago_affinia_chicago.txt\n",
            "affinia_chicago\n",
            "usa_illinois_chicago_hyatt_regency_chicago.txt\n",
            "hyatt_regency_chicago\n",
            "usa_illinois_chicago_intercontinental_chicago.txt\n",
            "intercontinental_chicago\n",
            "usa_illinois_chicago_james_chicago.txt\n",
            "james_chicago\n",
            "usa_illinois_chicago_swissotel_chicago.txt\n",
            "swissotel_chicago\n",
            "usa_illinois_chicago_the_palmer_house_hilton.txt\n",
            "the_palmer_house_hilton\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "import re\n",
        "\n",
        "all_reviews = {} # Init an empty dictionary that will be used to collect all the reviews\n",
        "\n",
        "# Define the regular expression that matches the reviews filenames.\n",
        "filename_pattern = re.compile(\"usa_illinois_chicago_([a-z_]+).txt\") # ([a-z_]+) means: \"one or more groups of alphabetic characters followed by an underscore\"\n",
        "\n",
        "with ZipFile(\"hotel-reviews.zip\") as zip: # open the zip file and read the files inside\n",
        "\n",
        "    for filename in zip.namelist(): # we repeat the following statements for each file inside the zip in order to collect the text of each hotel. 1 file --> 1 hotel\n",
        "        print(filename)\n",
        "        # match() returns a match object if one or more characters at the beginning of string match this regular expression, None otherwise. \n",
        "        # Then we call the group() method on the match object: group(1) returns the matched content of the first parenthesized subgroup in the regular expression\n",
        "        hotel = filename_pattern.match(filename).group(1) \n",
        "\n",
        "        print(hotel)\n",
        "\n",
        "        with zip.open(filename) as f: # open each txt file to read its content (i.e the reviews texts)\n",
        "            # for each file: decode each line of the file to UTF-8 encoding (to properly read the string), delete spaces at beginning/end of the string using strip()\n",
        "            # put each transformed line in a list using list()\n",
        "            # put the list of lines of the current file in a new entry of all_reviews dictionary\n",
        "            all_reviews[hotel] = list(line.decode(errors=\"ignore\").strip() for line in f) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9aGIOvin9IOU"
      },
      "source": [
        "As an example, we will use reviews for the Intercontinental hotel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjuPCyyq9IOV"
      },
      "outputs": [],
      "source": [
        "reviews_interc = all_reviews[\"intercontinental_chicago\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 39
        },
        "id": "WHYJMRsK9IOX",
        "outputId": "847bb9a7-d611-439b-e9d4-1530c285292a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A great spot! We have always been pleased with our stays at Intercontinental hotels. Chicago was especially pleasant with a helpful staff.'"
            ]
          },
          "execution_count": 341,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews_interc[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbemiaFE9IOY"
      },
      "source": [
        "### Lists of feature words\n",
        "\n",
        "To detect sentences dealing with a specific feature, we search for feature-related keywords\n",
        "\n",
        "Using only the names of the 6 features as keywords, would produce few results: lists of _feature words_ which are synonyms or anyhow else related to each feature is created (manually in this case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-3DBtSl9IOZ"
      },
      "outputs": [],
      "source": [
        "feature_words = {\n",
        "    'location': {'location', 'airport', 'center', 'island', 'lake', 'ocean',\n",
        "                 'sea', 'around', 'university', 'romantic', 'coast', 'beach',\n",
        "                 'disco', 'nightlife'},\n",
        "    'sleepquality': {'silence','sleep','night','noise','nightlife'},\n",
        "    'rooms': {'room', 'rooms', 'space', 'bed', 'bath', 'bathroom', 'toilet',\n",
        "              'degrade', 'disorder','shower','jacuzzi','frigo'},\n",
        "    'service': {'service','pet','friendly','swimming', 'pool', 'pools', 'spa',\n",
        "                'waiters', 'severs', 'waiter', 'manservant', 'cordial',\n",
        "                'hearty', 'restorative', 'disagreeable', 'unpleasant',\n",
        "                'restaurant', 'food', 'breakfast', 'lunch', 'dinner', 'bar'},\n",
        "    'value': {'cheap','affordable','afford','woth', 'price', 'value', 'cost',\n",
        "              'expensive', 'economical', 'depreciate', 'discount', 'luxury',\n",
        "              'hall', 'meal'},\n",
        "    'cleanliness': {'clean', 'cleanliness', 'place', 'neatness', 'sweeping',\n",
        "                    'dirty', 'soiled', 'grubby', 'foul', 'mucky'}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa3tsTGX9IOa"
      },
      "source": [
        "### Breaking reviews into sentences\n",
        "\n",
        "We break reviews into single sentences, assuming that each sentence deals with (at most) one of the features\n",
        "\n",
        "Breaking text into sentences (_sentence tokenization_) is not straightforward: sentences usually end with a period (\".\"), but may also end with other punctuation (\"!\", \"?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLGtjlvH9IOa"
      },
      "source": [
        "This is an example of function for sentence tokenization, which splits text on \".\", \"?\" and \"!\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GtYfbWuB9IOa"
      },
      "outputs": [],
      "source": [
        "def my_sent_tokenizer(text):\n",
        "    return re.split(\"[\\\\.\\\\?!]\", text) #\\\\ operator escapes the dot and question mark characters. This is needed because '.' and '?' are special characters in regex syntax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-qawU1O9IOb",
        "outputId": "2698a546-1b5b-436a-f08a-470d5309a4cf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['A great spot',\n",
              " ' We have always been pleased with our stays at Intercontinental hotels',\n",
              " ' Chicago was especially pleasant with a helpful staff',\n",
              " '']"
            ]
          },
          "execution_count": 344,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_sent_tokenizer(reviews_interc[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vsr537m99IOe"
      },
      "source": [
        "However this function fails when these characters are used in the middle of a sentence, e.g. in an ellipsis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOwOjGfT9IOe",
        "outputId": "d04fbc57-1f20-4fd6-8cb2-fcce03a024b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This works', '', '', ' or not', ' Maybe not', '']"
            ]
          },
          "execution_count": 345,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_sent_tokenizer(\"This works... or not? Maybe not.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGF6ez9s9IOf"
      },
      "source": [
        "Similarly to the word tokenizer used above, NLTK provides a sentence tokenizer based on knowledge of English language to detect such exceptions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2urU6hiB9IOg",
        "outputId": "9af569cf-693d-4dc7-b288-c9e673843518"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['This works... or not?', 'Maybe not.']"
            ]
          },
          "execution_count": 346,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.sent_tokenize(\"This works... or not? Maybe not.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFIWabkV9IOh"
      },
      "source": [
        "Using this tokenization function, we turn the list of reviews into a list of single sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hz-aaqP39IOh"
      },
      "outputs": [],
      "source": [
        "sentences_interc = [sent for review in reviews_interc for sent in nltk.sent_tokenize(review)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWUuSZu49IOi"
      },
      "source": [
        "### Detecting features and opinions in sentences\n",
        "\n",
        "We define a function which counts, for each feature, the number of sentences in a given list expressing a positive or negative judgement about it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qxb70Fj9IOi"
      },
      "outputs": [],
      "source": [
        "def feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words):\n",
        "    # initialize to 0 counts of positive and negative sentences per feature\n",
        "    pos_counts = {feat: 0 for feat in feature_words.keys()}\n",
        "    neg_counts = {feat: 0 for feat in feature_words.keys()} \n",
        "    # {\n",
        "    #  \"value\": 0,\n",
        "    #  \"service\": 0,\n",
        "    #  ...\n",
        "    # }\n",
        "\n",
        "    for sent in sentences: # analyze each sentence in the sentences list passed as argument to this function\n",
        "\n",
        "        # evaluate sentiment of sentence\n",
        "        word_list = nltk.word_tokenize(sent) # e.g. nltk.word_tokenize(\"This isn't a test, or is it?\") --> ['This', 'is', \"n't\", 'a', 'test', ',', 'or', 'is', 'it', '?']\n",
        "        pos_word_count = sum(1 for word in word_list if word in pos_words) # Sum 1 for each positive word found in the sentence. E.g. 2\n",
        "        neg_word_count = sum(1 for word in word_list if word in neg_words) # Sum 1 for each negative word found in the sentence. E.g. 3\n",
        "        sent_score = pos_word_count - neg_word_count # E.g. 2 - 3 = -1\n",
        "\n",
        "        # detect features in sentence\n",
        "        word_set = set(word_list) # e.g. {'this', 'is', \"n't\", \"a\", \"test\", \",\", \"or\", \"it\", \"?\"}   No words are repeated since we use a set!\n",
        "        # loop over each feature (e.g. value, service, ...) to analyze features in the current sentence \n",
        "        # (i.e. the variable named 'sent')\n",
        "        for feat, keywords in feature_words.items(): \n",
        "            # if the intersection between the sentence word set and the feature keywords is not empty \n",
        "            # (i.e. the sentence contains at least one of the current feature keywords)\n",
        "            if word_set & keywords: \n",
        "                if sent_score > 0: # if the sentence polarity is positive\n",
        "                    pos_counts[feat] += 1 # increment by one the positive counter of the current feature we are analyzing\n",
        "                elif sent_score < 0: # if the sentence polarity is negative\n",
        "                    neg_counts[feat] += 1 # increment by one the negative counter of the current feature we are analyzing\n",
        "\n",
        "    # At the end of the positive/negative counts for each feature, we create a new dataframe containing the features \n",
        "    # as rows and the two counters as columns\n",
        "    return pd.DataFrame({\"pos_count\": pos_counts, \"neg_count\": neg_counts})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qmR31Yb9IOj"
      },
      "source": [
        "For each list of sentences, the function returns a DataFrame with counts of positive and negative sentences for each feature\n",
        "\n",
        "Let's apply it for example to reviews of Intercontinental"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl6kJjaF9IOk"
      },
      "outputs": [],
      "source": [
        "scores_interc = feature_pos_neg_counts(sentences_interc, feature_words, hu_liu_pos, hu_liu_neg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "ODajRR8-9IOk",
        "outputId": "d55b1832-3068-4b7a-ee15-314d54df10bb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_count</th>\n",
              "      <th>neg_count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <td>230</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sleepquality</th>\n",
              "      <td>49</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rooms</th>\n",
              "      <td>423</td>\n",
              "      <td>92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>372</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleanliness</th>\n",
              "      <td>130</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pos_count  neg_count\n",
              "location            230         18\n",
              "sleepquality         49         28\n",
              "rooms               423         92\n",
              "service             372         55\n",
              "value                70         34\n",
              "cleanliness         130         11"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_interc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5smNWpx9IOl"
      },
      "source": [
        "### Summarizing evaluation of hotel features\n",
        "\n",
        "Similarly to above, we compute for each feature a sentiment score in a 0-50 scale from the ratio of positive sentences about a feature w.r.t. their total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvyHtRYs9IOm"
      },
      "outputs": [],
      "source": [
        "scores_interc[\"tot_count\"] = scores_interc.pos_count + scores_interc.neg_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NxSaH52X9IOn"
      },
      "outputs": [],
      "source": [
        "scores_interc[\"score\"] = round(50 * scores_interc.pos_count / scores_interc.tot_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 263
        },
        "id": "TPqAtJN99IOo",
        "outputId": "b1c12bba-8216-4942-b437-2a217aa3a8f2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pos_count</th>\n",
              "      <th>neg_count</th>\n",
              "      <th>tot_count</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>location</th>\n",
              "      <td>230</td>\n",
              "      <td>18</td>\n",
              "      <td>248</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sleepquality</th>\n",
              "      <td>49</td>\n",
              "      <td>28</td>\n",
              "      <td>77</td>\n",
              "      <td>32.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rooms</th>\n",
              "      <td>423</td>\n",
              "      <td>92</td>\n",
              "      <td>515</td>\n",
              "      <td>41.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>service</th>\n",
              "      <td>372</td>\n",
              "      <td>55</td>\n",
              "      <td>427</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>value</th>\n",
              "      <td>70</td>\n",
              "      <td>34</td>\n",
              "      <td>104</td>\n",
              "      <td>34.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>cleanliness</th>\n",
              "      <td>130</td>\n",
              "      <td>11</td>\n",
              "      <td>141</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              pos_count  neg_count  tot_count  score\n",
              "location            230         18        248   46.0\n",
              "sleepquality         49         28         77   32.0\n",
              "rooms               423         92        515   41.0\n",
              "service             372         55        427   44.0\n",
              "value                70         34        104   34.0\n",
              "cleanliness         130         11        141   46.0"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "scores_interc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCoak-S39IOp"
      },
      "source": [
        "In order to easily repeat this process for every hotel, we wrap it in a function which takes as input the list of reviews and returns the Series with the final scores per feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xL4QJitL9IOp"
      },
      "outputs": [],
      "source": [
        "def feature_scores(reviews, feature_words, pos_words, neg_words):\n",
        "    sentences = [sent for review in reviews for sent in nltk.sent_tokenize(review)]\n",
        "    counts = feature_pos_neg_counts(sentences, feature_words, pos_words, neg_words)\n",
        "    total = counts.pos_count + counts.neg_count\n",
        "    return round(50 * counts.pos_count / total)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BF2X1PJN9IOq",
        "outputId": "4e004864-e95f-4469-f2b4-20af351ddab9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "location        46.0\n",
              "sleepquality    32.0\n",
              "rooms           41.0\n",
              "service         44.0\n",
              "value           34.0\n",
              "cleanliness     46.0\n",
              "dtype: float64"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "feature_scores(reviews_interc, feature_words, hu_liu_pos, hu_liu_neg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovCL19qT9IOr"
      },
      "source": [
        "Let's create a DataFrame with feature scores for all analyzed hotels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnPw_fR_9IOr"
      },
      "outputs": [],
      "source": [
        "scores = pd.DataFrame({hotel: feature_scores(reviews, feature_words, hu_liu_pos, hu_liu_neg) for hotel, reviews in all_reviews.items()})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 700
        },
        "id": "eZMYfs7G9IOs",
        "outputId": "bff5bbcd-28ce-4489-fca7-72cc64a80752"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              affinia_chicago  hyatt_regency_chicago  \\\n",
            "location                 45.0                   45.0   \n",
            "sleepquality             25.0                   27.0   \n",
            "rooms                    42.0                   37.0   \n",
            "service                  45.0                   39.0   \n",
            "value                    39.0                   30.0   \n",
            "cleanliness              46.0                   42.0   \n",
            "\n",
            "              intercontinental_chicago  james_chicago  swissotel_chicago  \\\n",
            "location                          46.0           47.0               44.0   \n",
            "sleepquality                      32.0           30.0               32.0   \n",
            "rooms                             41.0           41.0               40.0   \n",
            "service                           44.0           44.0               43.0   \n",
            "value                             34.0           35.0               34.0   \n",
            "cleanliness                       46.0           46.0               46.0   \n",
            "\n",
            "              the_palmer_house_hilton  \n",
            "location                         45.0  \n",
            "sleepquality                     26.0  \n",
            "rooms                            37.0  \n",
            "service                          40.0  \n",
            "value                            35.0  \n",
            "cleanliness                      44.0  \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>location</th>\n",
              "      <th>sleepquality</th>\n",
              "      <th>rooms</th>\n",
              "      <th>service</th>\n",
              "      <th>value</th>\n",
              "      <th>cleanliness</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>affinia_chicago</th>\n",
              "      <td>45.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>45.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>hyatt_regency_chicago</th>\n",
              "      <td>45.0</td>\n",
              "      <td>27.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>39.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>42.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>intercontinental_chicago</th>\n",
              "      <td>46.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>james_chicago</th>\n",
              "      <td>47.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>41.0</td>\n",
              "      <td>44.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>swissotel_chicago</th>\n",
              "      <td>44.0</td>\n",
              "      <td>32.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>43.0</td>\n",
              "      <td>34.0</td>\n",
              "      <td>46.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the_palmer_house_hilton</th>\n",
              "      <td>45.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>37.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>35.0</td>\n",
              "      <td>44.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          location  sleepquality  rooms  service  value  \\\n",
              "affinia_chicago               45.0          25.0   42.0     45.0   39.0   \n",
              "hyatt_regency_chicago         45.0          27.0   37.0     39.0   30.0   \n",
              "intercontinental_chicago      46.0          32.0   41.0     44.0   34.0   \n",
              "james_chicago                 47.0          30.0   41.0     44.0   35.0   \n",
              "swissotel_chicago             44.0          32.0   40.0     43.0   34.0   \n",
              "the_palmer_house_hilton       45.0          26.0   37.0     40.0   35.0   \n",
              "\n",
              "                          cleanliness  \n",
              "affinia_chicago                  46.0  \n",
              "hyatt_regency_chicago            42.0  \n",
              "intercontinental_chicago         46.0  \n",
              "james_chicago                    46.0  \n",
              "swissotel_chicago                46.0  \n",
              "the_palmer_house_hilton          44.0  "
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(scores)\n",
        "\n",
        "scores.T   # transpose the table"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRg2vywT9IOv"
      },
      "source": [
        "We can create a bar plot to compare the hotels by each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "Z77JJX999IOv",
        "outputId": "8f2220fe-897c-4823-c19e-a33eeb4b08ef"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "scores.plot.bar()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr17VRMp9IOw"
      },
      "source": [
        "### Comparing scores with TripAdvisor\n",
        "\n",
        "Obtained scores can be compared with the feature ratings which were computed by TripAdvisor up to some time ago\n",
        "\n",
        "![hotel ratings](https://www.dropbox.com/s/pq6q9ugsaessow6/hotel-ratings.png?dl=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k9gENE_9IOw"
      },
      "source": [
        "## Activity 3: Classification of Reviews via Supervised Training\n",
        "\n",
        "**Goal:** classify user reviews of movies extracted from IMDB as positive or negative\n",
        "\n",
        "Contrarily to previous activities, this time we will train a classificaton model on existing reviews instead of using manually set keywords"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXWxfW1Q9IOw"
      },
      "source": [
        "### Loading reviews\n",
        "\n",
        "We load reviews from a GZIP-compressed CSV file of 10,000 movie reviews, alternated between positive and negative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gyb5edlH9IOx"
      },
      "outputs": [],
      "source": [
        "download(\"acl-10k.csv.gz\", \"https://github.com/unibodatascience/BBS-TextMining/raw/3ad6643b698f652f200dfbf463a3cb49de8c0e9f/05%20-%20Opinion%20Mining%20with%20Python%20(part%201)/data/acl-10k.csv.gz\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUWkUCnB9IOy"
      },
      "outputs": [],
      "source": [
        "reviews = pd.read_csv(\"acl-10k.csv.gz\", sep=\"\\t\", header=None, names=[\"label\", \"text\"], compression=\"gzip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "gYE_BFzX9IOz",
        "outputId": "3bd94ea3-95fe-484d-ecbb-5718a44d007c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>neg</td>\n",
              "      <td>Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pos</td>\n",
              "      <td>If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>neg</td>\n",
              "      <td>Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pos</td>\n",
              "      <td>Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label  \\\n",
              "0   pos   \n",
              "1   neg   \n",
              "2   pos   \n",
              "3   neg   \n",
              "4   pos   \n",
              "\n",
              "                                                                                                  text  \n",
              "0  Bromwell High is a cartoon comedy. It ran at the same time as some other programs about school l...  \n",
              "1  Story of a man who has unnatural feelings for a pig. Starts out with a opening scene that is a t...  \n",
              "2  If you like adult comedy cartoons, like South Park, then this is nearly a similar format about t...  \n",
              "3  Robert DeNiro plays the most unbelievably intelligent illiterate of all time. This movie is so w...  \n",
              "4  Bromwell High is nothing short of brilliant. Expertly scripted and perfectly delivered, this sea...  "
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "reviews.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U172DUlL9IO0"
      },
      "source": [
        "In order to validate the goodness of automated classification, we use the _hold-out_ approach: a part of the reviews is used to train a classifier, while the remaining ones are used to assess its accuracy\n",
        "\n",
        "Let's select the first half of the reviews as the _training set_ and the second half as the _test set_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxsrEToT9IO0"
      },
      "outputs": [],
      "source": [
        "reviews_train = reviews[:5000] # first 5000 reviews\n",
        "reviews_test = reviews[5000:] # last 5000 reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSndGPba9IO1"
      },
      "source": [
        "### Bag of Words and Vector Space Model\n",
        "\n",
        "In order to train and use a classifier on reviews, we have to define the _features_ which represent them\n",
        "\n",
        "With the _Bag of Words_ model we represent each review as the set of words contained in it, regardless of their order\n",
        "\n",
        "Once defined a set of known words, we can represent each review with a vector indicating for each word the number of occurrencies in the text; a set of reviews can be be consequently represented as a _document-term matrix_ with a row vector for each review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4Wvi4Uo9IO1"
      },
      "source": [
        "Let's define a list of example text documents..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV26ZAf49IO1"
      },
      "outputs": [],
      "source": [
        "docs = [\n",
        "    \"the sky is blue\",\n",
        "    \"sky is blue and sky is beautiful\",\n",
        "    \"the beautiful sky is so blue\",\n",
        "    \"i love blue cheese\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MossE1cR9IO2"
      },
      "source": [
        "A `CountVectorizer` extracts a vector for each document with counts of distinct words in it: we start from creating an \"empty\" vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WeRiIqIZ9IO2"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abjwprh_9IO3"
      },
      "source": [
        "We use the `fit_transform` method passing the list of documents to\n",
        "\n",
        "- \"build\" the vector space with dimensions corresponding to words within them (_fit_)\n",
        "- return the document-term matrix representing them (_transform_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaqE_cGv9IO3",
        "outputId": "a8adad6a-dd33-4345-e40e-c2a4aa34f7f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<4x9 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 18 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtm = vect.fit_transform(docs)\n",
        "dtm # 4 x 9 matrix, 4 rows represent the number of documents, 9 columns represent the number of distinct words found within them"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNyRpX6J9IO4"
      },
      "source": [
        "The obtained `dtm` matrix contains a row for each document and a column for each distinct word found within documents: we can obtain a list of the words \"learned\" by the vectorizer..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsirTqtE9IO4",
        "outputId": "7dbbf6d0-2eb9-4eeb-cfaa-05987f6a7f69"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "['and', 'beautiful', 'blue', 'cheese', 'is', 'love', 'sky', 'so', 'the']"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.get_feature_names()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_vDbPWyr9IO5"
      },
      "source": [
        "Let's view the matrix as a DataFrame, labeling rows and columns with corresponding documents and features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "C8xOa6zB9IO5",
        "outputId": "2b50a5ad-6a98-494e-97d7-be3464bd0938"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the sky is blue</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sky is blue and sky is beautiful</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the beautiful sky is so blue</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i love blue cheese</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  and  beautiful  blue  cheese  is  love  sky  \\\n",
              "the sky is blue                     0          0     1       0   1     0    1   \n",
              "sky is blue and sky is beautiful    1          1     1       0   2     0    2   \n",
              "the beautiful sky is so blue        0          1     1       0   1     0    1   \n",
              "i love blue cheese                  0          0     1       1   0     1    0   \n",
              "\n",
              "                                  so  the  \n",
              "the sky is blue                    0    1  \n",
              "sky is blue and sky is beautiful   0    0  \n",
              "the beautiful sky is so blue       1    1  \n",
              "i love blue cheese                 0    0  "
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoJFPERf9IO6"
      },
      "source": [
        "As we can see, the matrix indicates for each document the number of occurrencies of each word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRH85pEK9IO6"
      },
      "source": [
        "Using the `transform` method, we can represent further documents in the same vector space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MNvHGGTU9IO6"
      },
      "outputs": [],
      "source": [
        "new_docs = [\"loving this blue sky today\"]\n",
        "new_dtm = vect.transform(new_docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "k3ZWv5yl9IO7",
        "outputId": "bde8ea97-9213-418a-938d-da7a1863cfc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>loving this blue sky today</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            and  beautiful  blue  cheese  is  love  sky  so  \\\n",
              "loving this blue sky today    0          0     1       0   0     0    1   0   \n",
              "\n",
              "                            the  \n",
              "loving this blue sky today    0  "
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.DataFrame(new_dtm.toarray(), index=new_docs, columns=vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdXF5wcL9IO-"
      },
      "source": [
        "Notice that some words of the new document (e.g. \"loving\") are lost in the representation, because they are not known in the vector space, but this is generally a minor problem if the vector space is built on many documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEB3lHRu9IO_"
      },
      "source": [
        "### Training a classifier\n",
        "\n",
        "We use the vector space model to represent reviews passed to a classifier: let's create a new vector space..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AaeFZphn9IPA"
      },
      "outputs": [],
      "source": [
        "vect = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxVsu06v9IPB"
      },
      "source": [
        "...and fit it to reviews of the training set only (as we assume to _not_ know in advance documents of the test set), obtaining the document-term matrix representing them"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IJ19rE7L9IPB"
      },
      "outputs": [],
      "source": [
        "dtm_train = vect.fit_transform(reviews_train.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EvHsj5Jh9IPC"
      },
      "source": [
        "We can get the total count of extracted feature words..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xUqEZwSn9IPC",
        "outputId": "1540410e-df9f-4c75-84f7-54094d9a0523"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "36272"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ao9puiLl9IPD"
      },
      "source": [
        "...and see some of them (they are in alphabetical order)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8nvNkQL9IPD",
        "outputId": "60d36e1a-4a19-4ae7-ada3-60469f7f7f60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['affections', 'affects', 'afficinados', 'affiliated', 'affiliation']"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect.get_feature_names()[1000:1005]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HEbpXAp49IPE"
      },
      "source": [
        "The document-term matrix is _sparse_, meaning that most of its elements are zero. We can verify the ratio of non-zero elements by converting them to booleans and computing the mean value (all non-zero values become 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ4TYTLb9IPE",
        "outputId": "f3261cb4-87e4-4dcc-b92d-8113119fff70"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0037657973092192322"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dtm_train.astype(bool).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-5Ij_zz9IPF"
      },
      "source": [
        "Such matrix is represented in memory with a space-efficient data structure which explicitly stores non-zero values only"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MtpO5hF9IPF"
      },
      "source": [
        "Now we can train any classification model on the generated vectors: let's use for example logistic regression, SVM and some bayesian models.\n",
        "\n",
        "As for the vectorizer, we first create the \"empty\" model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV3gt-5wxKxW"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "model = MultinomialNB() # Naive Bayes classifier for multinomial models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDV_JuKf-ieE"
      },
      "source": [
        "The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hd6GUeZ6yEno"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import BernoulliNB # Naive Bayes classifier for multivariate Bernoulli models.\n",
        "# The default parameter named \"binarize\" will transform each input vector in a\n",
        "# binary vector based on the specified threshold (0.0)\n",
        "model = BernoulliNB(binarize=0.0) # if input > 0.0 then 1 else 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxyakhXB4z-v"
      },
      "source": [
        "Like MultinomialNB, this classifier is suitable for discrete data but it usually works better with few features and **short docs**. \n",
        "Indeed, this latter Naive Bayes model will perform better (Accuracy: $\\approx$ 77% vs $\\approx$ 81%) than the multinomial version since we are dealing with short texts.\n",
        "\n",
        "The difference is that while MultinomialNB works better with occurrence counts, BernoulliNB is designed for binary/boolean features! Since we have the frequency count for each term, we have to convert it into a binary variable but the BernoulliNB implementation already do this mapping!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rNKFlWZ09Ko"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "model = SVC() # default kernel is set to RBF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2dY6AnK61uJ6"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import LinearSVC\n",
        "model = LinearSVC(max_iter = 5000) # max_iter param represents the maximum number of iterations performed by the optimization algorithm used to train the model by the sklearn library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BYCAZu2v4C1L"
      },
      "source": [
        "SVM generally does just as well on textual data without using kernels because the multidimensional space is so vast that the probability of finding a separation hyperplane is similar to that of finding a nonlinear separation.\n",
        "In other words you can notice that with or without a kernel the result does not change significantly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vc_lVIQnAS-A"
      },
      "source": [
        "Let's go on creating a logistic regression model..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jtFH7fT9IPF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "model = LogisticRegression(solver=\"liblinear\") # liblinear is an optimization algorithm recommended for small volume (small number of rows) and high dimension (high number of columns) datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8die02Q9IPH"
      },
      "source": [
        "...then we fit it to the training set, passing the vector representation of the reviews along with their actual labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yda-8J79IPH",
        "outputId": "981e5406-cdb6-4662-9b80-de77c07730b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dtm_train, reviews_train.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TiT04TP9IPI"
      },
      "source": [
        "### Using the classifier\n",
        "\n",
        "Once the classifier is trained, we can use it to estimate labels for further reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quyMXP829IPI"
      },
      "outputs": [],
      "source": [
        "new_reviews = [\"What an awesome movie!\", \"It was really boring\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aN_eCM4V9IPI"
      },
      "source": [
        "We first have to use the vectorizer to extract their representation in the vector space..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TImYsSgC9IPJ"
      },
      "outputs": [],
      "source": [
        "dtm_new = vect.transform(new_reviews)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1JhS_eH9IPJ"
      },
      "source": [
        "...then we use the `predict` method of the model to get corresponding predicted labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uH3B9x-A9IPJ",
        "outputId": "6af0ae38-7a8f-4bb9-bbf8-1836b08fdaf1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['pos', 'neg'], dtype=object)"
            ]
          },
          "execution_count": 112,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(dtm_new)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XAeXqW9IPK"
      },
      "source": [
        "### Evaluating the classifier\n",
        "\n",
        "We can evaluate the goodness of the classifier by getting predicted labels for reviews in the test set and comparing them with known actual labels\n",
        "\n",
        "Given data and actual labels of the test set, the `score` method of the model computes the _accuracy_ as the ratio of test reviews for which classification is correct\n",
        "\n",
        "We first obtain the document-term matrix for the test set..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t3vPmrv9IPK"
      },
      "outputs": [],
      "source": [
        "dtm_test = vect.transform(reviews_test.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8p-rRVcK9IPM"
      },
      "source": [
        "...then we call the `score` method on it and on the known labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUGulqIl9IPM",
        "outputId": "2e3ada3c-d28c-4ec0-985d-0607de8b9fac"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.819"
            ]
          },
          "execution_count": 114,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(dtm_test, reviews_test.label) # classification accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rSJPrJY9IPN"
      },
      "source": [
        "### Creating a pipeline\n",
        "\n",
        "In all the operations above (training, predicting, evaluating) we had to manually convert text reviews into their vector representations before passing them to the model\n",
        "\n",
        "scikit-learn allows to create _pipelines_, which combine a prediction model with a sequence of one or more pre-processing steps into a single object\n",
        "\n",
        "We first create the pipeline by specifying its components, in this case the vectorizer and the actual classifier; each component has a name, allowing it to be referenced after creation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGRxjDKU9IPO"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "model = Pipeline([\n",
        "    (\"vectorizer\", CountVectorizer()), # Step 1\n",
        "    (\"classifier\", LogisticRegression(max_iter=500)) # Step 2\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eS6yzG6m9IPO"
      },
      "source": [
        "Now, we can use the pipeline as we used the model above, but passing directly the text of reviews, as the vectorizer is automatically fit to reviews used to fit the model and used to transform all reviews passed to the classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WXol6wfi9IPP"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);\n",
        "# \";\" is used to suppress output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3U9h8m8L9IPP",
        "outputId": "c957c309-3ebf-4694-fa7e-87e5152a25fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['pos', 'neg'], dtype=object)"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.predict(new_reviews)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EYlXN3g9IPQ",
        "outputId": "b435e7cd-aea9-4c34-a502-27c986da209f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8188"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9L8flQBB9IPS"
      },
      "source": [
        "We obtain the same result as above, but with cleaner code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_s0lFHW9IPS"
      },
      "source": [
        "### Applying tf.idf term weighting\n",
        "\n",
        "The `CountVectorizer` generates vectors with simple counts of occurrencies of terms within a document, without considering the relative importance of such terms with respect to each other\n",
        "\n",
        "The _tf.idf_ term weighting scheme uses a formula with two factors to better evaluate the weight of each term in each document\n",
        "\n",
        "- The _tf_ factor evaluates the _local_ importance of a term in a document: it is usually the usual count of occurrencies of the term (or its logarithm)\n",
        "- The _idf_ factor evaluates the _global_ importance of a term in the set of documents: it is higher for terms appearing in fewer documents, as they are supposed to be more specific\n",
        "\n",
        "In order to use tf.idf in place of raw counts of occurrencies, we simply use `TfidfVectorizer` in place of `CountVectorizer`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTWh-mql9IPS"
      },
      "source": [
        "Let's see for example the tf.idf applied to example documents used above..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "id": "1adRlwwO9IPS",
        "outputId": "2ace24e6-603d-4cfd-fdba-d2599d4537cb"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>and</th>\n",
              "      <th>beautiful</th>\n",
              "      <th>blue</th>\n",
              "      <th>cheese</th>\n",
              "      <th>is</th>\n",
              "      <th>love</th>\n",
              "      <th>sky</th>\n",
              "      <th>so</th>\n",
              "      <th>the</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>the sky is blue</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.399</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.488</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sky is blue and sky is beautiful</th>\n",
              "      <td>0.441</td>\n",
              "      <td>0.347</td>\n",
              "      <td>0.230</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.562</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>the beautiful sky is so blue</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.432</td>\n",
              "      <td>0.286</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.350</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>i love blue cheese</th>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.346</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.663</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    and  beautiful   blue  cheese     is  \\\n",
              "the sky is blue                   0.000      0.000  0.399   0.000  0.488   \n",
              "sky is blue and sky is beautiful  0.441      0.347  0.230   0.000  0.562   \n",
              "the beautiful sky is so blue      0.000      0.432  0.286   0.000  0.350   \n",
              "i love blue cheese                0.000      0.000  0.346   0.663  0.000   \n",
              "\n",
              "                                   love    sky     so    the  \n",
              "the sky is blue                   0.000  0.488  0.000  0.603  \n",
              "sky is blue and sky is beautiful  0.000  0.562  0.000  0.000  \n",
              "the beautiful sky is so blue      0.000  0.350  0.548  0.432  \n",
              "i love blue cheese                0.663  0.000  0.000  0.000  "
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vect = TfidfVectorizer()\n",
        "dtm = vect.fit_transform(docs)\n",
        "pd.DataFrame(dtm.toarray(), index=docs, columns=vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TC1RFxK9IPU"
      },
      "source": [
        "We can see e.g. in the last document that \"cheese\" has an higher importance than \"blue\", being a less common and thus more discriminating word"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6DC0EG49IPU"
      },
      "source": [
        "We employ tf.idf in our classification pipeline by replacing `CountVectorizer`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByQMYMeM9IPU"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7C2jNFgP9IPW"
      },
      "source": [
        "As above, we fit the model on the training set and then evaluate it on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GmSW_6aS9IPW"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrIM5UFU9IPX",
        "outputId": "16bba1b0-1476-4259-fa03-148518486568"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8412"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRfG6tH99IPY"
      },
      "source": [
        "### Looking for the most influential words\n",
        "\n",
        "Logistic regression computes the likelihood of a review being positive (or negative) according to the following formula:\n",
        "$$ h_\\theta(\\mathbf{x})=\\frac{1}{1+\\exp\\left(-\\theta_0-\\sum_{i=1}^n{\\theta_i\\cdot x_i}\\right)} $$\n",
        "\n",
        "Every $x_i$ variable indicates the element $i$ of an input vector (i.e. the weight of the $i$-th word in the dictionary), while $\\theta_i$ is the model parameter indicating how much the word contributes to the review being estimated as positive or negative\n",
        "\n",
        "By looking at values of the parameters, we can find out which words contribute the most at the reviews being labeled as positive or negative"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e7YGzS49IPZ"
      },
      "source": [
        "The $\\theta_i$ parameters are available as the `coef_` attribute of the `LogisticRegression` model, we get it from the pipeline and print some values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbbzwNtK9IPZ",
        "outputId": "35bf3791-ab2a-4a4a-d94d-3e6c85a3f350"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-0.05094521, -0.01434774, -0.0256676 ,  0.04577293])"
            ]
          },
          "execution_count": 123,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_classifier = model.named_steps[\"classifier\"]\n",
        "\n",
        "model_classifier.coef_[0, :4]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TUAtgdBA9IPa"
      },
      "source": [
        "In order to make sense of the values, we get from the `TfidfVectorizer` the names of features and match them to values using a series"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPsPGgMQ9IPa",
        "outputId": "62abb48c-a549-45ea-c624-3dd18c13eb7f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
        "model_coefs = pd.Series(model_classifier.coef_[0],\n",
        "                        model_vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXPsMfL_9IPb"
      },
      "source": [
        "We sort the values in ascending order"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2EiVr4aC9IPc"
      },
      "outputs": [],
      "source": [
        "model_coefs.sort_values(inplace=True) # inplace=True let us sort the original pandas Series stored in model_coefs variable. Otherwise sort_values would return a copy of the sorted series without sorting the original one."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMLV2Y5O9IPc"
      },
      "source": [
        "Now at the top of the series we find the terms with the lowest coefficients, which make the model decision most tend to the \"negative\" class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0ZpIVzE9IPd",
        "outputId": "31f83e7a-2fb7-4f9b-e04e-c05e8de51423"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "bad      -5.200\n",
              "worst    -4.123\n",
              "awful    -2.801\n",
              "waste    -2.771\n",
              "boring   -2.760\n",
              "dtype: float64"
            ]
          },
          "execution_count": 126,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idX8RZY09IPe"
      },
      "source": [
        "...while at the bottom of the series we find terms with the highest coefficients, whose presence makes the review positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ThCVy2X9IPe",
        "outputId": "5715eda7-d737-4e7d-a22b-2317dbd1a562"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "and      2.434\n",
              "well     2.517\n",
              "love     2.688\n",
              "best     3.217\n",
              "great    4.528\n",
              "dtype: float64"
            ]
          },
          "execution_count": 127,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.tail(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qeg3twi49IPf"
      },
      "source": [
        "In this way, we can generally find out the most important terms in deciding the orientation of a review"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pULaHu9z9IPf"
      },
      "source": [
        "### Regularization of parameters\n",
        "\n",
        "The logistic regression model uses _regularization_ to prevent parameters from having very high absolute values, which may lead to overfitting\n",
        "\n",
        "The C parameter controls the regularization strength: smaller values lead to stronger regularization, while larger values make the model fit more to training data\n",
        "\n",
        "This parameter can be tuned to improve the model accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "78n6wGbC9IPg"
      },
      "source": [
        "Let's try for example to raise the C parameter from its default value 1 to 10, thus lowering the regularization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "flxU_m1R9IPg"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer()),\n",
        "    (\"classifier\", LogisticRegression(C=10))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNlSMPQt9IPh"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQNnmdaj9IPh",
        "outputId": "05c14778-f698-48ed-ccda-071490fa01b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.829"
            ]
          },
          "execution_count": 130,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ePLEJs_79IPi"
      },
      "source": [
        "In this case accuracy slightly drops, possibly due to overfitting"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72a-QgZt9IPi"
      },
      "source": [
        "If we check for model parameters, their absolute value are now higher"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2613CtoE9IPi",
        "outputId": "adaa1e64-5ef7-4684-b552-13d3be7d1221"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "model_classifier = model.named_steps[\"classifier\"]\n",
        "model_vectorizer = model.named_steps[\"vectorizer\"]\n",
        "model_coefs = pd.Series(model_classifier.coef_[0],\n",
        "                        model_vectorizer.get_feature_names())\n",
        "model_coefs.sort_values(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a5Qb8jwP9IPk",
        "outputId": "e59ca867-5a6f-4dbf-db48-249f23cb8676"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "worst   -9.775\n",
              "bad     -9.499\n",
              "awful   -6.673\n",
              "dtype: float64"
            ]
          },
          "execution_count": 132,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7D1bH_gF9IPl",
        "outputId": "6f244896-1db8-482f-add5-81731b6ba817"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "perfect    6.164\n",
              "best       7.489\n",
              "great      8.936\n",
              "dtype: float64"
            ]
          },
          "execution_count": 133,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_coefs.tail(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-9mDJ7Z9IPm"
      },
      "source": [
        "### Reducing the dimensionality\n",
        "\n",
        "Considering the number of distinct terms across all training reviews, the dimensionality of the vector space is very high"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBGZBkZE9IPm",
        "outputId": "7b8c3cd4-d3d9-4353-b034-806ae2a83e0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "36272"
            ]
          },
          "execution_count": 134,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model_vectorizer.get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rLdnbUD69IPm"
      },
      "source": [
        "Methods exist to reduce the dimensionality in order to lower the time required for training the model with very small repercussion on its accuracy\n",
        "\n",
        "One possibility is to not consider words appearing only in very few reviews, such as very specific terms or misspelled words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6EMtre29IPn"
      },
      "source": [
        "We can configure the vectorizer with the `min_df` parameter to exclude terms appearing e.g. in less than 3 training reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z6ZuZ4H-9IPn"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3)), # df stands for document frequency.\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BlU4nBov9IPo"
      },
      "source": [
        "Let's fit the model as above..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "84ujhE7B9IPo"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfGd227X9IPo"
      },
      "source": [
        "Looking at the fit vectorizer, the number of dimensions is now much lower..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koXs4jxM9IPp",
        "outputId": "8f1ee820-cffb-4b8c-85f4-35e583e210b6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "16127"
            ]
          },
          "execution_count": 137,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0d-ti6q79IPp"
      },
      "source": [
        "...but the accuracy is close to the previous value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6R5wO9wf9IPq",
        "outputId": "cd4cfc50-34e1-404e-d67a-0cf28fd8374d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8424"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDT9_dtm9IPq"
      },
      "source": [
        "### Stemming\n",
        "\n",
        "Another way to reduce dimensionality is to group similar terms into an unique feature\n",
        "\n",
        "_Stemming_ is the extraction of the morphological root (_stem_) of a word: using stems of words as features in place of words themselves, we obtain a single feature for possibly several single terms with a common stem (e.g. {run, runned, running} --> \"run\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RamgdDXU9IPq"
      },
      "source": [
        "We start creating a `PorterStemmer` object, providing a `stem` method"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmpatPc29IPr"
      },
      "outputs": [],
      "source": [
        "ps = nltk.stem.PorterStemmer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dc0qOEK9IPr",
        "outputId": "26e3b973-11be-4981-a1fb-9e2f2a64ba92"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('stem', 'stem')"
            ]
          },
          "execution_count": 140,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps.stem(\"stem\"), ps.stem(\"stemming\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cl_591k6v6TZ",
        "outputId": "8de49fb9-30e0-4c1d-b857-b3cb865f981c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "('run', 'run', 'run')"
            ]
          },
          "execution_count": 141,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps.stem(\"run\"), ps.stem(\"runned\"), ps.stem(\"running\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwlX4rHf9IPt"
      },
      "source": [
        "We can use that to create a function which uses NLTK to tokenize text into words and return a sequence of stems instead of complete words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZStwuomf9IPu"
      },
      "outputs": [],
      "source": [
        "def tokenize_with_stemming(text):\n",
        "    return [ps.stem(token) for token # for each word in the tokenized text apply the ps.stem() function\n",
        "        in nltk.tokenize.word_tokenize(text)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZxdVWzM9IPv",
        "outputId": "6c808c03-d97b-4fc6-e7a5-c9f98eea08e3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['we', 'have', 'shown', 'mani', 'exampl', '!']"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenize_with_stemming(\"We have shown many examples!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIs6UWap9IPw"
      },
      "source": [
        "In a vectorizer, we can set the `tokenizer` parameter to use our custom tokenization function in place of scikit-learn default one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ie7GW6VM9IPw"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3, tokenizer=tokenize_with_stemming)),\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Oxp_WkP9IPx"
      },
      "source": [
        "We can then fit the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guFzXQvr9IPx"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train.text, reviews_train.label);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3dMVXv-9IPy"
      },
      "source": [
        "The number of feature is further reduced"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_35EZ_i69IPy",
        "outputId": "a82b4831-8a93-456f-fd1c-4138d6e1014b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "12516"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iysRIvF9IPz"
      },
      "source": [
        "Computing the accuracy..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TYBlI3gx9IPz",
        "outputId": "5ea8db90-c944-442a-98d1-c4580bb5b991"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8402"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test.text, reviews_test.label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbXQzbdz9IP0"
      },
      "source": [
        "...we see in this case a minor loss "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k6QpBeJP9IP0"
      },
      "source": [
        "### n-grams\n",
        "\n",
        "An _n-gram_ is a sequence of n consecutive words in a text: in the common cases with n equal to 2 and 3, they are called _bigrams_ and _trigrams_\n",
        "\n",
        "n-grams can be used in addition or replacement to single words as features to represent reviews: they can be useful to spot meaningful expressions composed of more than one word, although we will also get many n-grams with no significant meaning\n",
        "\n",
        "For example, in the sentence \"Sentiment analysis is not bad\" we have meaningful bigrams indicating a concept (\"Sentiment analysis\") and an opinion (\"not bad\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObnuLgHv9IP0"
      },
      "source": [
        "Setting the `ngram_range` parameter of a vectorizer to a tuple `(a,b)`, it will use as features all n-grams with n between a and b; the default value is `(1, 1)`, meaning that only single words (\"1-grams\") are considered\n",
        "\n",
        "Let's see what happens by setting `(1, 2)`, i.e. considering both single words and bigrams, still limiting features to those appearing in 3 reviews at least"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsRwMuQR9IP0"
      },
      "outputs": [],
      "source": [
        "model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(min_df=3, ngram_range=(1, 2))), # using 1-grams and 2-grams\n",
        "    (\"classifier\", LogisticRegression())\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSOpCexo9IP1"
      },
      "source": [
        "Fit the model as usual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha-KoggH9IP1"
      },
      "outputs": [],
      "source": [
        "model.fit(reviews_train[\"text\"], reviews_train[\"label\"]); #reviews_train.text = reviews_train[\"text\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "py-_TiXu9IP4"
      },
      "source": [
        "Adding bigrams to single words, the dimensionality is sensibly higher..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hA6B_k8q9IP4",
        "outputId": "edaf6973-d561-4314-f31a-7c7f6c453db1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "71800"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(model.named_steps[\"vectorizer\"].get_feature_names()) # \"sentiment\" + \"sentiment analysis\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tW1Xe-wy9IP5"
      },
      "source": [
        "...but in this case we successfully increase the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zKZ1Eq_9IP5",
        "outputId": "ec6c8991-bfa1-4fa9-ca15-de2af61ef098"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.851"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.score(reviews_test[\"text\"], reviews_test[\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_k_q0uh9IP5"
      },
      "source": [
        "### Sentiment analysis with NLTK\n",
        "\n",
        "NLTK integrates specific functions for sentiment analysis, allowing to evaluate the subjectivity and the sentiment of text\n",
        "\n",
        "Let's see for example how to classify reviews using VADER (_Valence Aware Dictionary for sEntiment Reasoning_), a lexicon and rule-based sentiment estimator specifically oriented to social media, of which NLTK provides an implementation\n",
        "\n",
        "- **Reference:** Hutto, C. J., and Eric Gilbert. \"VADER: A Parsimonious Rule-Based Model for Sentiment Analysis of Social Media Text.\" _Eighth International AAAI Conference on Weblogs and Social Media_. 2014."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgCSzAi59IP6"
      },
      "source": [
        "Download the necessary data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmAuvsax9IP6",
        "outputId": "a4ef1eed-1893-4f85-e32c-2208b74e0b46"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/gianluca/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download(\"vader_lexicon\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_-UnfYU9IP6"
      },
      "source": [
        "Import the class and create an analyzer object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNOc25rqu1GP",
        "outputId": "36612d7c-8680-45e7-af70-2ccede221247"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting twython\n",
            "  Downloading twython-3.9.1-py3-none-any.whl (33 kB)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from twython) (1.3.1)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from twython) (2.27.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=2.1.0->twython) (2022.5.18.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=2.1.0->twython) (1.26.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=2.1.0->twython) (3.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests>=2.1.0->twython) (2.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/Caskroom/miniconda/base/envs/r4_env/lib/python3.9/site-packages (from requests-oauthlib>=0.4.0->twython) (3.2.0)\n",
            "Installing collected packages: twython\n",
            "Successfully installed twython-3.9.1\n"
          ]
        }
      ],
      "source": [
        "!pip install twython # nltk.sentiment dependency"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnZ6wPt_9IP6"
      },
      "outputs": [],
      "source": [
        "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
        "vader = SentimentIntensityAnalyzer()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoLmF1HV9IP7"
      },
      "source": [
        "We can see some words in the VADER lexicon along with the positive or negative orientation assigned to them: we can see that typical social media language is recognized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5T7h5oA9IP7",
        "outputId": "9c222227-da31-4c06-ba8c-a821a31b911f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2.7"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\"excellent\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxOoK2PH9IP8",
        "outputId": "c49d1c82-2d3e-4240-f742-708b6bdd5507"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-1.5"
            ]
          },
          "execution_count": 156,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\"sux\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGFlq5j59IP8",
        "outputId": "677ecf2d-3bcc-4eac-d897-55805b8ffd2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-2.8"
            ]
          },
          "execution_count": 157,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\"wtf\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Z-AOTKC9IP9",
        "outputId": "336ac10d-4135-4cd5-9c22-c4242a973f2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1.3"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.lexicon[\":-)\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DwkZwp419IP_"
      },
      "source": [
        "Using the `polarity_score` method, given some text, we obtain a dictionary stating the probability of the sentence being either positive, negative or sentiment-neutral.\n",
        "\n",
        "The `compound` score is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1 (most extreme negative) and +1 (most extreme positive)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9w-Tk-NI9IP_",
        "outputId": "22c57d26-a641-48ef-bca6-0397589c10aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.412, 'pos': 0.588, 'compound': 0.431}"
            ]
          },
          "execution_count": 159,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.polarity_scores(\"Not a bad movie\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMFpr1YA9IQA",
        "outputId": "83127d29-6629-4d12-b58b-8e461091abb2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.413, 'neu': 0.587, 'pos': 0.0, 'compound': -0.2755}"
            ]
          },
          "execution_count": 160,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.polarity_scores(\"I wouldn't recommend this movie\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-28eatr59IQC",
        "outputId": "b7c8f5c3-2df2-4689-b87e-84036894e7d7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'neg': 0.0, 'neu': 0.667, 'pos': 0.333, 'compound': 0.4588}"
            ]
          },
          "execution_count": 161,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader.polarity_scores(\"This movie is candidated to 3 Academy awards\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnBSC1np9IQE"
      },
      "source": [
        "We can see that the model is reasonably good in detecting compound statements such as negations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6s63IFF9IQE"
      },
      "source": [
        "Let's create a function that, given a review, returns a \"pos\" or \"neg\" label according to VADER scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNMhwi1i9IQE"
      },
      "outputs": [],
      "source": [
        "def vader_classify(text):\n",
        "    scores = vader.polarity_scores(text)\n",
        "    return \"pos\" if scores[\"pos\"] >= scores[\"neg\"] else \"neg\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MW-iJVP-9IQF"
      },
      "source": [
        "Using the `apply` method of series, we apply the function to each review text obtaining a series of pos/neg labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUtWVwWa9IQF"
      },
      "outputs": [],
      "source": [
        "vader_preds = reviews_test[\"text\"].apply(vader_classify)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIS92sBh9IQH"
      },
      "source": [
        "We compare this series with actual labels, obtaining a boolean series stating for which reviews the classifier indicated the correct label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPTLs0SR9IQH"
      },
      "outputs": [],
      "source": [
        "vader_hits = vader_preds == reviews_test[\"label\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9_JcA9v9IQJ",
        "outputId": "e6989c45-e715-4421-be88-6f8503089e97"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ True,  True,  True,  True,  True,  True,  True, False,  True])"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader_hits.values[:9]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AWYLf4HU9IQL"
      },
      "source": [
        "Computing the mean, we obtain the ratio of `True` values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BT_IrQIf9IQL",
        "outputId": "bf84ed28-052a-4aff-a7c9-953eceb61c60"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6948"
            ]
          },
          "execution_count": 166,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vader_hits.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "whSM4e3_9IQM"
      },
      "source": [
        "Here VADER achieves a lower accuracy than our supervised model, which however required a large set of pre-labeled reviews to be trained"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKe42xjW9IQM"
      },
      "source": [
        "### Exercise 2: test new methods on tweets\n",
        "\n",
        "In this activity we have seen two sentiment classification methods\n",
        "- using a classifier trained on the labeled reviews used here\n",
        "- using the pretrained VADER model\n",
        "\n",
        "Test both these new methods on airline tweets from the first activity, giving each tweet a score of -5 or 5 according to the negative or positive response of the classifier, then compare as above summary scores obtained by both methods with ACSI scores\n",
        "\n",
        "Which of the two methods do you expect to be more accurate?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZwNfCgBU9IOR",
        "Qr17VRMp9IOw"
      ],
      "name": "1_opinion_lab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}