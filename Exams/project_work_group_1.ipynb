{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "project-work-group-1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzuf3cVHi6TS"
      },
      "source": [
        "# Text Mining Project Work (Group 1)\n",
        "\n",
        "**Text Classification and Sentiment Analysis**\n",
        "\n",
        "_Prof. Gianluca Moro, Dott. Ing. Nicola Piscaglia – DISI, University of Bologna_\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOBjMeN9i6TV"
      },
      "source": [
        "## Instructions\n",
        "- The provided exercises must be executed by the students of Group 1\n",
        "- At the end, the file must contain all the required results (as code cell outputs) along with all the commands necessary to reproduce them; \n",
        "- The function of every command or group of related commands\n",
        "must be documented clearly and concisely. \n",
        "- The submission deadline is the 1st July 2022.\n",
        "- When finished, one team member will send the notebook file (having .ipynb extension) via mail (using your BBS email account) to the teacher (nicola.piscaglia@bbs.unibo.it) indicating “[BBS Teamwork] Your last names” as subject, also keeping an own copy of the file for safety.\n",
        "- You are allowed to consult the teaching material and to search the Web for quick reference. \n",
        "- If still in doubt about anything, ask the teacher\n",
        "- It is severely NOT allowed to communicate with other teams. Ask the teacher for any clarification about the exercises.\n",
        "- Each correctly developed point counts 2/30."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9APLha11i6TX"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The following cell contains some necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQSnHTwOi6TZ"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import os\n",
        "from urllib.request import urlretrieve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dIq4xWzi6Th"
      },
      "source": [
        "Run the following to download the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEUzfMXAi6Ti"
      },
      "source": [
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"Magazine_Subscriptions.json.gz\", \"https://www.dropbox.com/s/g6om8q8c8pvirw8/Magazine_Subscriptions.json.gz?dl=1\")"
      ],
      "metadata": {
        "id": "Rw7H0NU2z9dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T94vizGRi6Tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "663def10-a843-44b0-e5e3-18416eff146b"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefuXgg9i6Tv"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1) We provide in the `Magazine_Subscriptions.json.gz` file a dataset composed by several reviews posted on Amazon.com about Magazine Subscriptions. \n",
        "Each review is labeled with a score between 1 and 5 stars (represented by the ```overall``` feature).\n",
        "\n",
        "The text of each review is represented by the ```reviewText``` feature which is going to be our input data along with the ```overall``` one.\n",
        "\n",
        "Load the dataset putting it in a new Pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Print the dataset rows number and visualize the first 5 rows."
      ],
      "metadata": {
        "id": "YejpY-z8mMEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Undersample the data by `overall` feature in order to obtain a class-balanced dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "hooSUzWZmRJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Cast the `reviewText` column to unicode string\n",
        "\n"
      ],
      "metadata": {
        "id": "jbaY-6hxnY5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5)** Select from data only the features named ```reviewText``` and ```overall``` putting them in a dataframe\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_7uRHPMRS2oj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLk7gkZji6UB"
      },
      "source": [
        "**6)** Verify the distribution of the number of stars"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7)** Remove from the dataframe the reviews rated with 3 stars."
      ],
      "metadata": {
        "id": "h7TL47guxDsK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5JNI0iWi6UH"
      },
      "source": [
        "**8)** Add a `label` column to the DataFrame whose value is `\"pos\"` for reviews with 4 stars, `\"very_pos\"` for 5-rated reviews, `\"neg\"` for reviews with 2 stars and `\"very_neg\"` for 1-rated reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3O4Igei6UK"
      },
      "source": [
        "**9)** Split the dataset randomly into a training set with 70% of data and a test set with the remaining 30%, stratifying the split by the `label` variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLD_buBZi6U6"
      },
      "source": [
        "**10)** Create a tf.idf vector space model from training reviews excluding words appearing in less than 3 documents and using bigrams in addition to single words. Then, extract the document-term matrix for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Xy6Oymi6VC"
      },
      "source": [
        "**11)** Train a logistic regression classifier on the training reviews, using the representation created above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gSb6gDi6VM"
      },
      "source": [
        "**12)** Verify the accuracy of the classifier on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13)** Get the model predictions and print the confusion matrix"
      ],
      "metadata": {
        "id": "lvQRHc_55w0b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14) Train a Deep Learning model of your choice (excluding transformer-based models like BERT) using the document-term representation built in point 10 and evaluate it on test data. Try to maximize the model accuracy. The usage of recurrent layers is up to you."
      ],
      "metadata": {
        "id": "mkzzstKZpMcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15) Get the predictions of this latter model and compare them with the Logistic Regression model ones trained in point 11 using the McNemar test and setting a confidence level = 95% (i.e. p-value must be > 0.05 for models to be significantly similar). \n",
        "\n",
        "Hint: you will need to adapt the type of the two model predictions to integer arrays in order to be compared.\n",
        "\n",
        "\n",
        "To obtain the p-value, you can use the provided `mcnemar_pval` function providing the arrays with the labels predicted by the two models and the true ones.\n",
        "\n",
        "```\n",
        "mcnemar_pval(model1_predictions, model2_predictions, y_test)\n",
        "```\n",
        "\n",
        "Note: McNemar test cannot be applied to compare two models on different test set data."
      ],
      "metadata": {
        "id": "JHn-cla6NrQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "def mcnemar_pval(p1, p2, y_test):\n",
        "    model1_errors = p1 != y_test\n",
        "    model2_errors = p2 != y_test\n",
        "\n",
        "    print(model1_errors, model2_errors)\n",
        "\n",
        "    # define contingency table\n",
        "    mc_table = pd.crosstab(model1_errors, model2_errors)\n",
        "    \n",
        "    print(mc_table)\n",
        "    \n",
        "    # calculate mcnemar test\n",
        "    mc_result = mcnemar(mc_table)\n",
        "    return mc_result.pvalue"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deSWd-yM07Hs",
        "outputId": "e35873ac-5c94-4515-e325-c9f611c3d7ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16) Extra: train/fine-tune a transformer-based model (e.g. BERT) on training reviews and evaluate it on the test reviews."
      ],
      "metadata": {
        "id": "8JSVjRY1gDzj"
      }
    }
  ]
}