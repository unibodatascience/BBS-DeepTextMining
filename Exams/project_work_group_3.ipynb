{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "project-work-group-3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzuf3cVHi6TS"
      },
      "source": [
        "# Text Mining Project Work (Group 3)\n",
        "\n",
        "**Text Classification and Sentiment Analysis**\n",
        "\n",
        "_Prof. Gianluca Moro, Dott. Ing. Nicola Piscaglia – DISI, University of Bologna_\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOBjMeN9i6TV"
      },
      "source": [
        "## Instructions\n",
        "- The provided exercises must be executed by the students of Group 3\n",
        "- At the end, the file must contain all the required results (as code cell outputs) along with all the commands necessary to reproduce them; \n",
        "- The function of every command or group of related commands\n",
        "must be documented clearly and concisely.\n",
        "- The submission deadline is the 1st July 2022.\n",
        "- When finished, one team member will send the notebook file (having .ipynb extension) via mail (using your BBS email account) to the teacher (nicola.piscaglia@bbs.unibo.it) indicating “[BBS Teamwork] Your last names” as subject, also keeping an own copy of the file for safety.\n",
        "- You are allowed to consult the teaching material and to search the Web for quick reference. \n",
        "- If still in doubt about anything, ask the teacher\n",
        "- It is severely NOT allowed to communicate with other teams. Ask the teacher for any clarification about the exercises.\n",
        "- Each correctly developed point counts 2/30."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9APLha11i6TX"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The following cell contains some necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQSnHTwOi6TZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275cf5e6-d276-412f-8358-5c55cccfd814"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "from statsmodels.stats.contingency_tables import mcnemar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dIq4xWzi6Th"
      },
      "source": [
        "Run the following to download the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEUzfMXAi6Ti"
      },
      "source": [
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"Automotive_5.json.gz\", \"https://www.dropbox.com/s/vfpxgpoii7lpy4x/Automotive_5.json.gz?dl=1\")"
      ],
      "metadata": {
        "id": "Rw7H0NU2z9dw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T94vizGRi6Tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0288eba-6162-436b-99ba-8f6ce94d8df5"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefuXgg9i6Tv"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1) We provide in the `Automotive_5.json.gz` file a dataset composed by several reviews posted on Amazon.com about Automotive products. \n",
        "Each review is labeled with a score between 1 and 5 stars (represented by the ```overall``` feature).\n",
        "\n",
        "The text of each review is represented by the ```reviewText``` feature which is going to be our input data along with the ```overall``` one.\n",
        "\n",
        "Load the first 300000 reviews in the dataset putting it in a new Pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Print the dataset rows number and visualize the first 5 rows."
      ],
      "metadata": {
        "id": "YejpY-z8mMEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Undersample the data by `overall` feature in order to obtain a class-balanced dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "hooSUzWZmRJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Cast the `reviewText` column to unicode string\n",
        "\n"
      ],
      "metadata": {
        "id": "jbaY-6hxnY5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5)** Select from data only the features named ```reviewText``` and ```overall``` putting them in a dataframe\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_7uRHPMRS2oj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLk7gkZji6UB"
      },
      "source": [
        "**6)** Verify the distribution of the number of stars"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7)** Remove from the dataframe the reviews rated with 3 stars."
      ],
      "metadata": {
        "id": "h7TL47guxDsK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5JNI0iWi6UH"
      },
      "source": [
        "**8)** Add a `label` column to the DataFrame whose value is `\"pos\"` for reviews with 4 or 5 stars and `\"neg\"` for reviews with 1 or 2 stars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3O4Igei6UK"
      },
      "source": [
        "**9)** Split the dataset randomly into a training set with 65% of data and a test set with the remaining 35%, stratifying the split by the `label` variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLD_buBZi6U6"
      },
      "source": [
        "**10)** Create a tf.idf vector space model from training reviews excluding words appearing in less than 7 documents and using only unigrams. Then, extract the document-term matrix for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Xy6Oymi6VC"
      },
      "source": [
        "**11)** Train a Multinomial Naive Bayes classifier on the training reviews, using the representation created above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gSb6gDi6VM"
      },
      "source": [
        "**12)** Verify the accuracy of the classifier on the test set"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13) Train a Deep Learning model (excluding transformer-based models like BERT) using the document-term representation built in point 10. The usage of recurrent layers is up to you."
      ],
      "metadata": {
        "id": "mkzzstKZpMcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14) Evaluate the model calculating the accuracy on test data. Try to maximize the model accuracy by tuning the neural network. "
      ],
      "metadata": {
        "id": "DiEkWRCnabhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15) Get the predictions of this latter model and the Multinomial Naive Bayes model (trained in point 11) ones. \n",
        "\n",
        "Then compare them using the McNemar test and setting a confidence level = 95%, i.e. p-value must be > 0.05 for models to be significantly similar.\n",
        "\n",
        "To obtain the p-value, use the provided `mcnemar_pval` function providing the arrays with the labels predicted by the two models and the true ones.\n",
        "\n",
        "```\n",
        "mcnemar_pval(model1_predictions, model2_predictions, y_test)\n",
        "```\n",
        "\n",
        "Hint: you will need to adapt the type of the two model predictions to integer arrays in order to be compared."
      ],
      "metadata": {
        "id": "JHn-cla6NrQM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.stats.contingency_tables import mcnemar\n",
        "\n",
        "def mcnemar_pval(p1, p2, y_test):\n",
        "    model1_errors = p1 != y_test\n",
        "    model2_errors = p2 != y_test\n",
        "\n",
        "    # define contingency table\n",
        "    mc_table = pd.crosstab(model1_errors, model2_errors)\n",
        "    \n",
        "    print(mc_table)\n",
        "    \n",
        "    # calculate mcnemar test\n",
        "    mc_result = mcnemar(mc_table)\n",
        "    return mc_result.pvalue"
      ],
      "metadata": {
        "id": "deSWd-yM07Hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "16) Extra: train/fine-tune a transformer-based model (e.g. BERT) on training reviews and evaluate it on the test reviews."
      ],
      "metadata": {
        "id": "8JSVjRY1gDzj"
      }
    }
  ]
}