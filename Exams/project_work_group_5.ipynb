{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "project-work-group-5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fzuf3cVHi6TS"
      },
      "source": [
        "# Text Mining Project Work (Group 5)\n",
        "\n",
        "**Text Classification and Sentiment Analysis**\n",
        "\n",
        "_Prof. Gianluca Moro, Dott. Ing. Nicola Piscaglia – DISI, University of Bologna_\n",
        "\n",
        "**Bologna Business School** - Alma Mater Studiorum Università di Bologna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOBjMeN9i6TV"
      },
      "source": [
        "## Instructions\n",
        "- The provided exercises must be executed by the students of Group 5\n",
        "- At the end, the file must contain all the required results (as code cell outputs) along with all the commands necessary to reproduce them; \n",
        "- The function of every command or group of related commands\n",
        "must be documented clearly and concisely. \n",
        "- The submission deadline is the 1st July 2022.\n",
        "- When finished, one team member will send the notebook file (having .ipynb extension) via mail (using your BBS email account) to the teacher (nicola.piscaglia@bbs.unibo.it) indicating “[BBS Teamwork] Your last names” as subject, also keeping an own copy of the file for safety.\n",
        "- You are allowed to consult the teaching material and to search the Web for quick reference. \n",
        "- If still in doubt about anything, ask the teacher\n",
        "- It is severely NOT allowed to communicate with other teams. Ask the teacher for any clarification about the exercises.\n",
        "- Each correctly developed point counts 2/30"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9APLha11i6TX"
      },
      "source": [
        "## Setup\n",
        "\n",
        "The following cell contains some necessary imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQSnHTwOi6TZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a146a441-a7e6-4285-c324-7ad5dd713e0f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import json\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "import os\n",
        "from urllib.request import urlretrieve\n",
        "from statsmodels.stats.contingency_tables import mcnemar"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5dIq4xWzi6Th"
      },
      "source": [
        "Run the following to download the necessary files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEUzfMXAi6Ti"
      },
      "source": [
        "def download(file, url):\n",
        "    if not os.path.exists(file):\n",
        "        urlretrieve(url, file)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"Gift_Cards.json.gz\", \"https://www.dropbox.com/s/c87cjds263jt3sb/Gift_Cards.json.gz?dl=1\")"
      ],
      "metadata": {
        "id": "Rw7H0NU2z9dw"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download(\"Magazine_Subscriptions.json.gz\", \"https://www.dropbox.com/s/g6om8q8c8pvirw8/Magazine_Subscriptions.json.gz?dl=1\")"
      ],
      "metadata": {
        "id": "GvVE-DgxCqux"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T94vizGRi6Tq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7dad42f-7d93-4dcf-9dd5-2aef4daeff5c"
      },
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HefuXgg9i6Tv"
      },
      "source": [
        "## Exercises\n",
        "\n",
        "1) We provide in the `Gift_Cards.json.gz` file a dataset composed by several reviews posted on Amazon.com about Gift cards products. \n",
        "Each review is labeled with a score between 1 and 5 stars (represented by the ```overall``` feature).\n",
        "\n",
        "The text of each review is represented by the ```reviewText``` feature which is going to be our input data along with the ```overall``` one.\n",
        "\n",
        "Load 100000 random reviews putting it in a new Pandas dataframe."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Print the dataset rows number and visualize the first 5 rows."
      ],
      "metadata": {
        "id": "YejpY-z8mMEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Undersample the data by `overall` feature in order to obtain a class-balanced dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "hooSUzWZmRJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Cast the `reviewText` column to unicode string\n",
        "\n"
      ],
      "metadata": {
        "id": "jbaY-6hxnY5L"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5)** Select from data only the features named ```reviewText``` and ```overall``` putting them in a dataframe\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_7uRHPMRS2oj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLk7gkZji6UB"
      },
      "source": [
        "**6)** Verify the distribution of the number of stars"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7)** Remove from the dataframe the reviews rated with 3 stars."
      ],
      "metadata": {
        "id": "h7TL47guxDsK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5JNI0iWi6UH"
      },
      "source": [
        "**8)** Add a `label` column to the DataFrame whose value is `\"pos\"` for reviews with 4 or 5 stars and `\"neg\"` for reviews with 1 or 2 stars."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gk3O4Igei6UK"
      },
      "source": [
        "**9)** Split the dataset randomly into a training set with 80% of data and a test set with the remaining 20%, stratifying the split by the `label` variable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLD_buBZi6U6"
      },
      "source": [
        "**10)** Create a tf.idf vector space model from training reviews excluding words appearing in less than 7 documents and using only unigrams. Then, extract the document-term matrix for them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F7Xy6Oymi6VC"
      },
      "source": [
        "**11)** Train a Support Vector Machine of your choice on the training reviews with a regularization parameter equals to 5, using the representation created above"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1gSb6gDi6VM"
      },
      "source": [
        "**12)** Verify the accuracy of the classifier on the test set and try to maximize it tuning the Support Vector Machine kernel and regularization factor."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**13)** Train a Deep Learning model (excluding transformer-based models like BERT) using the document-term representation built in point 10. The usage of recurrent layers is up to you."
      ],
      "metadata": {
        "id": "mkzzstKZpMcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14) Evaluate the model calculating the accuracy on test data. Try to maximize the model accuracy by tuning the neural network. "
      ],
      "metadata": {
        "id": "DiEkWRCnabhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "15) Evaluate the DL trained model on 50000 random reviews from the dataset in `Magazine_Subscriptions.json.gz` file.\n",
        "\n",
        "Hint: you have to repeat the preprocessing steps done in the previous steps for the Gift cards reviews."
      ],
      "metadata": {
        "id": "SiJ79SjqCVRf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16) Extra: train/fine-tune a transformer-based model (e.g. BERT) on Gift Cards training reviews and evaluate it on the Gift Cards test reviews."
      ],
      "metadata": {
        "id": "8JSVjRY1gDzj"
      }
    }
  ]
}